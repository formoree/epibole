{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务需求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任务需求：\n",
    "+ 可以用Python在mnist手写数字集的基础上实现二分类网络，只需要给出代码里用到的网络模型，数据结构就行，不做报告也可以。\n",
    "\n",
    "性能要求：\n",
    "+ tensorflow2.0 matplylib numpy\n",
    "\n",
    "项目总结：\n",
    "+ 提前问好顾客电脑环境，如果需要装环境，另加钱20~30\n",
    "\n",
    "时间：2021.7.18.10:43~2021.7.18.3:39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T03:19:09.990266Z",
     "start_time": "2021-07-18T03:19:09.974312Z"
    }
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T04:45:42.780957Z",
     "start_time": "2021-07-18T04:45:42.491699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#这是解压本地文件获取mnist数据集\n",
    "#定义函数读取images和labels文件(training训练集)\n",
    "def readfile():\n",
    "    with open('mnist/train-images.idx3-ubyte','rb') as f:\n",
    "        train_image = f.read()\n",
    "    with open('mnist/train-labels.idx1-ubyte', 'rb') as f:\n",
    "        train_labels = f.read()\n",
    "    return train_image,train_labels\n",
    "\n",
    "#根据官方文件的定义对数据进行清理并可视化\n",
    "image,label=readfile()\n",
    "index = struct.calcsize('>IIII')    # I代表一个无符号整数 ，跳过四个\n",
    "temp = struct.unpack_from('>784B', image, index) #MNIST中的图片都是28*28的，所以读取784bit\n",
    "img=np.reshape(temp, (28, 28))     \n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通过tensorflow自带mnist数据集进行操作\n",
    "#自带数据集与官方数据集相同 tensorflow只是对其进行了简单化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T07:16:15.155065Z",
     "start_time": "2021-07-18T07:16:14.821384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "(x,y),(x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "x.shape,y.shape\n",
    "x_train,y_train=x,y\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T07:16:15.751483Z",
     "start_time": "2021-07-18T07:16:15.733557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上面代码可以看出\n",
    "+ 测试集60000个\n",
    "+ 训练集10000个\n",
    "+ 数据属性为28*28个像素点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T07:16:18.488651Z",
     "start_time": "2021-07-18T07:16:18.268834Z"
    }
   },
   "outputs": [],
   "source": [
    "#MNIST中的突袭那个默认为uint8 (0~255的数字)\n",
    "#对数据进行归一化操作 并在最后一维作为颜色通道\n",
    "# x,y 数据与标签\n",
    "#x_train [60000,28,28,1] 不要多次操作代码块导致数据类型变化\n",
    "x_train = np.expand_dims(x_train.astype(np.float32)/255.0,axis=-1)\n",
    "x_test = np.expand_dims(x_test.astype(np.float32)/255.0,axis=-1)\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "num_x_train,num_x_test = x_train.shape[0],x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T07:19:41.382113Z",
     "start_time": "2021-07-18T07:19:41.362174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T07:24:40.543047Z",
     "start_time": "2021-07-18T07:24:40.525128Z"
    }
   },
   "outputs": [],
   "source": [
    "#从数据集中去除batch_size个元素进行操作 结束操作后返回\n",
    "def get_batch(batch_size,x):\n",
    "    index = np.random.randint(0, np.shape(x)[0], batch_size)\n",
    "    return x_train[index, :], y_train[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T03:11:51.309035Z",
     "start_time": "2021-07-18T03:11:51.286101Z"
    }
   },
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T07:33:48.049293Z",
     "start_time": "2021-07-18T07:33:48.036298Z"
    }
   },
   "source": [
    "网络模型：MLP(多层感知机)\n",
    "+ 网络包含两个全连接层(一个有100个神经元 另一个有10个) 一个softmax输出层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T07:24:41.734613Z",
     "start_time": "2021-07-18T07:24:41.718650Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Flatten层将除第一维（batch_size）以外的维度展平\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        # 全连接层\n",
    "        self.dense1 = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
    "\n",
    "    def call(self, inputs):         # [batch_size, 28, 28, 1]\n",
    "        x = self.flatten(inputs)    # [batch_size, 784]\n",
    "        x = self.dense1(x)          # [batch_size, 100]\n",
    "        x = self.dense2(x)          # [batch_size, 10]\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T07:25:34.720351Z",
     "start_time": "2021-07-18T07:24:42.486763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: loss 2.365585\n",
      "batch 1: loss 2.248271\n",
      "batch 2: loss 2.212050\n",
      "batch 3: loss 2.092207\n",
      "batch 4: loss 1.985019\n",
      "batch 5: loss 1.918889\n",
      "batch 6: loss 1.886167\n",
      "batch 7: loss 1.755687\n",
      "batch 8: loss 1.722627\n",
      "batch 9: loss 1.751982\n",
      "batch 10: loss 1.592212\n",
      "batch 11: loss 1.535149\n",
      "batch 12: loss 1.474612\n",
      "batch 13: loss 1.491805\n",
      "batch 14: loss 1.523125\n",
      "batch 15: loss 1.469264\n",
      "batch 16: loss 1.365804\n",
      "batch 17: loss 1.331698\n",
      "batch 18: loss 1.260811\n",
      "batch 19: loss 1.101466\n",
      "batch 20: loss 1.107714\n",
      "batch 21: loss 1.220228\n",
      "batch 22: loss 1.180540\n",
      "batch 23: loss 1.056524\n",
      "batch 24: loss 0.969161\n",
      "batch 25: loss 0.938684\n",
      "batch 26: loss 1.005489\n",
      "batch 27: loss 1.053588\n",
      "batch 28: loss 0.855048\n",
      "batch 29: loss 0.879035\n",
      "batch 30: loss 0.922849\n",
      "batch 31: loss 0.785271\n",
      "batch 32: loss 0.748908\n",
      "batch 33: loss 0.890691\n",
      "batch 34: loss 0.863075\n",
      "batch 35: loss 0.791543\n",
      "batch 36: loss 0.958595\n",
      "batch 37: loss 0.948610\n",
      "batch 38: loss 0.926383\n",
      "batch 39: loss 0.937089\n",
      "batch 40: loss 0.770561\n",
      "batch 41: loss 0.532925\n",
      "batch 42: loss 0.717192\n",
      "batch 43: loss 0.763193\n",
      "batch 44: loss 0.601580\n",
      "batch 45: loss 0.611936\n",
      "batch 46: loss 0.680100\n",
      "batch 47: loss 0.684971\n",
      "batch 48: loss 0.641209\n",
      "batch 49: loss 0.673555\n",
      "batch 50: loss 0.551734\n",
      "batch 51: loss 0.606676\n",
      "batch 52: loss 0.644554\n",
      "batch 53: loss 0.572426\n",
      "batch 54: loss 0.528384\n",
      "batch 55: loss 0.362808\n",
      "batch 56: loss 0.600360\n",
      "batch 57: loss 0.546602\n",
      "batch 58: loss 0.590022\n",
      "batch 59: loss 0.466512\n",
      "batch 60: loss 0.493104\n",
      "batch 61: loss 0.758354\n",
      "batch 62: loss 0.616509\n",
      "batch 63: loss 0.646795\n",
      "batch 64: loss 0.603667\n",
      "batch 65: loss 0.532242\n",
      "batch 66: loss 0.346438\n",
      "batch 67: loss 0.581876\n",
      "batch 68: loss 0.699922\n",
      "batch 69: loss 0.563550\n",
      "batch 70: loss 0.406004\n",
      "batch 71: loss 0.672777\n",
      "batch 72: loss 0.510119\n",
      "batch 73: loss 0.434324\n",
      "batch 74: loss 0.405425\n",
      "batch 75: loss 0.589863\n",
      "batch 76: loss 0.474524\n",
      "batch 77: loss 0.318664\n",
      "batch 78: loss 0.519273\n",
      "batch 79: loss 0.418623\n",
      "batch 80: loss 0.590023\n",
      "batch 81: loss 0.567282\n",
      "batch 82: loss 0.465849\n",
      "batch 83: loss 0.449021\n",
      "batch 84: loss 0.409394\n",
      "batch 85: loss 0.396487\n",
      "batch 86: loss 0.445340\n",
      "batch 87: loss 0.239471\n",
      "batch 88: loss 0.414606\n",
      "batch 89: loss 0.497236\n",
      "batch 90: loss 0.410088\n",
      "batch 91: loss 0.485192\n",
      "batch 92: loss 0.709856\n",
      "batch 93: loss 0.287348\n",
      "batch 94: loss 0.563241\n",
      "batch 95: loss 0.575004\n",
      "batch 96: loss 0.570900\n",
      "batch 97: loss 0.374054\n",
      "batch 98: loss 0.333836\n",
      "batch 99: loss 0.398720\n",
      "batch 100: loss 0.340521\n",
      "batch 101: loss 0.370521\n",
      "batch 102: loss 0.521178\n",
      "batch 103: loss 0.575528\n",
      "batch 104: loss 0.293997\n",
      "batch 105: loss 0.375290\n",
      "batch 106: loss 0.542660\n",
      "batch 107: loss 0.313360\n",
      "batch 108: loss 0.519954\n",
      "batch 109: loss 0.357271\n",
      "batch 110: loss 0.639342\n",
      "batch 111: loss 0.381846\n",
      "batch 112: loss 0.436630\n",
      "batch 113: loss 0.567900\n",
      "batch 114: loss 0.360525\n",
      "batch 115: loss 0.344552\n",
      "batch 116: loss 0.267292\n",
      "batch 117: loss 0.392724\n",
      "batch 118: loss 0.324175\n",
      "batch 119: loss 0.499229\n",
      "batch 120: loss 0.396897\n",
      "batch 121: loss 0.279354\n",
      "batch 122: loss 0.483477\n",
      "batch 123: loss 0.405206\n",
      "batch 124: loss 0.372100\n",
      "batch 125: loss 0.376384\n",
      "batch 126: loss 0.530852\n",
      "batch 127: loss 0.427123\n",
      "batch 128: loss 0.531260\n",
      "batch 129: loss 0.474277\n",
      "batch 130: loss 0.530963\n",
      "batch 131: loss 0.426486\n",
      "batch 132: loss 0.357005\n",
      "batch 133: loss 0.452309\n",
      "batch 134: loss 0.443560\n",
      "batch 135: loss 0.327450\n",
      "batch 136: loss 0.402760\n",
      "batch 137: loss 0.342350\n",
      "batch 138: loss 0.406298\n",
      "batch 139: loss 0.219711\n",
      "batch 140: loss 0.310045\n",
      "batch 141: loss 0.264225\n",
      "batch 142: loss 0.215078\n",
      "batch 143: loss 0.294182\n",
      "batch 144: loss 0.544588\n",
      "batch 145: loss 0.333862\n",
      "batch 146: loss 0.290602\n",
      "batch 147: loss 0.481555\n",
      "batch 148: loss 0.321652\n",
      "batch 149: loss 0.359688\n",
      "batch 150: loss 0.510179\n",
      "batch 151: loss 0.574834\n",
      "batch 152: loss 0.230789\n",
      "batch 153: loss 0.491148\n",
      "batch 154: loss 0.488558\n",
      "batch 155: loss 0.579244\n",
      "batch 156: loss 0.502852\n",
      "batch 157: loss 0.270028\n",
      "batch 158: loss 0.231613\n",
      "batch 159: loss 0.414007\n",
      "batch 160: loss 0.471811\n",
      "batch 161: loss 0.308258\n",
      "batch 162: loss 0.490304\n",
      "batch 163: loss 0.372240\n",
      "batch 164: loss 0.358860\n",
      "batch 165: loss 0.341616\n",
      "batch 166: loss 0.412336\n",
      "batch 167: loss 0.397914\n",
      "batch 168: loss 0.358050\n",
      "batch 169: loss 0.507919\n",
      "batch 170: loss 0.233935\n",
      "batch 171: loss 0.300752\n",
      "batch 172: loss 0.599217\n",
      "batch 173: loss 0.489968\n",
      "batch 174: loss 0.391587\n",
      "batch 175: loss 0.281740\n",
      "batch 176: loss 0.192811\n",
      "batch 177: loss 0.349779\n",
      "batch 178: loss 0.247869\n",
      "batch 179: loss 0.417586\n",
      "batch 180: loss 0.577595\n",
      "batch 181: loss 0.591232\n",
      "batch 182: loss 0.386835\n",
      "batch 183: loss 0.379274\n",
      "batch 184: loss 0.258880\n",
      "batch 185: loss 0.265305\n",
      "batch 186: loss 0.502199\n",
      "batch 187: loss 0.409834\n",
      "batch 188: loss 0.360779\n",
      "batch 189: loss 0.183350\n",
      "batch 190: loss 0.336404\n",
      "batch 191: loss 0.349374\n",
      "batch 192: loss 0.347625\n",
      "batch 193: loss 0.528716\n",
      "batch 194: loss 0.273893\n",
      "batch 195: loss 0.345042\n",
      "batch 196: loss 0.366163\n",
      "batch 197: loss 0.487851\n",
      "batch 198: loss 0.530381\n",
      "batch 199: loss 0.285123\n",
      "batch 200: loss 0.305068\n",
      "batch 201: loss 0.278404\n",
      "batch 202: loss 0.180719\n",
      "batch 203: loss 0.480715\n",
      "batch 204: loss 0.413290\n",
      "batch 205: loss 0.519754\n",
      "batch 206: loss 0.282529\n",
      "batch 207: loss 0.319670\n",
      "batch 208: loss 0.288601\n",
      "batch 209: loss 0.412016\n",
      "batch 210: loss 0.462313\n",
      "batch 211: loss 0.625079\n",
      "batch 212: loss 0.200744\n",
      "batch 213: loss 0.455729\n",
      "batch 214: loss 0.334885\n",
      "batch 215: loss 0.298242\n",
      "batch 216: loss 0.823689\n",
      "batch 217: loss 0.290324\n",
      "batch 218: loss 0.292323\n",
      "batch 219: loss 0.387765\n",
      "batch 220: loss 0.347649\n",
      "batch 221: loss 0.356273\n",
      "batch 222: loss 0.289344\n",
      "batch 223: loss 0.243414\n",
      "batch 224: loss 0.437339\n",
      "batch 225: loss 0.421400\n",
      "batch 226: loss 0.222882\n",
      "batch 227: loss 0.385257\n",
      "batch 228: loss 0.335708\n",
      "batch 229: loss 0.335594\n",
      "batch 230: loss 0.461018\n",
      "batch 231: loss 0.354698\n",
      "batch 232: loss 0.397967\n",
      "batch 233: loss 0.449839\n",
      "batch 234: loss 0.195017\n",
      "batch 235: loss 0.249762\n",
      "batch 236: loss 0.448443\n",
      "batch 237: loss 0.345611\n",
      "batch 238: loss 0.312965\n",
      "batch 239: loss 0.406711\n",
      "batch 240: loss 0.160314\n",
      "batch 241: loss 0.400521\n",
      "batch 242: loss 0.282736\n",
      "batch 243: loss 0.367893\n",
      "batch 244: loss 0.097293\n",
      "batch 245: loss 0.369735\n",
      "batch 246: loss 0.331637\n",
      "batch 247: loss 0.281484\n",
      "batch 248: loss 0.175007\n",
      "batch 249: loss 0.492846\n",
      "batch 250: loss 0.257485\n",
      "batch 251: loss 0.612773\n",
      "batch 252: loss 0.484752\n",
      "batch 253: loss 0.351385\n",
      "batch 254: loss 0.484836\n",
      "batch 255: loss 0.280349\n",
      "batch 256: loss 0.289349\n",
      "batch 257: loss 0.326263\n",
      "batch 258: loss 0.352180\n",
      "batch 259: loss 0.403557\n",
      "batch 260: loss 0.294648\n",
      "batch 261: loss 0.266421\n",
      "batch 262: loss 0.307326\n",
      "batch 263: loss 0.278092\n",
      "batch 264: loss 0.533668\n",
      "batch 265: loss 0.245000\n",
      "batch 266: loss 0.335253\n",
      "batch 267: loss 0.381045\n",
      "batch 268: loss 0.306143\n",
      "batch 269: loss 0.283001\n",
      "batch 270: loss 0.292047\n",
      "batch 271: loss 0.349029\n",
      "batch 272: loss 0.319337\n",
      "batch 273: loss 0.244453\n",
      "batch 274: loss 0.338490\n",
      "batch 275: loss 0.346069\n",
      "batch 276: loss 0.435966\n",
      "batch 277: loss 0.260890\n",
      "batch 278: loss 0.152064\n",
      "batch 279: loss 0.289010\n",
      "batch 280: loss 0.483479\n",
      "batch 281: loss 0.285763\n",
      "batch 282: loss 0.156554\n",
      "batch 283: loss 0.295336\n",
      "batch 284: loss 0.228055\n",
      "batch 285: loss 0.183140\n",
      "batch 286: loss 0.302926\n",
      "batch 287: loss 0.469817\n",
      "batch 288: loss 0.204438\n",
      "batch 289: loss 0.169108\n",
      "batch 290: loss 0.371333\n",
      "batch 291: loss 0.212863\n",
      "batch 292: loss 0.498108\n",
      "batch 293: loss 0.275111\n",
      "batch 294: loss 0.291549\n",
      "batch 295: loss 0.467774\n",
      "batch 296: loss 0.516865\n",
      "batch 297: loss 0.452661\n",
      "batch 298: loss 0.370789\n",
      "batch 299: loss 0.425324\n",
      "batch 300: loss 0.232523\n",
      "batch 301: loss 0.440013\n",
      "batch 302: loss 0.276789\n",
      "batch 303: loss 0.221663\n",
      "batch 304: loss 0.152884\n",
      "batch 305: loss 0.108858\n",
      "batch 306: loss 0.237763\n",
      "batch 307: loss 0.266723\n",
      "batch 308: loss 0.355311\n",
      "batch 309: loss 0.283161\n",
      "batch 310: loss 0.192025\n",
      "batch 311: loss 0.330034\n",
      "batch 312: loss 0.202762\n",
      "batch 313: loss 0.412776\n",
      "batch 314: loss 0.403731\n",
      "batch 315: loss 0.240852\n",
      "batch 316: loss 0.510499\n",
      "batch 317: loss 0.353267\n",
      "batch 318: loss 0.186073\n",
      "batch 319: loss 0.121643\n",
      "batch 320: loss 0.242004\n",
      "batch 321: loss 0.492595\n",
      "batch 322: loss 0.201890\n",
      "batch 323: loss 0.341031\n",
      "batch 324: loss 0.303398\n",
      "batch 325: loss 0.143915\n",
      "batch 326: loss 0.296101\n",
      "batch 327: loss 0.337191\n",
      "batch 328: loss 0.293429\n",
      "batch 329: loss 0.326928\n",
      "batch 330: loss 0.178112\n",
      "batch 331: loss 0.173303\n",
      "batch 332: loss 0.193474\n",
      "batch 333: loss 0.278532\n",
      "batch 334: loss 0.204177\n",
      "batch 335: loss 0.260605\n",
      "batch 336: loss 0.291581\n",
      "batch 337: loss 0.321019\n",
      "batch 338: loss 0.374268\n",
      "batch 339: loss 0.222785\n",
      "batch 340: loss 0.306853\n",
      "batch 341: loss 0.410694\n",
      "batch 342: loss 0.152635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 343: loss 0.316828\n",
      "batch 344: loss 0.322096\n",
      "batch 345: loss 0.170705\n",
      "batch 346: loss 0.498839\n",
      "batch 347: loss 0.181638\n",
      "batch 348: loss 0.196685\n",
      "batch 349: loss 0.274043\n",
      "batch 350: loss 0.168045\n",
      "batch 351: loss 0.250049\n",
      "batch 352: loss 0.585006\n",
      "batch 353: loss 0.214255\n",
      "batch 354: loss 0.390597\n",
      "batch 355: loss 0.237703\n",
      "batch 356: loss 0.352095\n",
      "batch 357: loss 0.225526\n",
      "batch 358: loss 0.569941\n",
      "batch 359: loss 0.377100\n",
      "batch 360: loss 0.494306\n",
      "batch 361: loss 0.448509\n",
      "batch 362: loss 0.214866\n",
      "batch 363: loss 0.306027\n",
      "batch 364: loss 0.220833\n",
      "batch 365: loss 0.215774\n",
      "batch 366: loss 0.278471\n",
      "batch 367: loss 0.191886\n",
      "batch 368: loss 0.422239\n",
      "batch 369: loss 0.244109\n",
      "batch 370: loss 0.236383\n",
      "batch 371: loss 0.223609\n",
      "batch 372: loss 0.144580\n",
      "batch 373: loss 0.401835\n",
      "batch 374: loss 0.415592\n",
      "batch 375: loss 0.159222\n",
      "batch 376: loss 0.256961\n",
      "batch 377: loss 0.127647\n",
      "batch 378: loss 0.085136\n",
      "batch 379: loss 0.217745\n",
      "batch 380: loss 0.161895\n",
      "batch 381: loss 0.354737\n",
      "batch 382: loss 0.231369\n",
      "batch 383: loss 0.107759\n",
      "batch 384: loss 0.234963\n",
      "batch 385: loss 0.356092\n",
      "batch 386: loss 0.327600\n",
      "batch 387: loss 0.152964\n",
      "batch 388: loss 0.233644\n",
      "batch 389: loss 0.141878\n",
      "batch 390: loss 0.316887\n",
      "batch 391: loss 0.231041\n",
      "batch 392: loss 0.309355\n",
      "batch 393: loss 0.317582\n",
      "batch 394: loss 0.174618\n",
      "batch 395: loss 0.176032\n",
      "batch 396: loss 0.330631\n",
      "batch 397: loss 0.157100\n",
      "batch 398: loss 0.168720\n",
      "batch 399: loss 0.308980\n",
      "batch 400: loss 0.288382\n",
      "batch 401: loss 0.195661\n",
      "batch 402: loss 0.294411\n",
      "batch 403: loss 0.282804\n",
      "batch 404: loss 0.210596\n",
      "batch 405: loss 0.185461\n",
      "batch 406: loss 0.277901\n",
      "batch 407: loss 0.181221\n",
      "batch 408: loss 0.148956\n",
      "batch 409: loss 0.296665\n",
      "batch 410: loss 0.242251\n",
      "batch 411: loss 0.272833\n",
      "batch 412: loss 0.166568\n",
      "batch 413: loss 0.143030\n",
      "batch 414: loss 0.167517\n",
      "batch 415: loss 0.214339\n",
      "batch 416: loss 0.166927\n",
      "batch 417: loss 0.258059\n",
      "batch 418: loss 0.146888\n",
      "batch 419: loss 0.307127\n",
      "batch 420: loss 0.170325\n",
      "batch 421: loss 0.543764\n",
      "batch 422: loss 0.265080\n",
      "batch 423: loss 0.237535\n",
      "batch 424: loss 0.356243\n",
      "batch 425: loss 0.314327\n",
      "batch 426: loss 0.244468\n",
      "batch 427: loss 0.335632\n",
      "batch 428: loss 0.132878\n",
      "batch 429: loss 0.253647\n",
      "batch 430: loss 0.175730\n",
      "batch 431: loss 0.245965\n",
      "batch 432: loss 0.154006\n",
      "batch 433: loss 0.288321\n",
      "batch 434: loss 0.260432\n",
      "batch 435: loss 0.129833\n",
      "batch 436: loss 0.162503\n",
      "batch 437: loss 0.268285\n",
      "batch 438: loss 0.312501\n",
      "batch 439: loss 0.321064\n",
      "batch 440: loss 0.164157\n",
      "batch 441: loss 0.175184\n",
      "batch 442: loss 0.122234\n",
      "batch 443: loss 0.236592\n",
      "batch 444: loss 0.144582\n",
      "batch 445: loss 0.147522\n",
      "batch 446: loss 0.066557\n",
      "batch 447: loss 0.124225\n",
      "batch 448: loss 0.338608\n",
      "batch 449: loss 0.310066\n",
      "batch 450: loss 0.289734\n",
      "batch 451: loss 0.165659\n",
      "batch 452: loss 0.145896\n",
      "batch 453: loss 0.122609\n",
      "batch 454: loss 0.325020\n",
      "batch 455: loss 0.135121\n",
      "batch 456: loss 0.218787\n",
      "batch 457: loss 0.300206\n",
      "batch 458: loss 0.080366\n",
      "batch 459: loss 0.331372\n",
      "batch 460: loss 0.145414\n",
      "batch 461: loss 0.137698\n",
      "batch 462: loss 0.094778\n",
      "batch 463: loss 0.196775\n",
      "batch 464: loss 0.405904\n",
      "batch 465: loss 0.352174\n",
      "batch 466: loss 0.283798\n",
      "batch 467: loss 0.199488\n",
      "batch 468: loss 0.277927\n",
      "batch 469: loss 0.566058\n",
      "batch 470: loss 0.350732\n",
      "batch 471: loss 0.322622\n",
      "batch 472: loss 0.335075\n",
      "batch 473: loss 0.206212\n",
      "batch 474: loss 0.203048\n",
      "batch 475: loss 0.170733\n",
      "batch 476: loss 0.061302\n",
      "batch 477: loss 0.393335\n",
      "batch 478: loss 0.145094\n",
      "batch 479: loss 0.202462\n",
      "batch 480: loss 0.172418\n",
      "batch 481: loss 0.405450\n",
      "batch 482: loss 0.271277\n",
      "batch 483: loss 0.264517\n",
      "batch 484: loss 0.341131\n",
      "batch 485: loss 0.609842\n",
      "batch 486: loss 0.390928\n",
      "batch 487: loss 0.147656\n",
      "batch 488: loss 0.254673\n",
      "batch 489: loss 0.363114\n",
      "batch 490: loss 0.293574\n",
      "batch 491: loss 0.378857\n",
      "batch 492: loss 0.227131\n",
      "batch 493: loss 0.135923\n",
      "batch 494: loss 0.197985\n",
      "batch 495: loss 0.181172\n",
      "batch 496: loss 0.212318\n",
      "batch 497: loss 0.181931\n",
      "batch 498: loss 0.351516\n",
      "batch 499: loss 0.158864\n",
      "batch 500: loss 0.376251\n",
      "batch 501: loss 0.238434\n",
      "batch 502: loss 0.298063\n",
      "batch 503: loss 0.268541\n",
      "batch 504: loss 0.235776\n",
      "batch 505: loss 0.364953\n",
      "batch 506: loss 0.310350\n",
      "batch 507: loss 0.208655\n",
      "batch 508: loss 0.223298\n",
      "batch 509: loss 0.250800\n",
      "batch 510: loss 0.193212\n",
      "batch 511: loss 0.262046\n",
      "batch 512: loss 0.555987\n",
      "batch 513: loss 0.212847\n",
      "batch 514: loss 0.262715\n",
      "batch 515: loss 0.133731\n",
      "batch 516: loss 0.158542\n",
      "batch 517: loss 0.383542\n",
      "batch 518: loss 0.337796\n",
      "batch 519: loss 0.396230\n",
      "batch 520: loss 0.175165\n",
      "batch 521: loss 0.314404\n",
      "batch 522: loss 0.325447\n",
      "batch 523: loss 0.202209\n",
      "batch 524: loss 0.336594\n",
      "batch 525: loss 0.119548\n",
      "batch 526: loss 0.371296\n",
      "batch 527: loss 0.167422\n",
      "batch 528: loss 0.189193\n",
      "batch 529: loss 0.227474\n",
      "batch 530: loss 0.221305\n",
      "batch 531: loss 0.244642\n",
      "batch 532: loss 0.201358\n",
      "batch 533: loss 0.500616\n",
      "batch 534: loss 0.225366\n",
      "batch 535: loss 0.251119\n",
      "batch 536: loss 0.286845\n",
      "batch 537: loss 0.147891\n",
      "batch 538: loss 0.067578\n",
      "batch 539: loss 0.368752\n",
      "batch 540: loss 0.246895\n",
      "batch 541: loss 0.336674\n",
      "batch 542: loss 0.222408\n",
      "batch 543: loss 0.282645\n",
      "batch 544: loss 0.383378\n",
      "batch 545: loss 0.207480\n",
      "batch 546: loss 0.135074\n",
      "batch 547: loss 0.348219\n",
      "batch 548: loss 0.232816\n",
      "batch 549: loss 0.256604\n",
      "batch 550: loss 0.171999\n",
      "batch 551: loss 0.134799\n",
      "batch 552: loss 0.081941\n",
      "batch 553: loss 0.130000\n",
      "batch 554: loss 0.125376\n",
      "batch 555: loss 0.424360\n",
      "batch 556: loss 0.257415\n",
      "batch 557: loss 0.201097\n",
      "batch 558: loss 0.349959\n",
      "batch 559: loss 0.305065\n",
      "batch 560: loss 0.196238\n",
      "batch 561: loss 0.170771\n",
      "batch 562: loss 0.238964\n",
      "batch 563: loss 0.437206\n",
      "batch 564: loss 0.281039\n",
      "batch 565: loss 0.196504\n",
      "batch 566: loss 0.374609\n",
      "batch 567: loss 0.211008\n",
      "batch 568: loss 0.088881\n",
      "batch 569: loss 0.244563\n",
      "batch 570: loss 0.357273\n",
      "batch 571: loss 0.347826\n",
      "batch 572: loss 0.275511\n",
      "batch 573: loss 0.119925\n",
      "batch 574: loss 0.118516\n",
      "batch 575: loss 0.139083\n",
      "batch 576: loss 0.129085\n",
      "batch 577: loss 0.213568\n",
      "batch 578: loss 0.141527\n",
      "batch 579: loss 0.160434\n",
      "batch 580: loss 0.120262\n",
      "batch 581: loss 0.176262\n",
      "batch 582: loss 0.070333\n",
      "batch 583: loss 0.179242\n",
      "batch 584: loss 0.107590\n",
      "batch 585: loss 0.425785\n",
      "batch 586: loss 0.161907\n",
      "batch 587: loss 0.149366\n",
      "batch 588: loss 0.164853\n",
      "batch 589: loss 0.328345\n",
      "batch 590: loss 0.250172\n",
      "batch 591: loss 0.281646\n",
      "batch 592: loss 0.204090\n",
      "batch 593: loss 0.170945\n",
      "batch 594: loss 0.131751\n",
      "batch 595: loss 0.340420\n",
      "batch 596: loss 0.200540\n",
      "batch 597: loss 0.131028\n",
      "batch 598: loss 0.222695\n",
      "batch 599: loss 0.137355\n",
      "batch 600: loss 0.219037\n",
      "batch 601: loss 0.314447\n",
      "batch 602: loss 0.196891\n",
      "batch 603: loss 0.222241\n",
      "batch 604: loss 0.275978\n",
      "batch 605: loss 0.416698\n",
      "batch 606: loss 0.132360\n",
      "batch 607: loss 0.141285\n",
      "batch 608: loss 0.109118\n",
      "batch 609: loss 0.315435\n",
      "batch 610: loss 0.145173\n",
      "batch 611: loss 0.221990\n",
      "batch 612: loss 0.384625\n",
      "batch 613: loss 0.269604\n",
      "batch 614: loss 0.173173\n",
      "batch 615: loss 0.149358\n",
      "batch 616: loss 0.186932\n",
      "batch 617: loss 0.125398\n",
      "batch 618: loss 0.129889\n",
      "batch 619: loss 0.296216\n",
      "batch 620: loss 0.142235\n",
      "batch 621: loss 0.319051\n",
      "batch 622: loss 0.168725\n",
      "batch 623: loss 0.541509\n",
      "batch 624: loss 0.332399\n",
      "batch 625: loss 0.231733\n",
      "batch 626: loss 0.184779\n",
      "batch 627: loss 0.250126\n",
      "batch 628: loss 0.097055\n",
      "batch 629: loss 0.114868\n",
      "batch 630: loss 0.200955\n",
      "batch 631: loss 0.125807\n",
      "batch 632: loss 0.167588\n",
      "batch 633: loss 0.278975\n",
      "batch 634: loss 0.297546\n",
      "batch 635: loss 0.107235\n",
      "batch 636: loss 0.414251\n",
      "batch 637: loss 0.101723\n",
      "batch 638: loss 0.097226\n",
      "batch 639: loss 0.106351\n",
      "batch 640: loss 0.100440\n",
      "batch 641: loss 0.194702\n",
      "batch 642: loss 0.164863\n",
      "batch 643: loss 0.056175\n",
      "batch 644: loss 0.142420\n",
      "batch 645: loss 0.320165\n",
      "batch 646: loss 0.360717\n",
      "batch 647: loss 0.262670\n",
      "batch 648: loss 0.184611\n",
      "batch 649: loss 0.416617\n",
      "batch 650: loss 0.281144\n",
      "batch 651: loss 0.192692\n",
      "batch 652: loss 0.148613\n",
      "batch 653: loss 0.178873\n",
      "batch 654: loss 0.232831\n",
      "batch 655: loss 0.083396\n",
      "batch 656: loss 0.299819\n",
      "batch 657: loss 0.153710\n",
      "batch 658: loss 0.113424\n",
      "batch 659: loss 0.148911\n",
      "batch 660: loss 0.323062\n",
      "batch 661: loss 0.233238\n",
      "batch 662: loss 0.105157\n",
      "batch 663: loss 0.074135\n",
      "batch 664: loss 0.211330\n",
      "batch 665: loss 0.243374\n",
      "batch 666: loss 0.185973\n",
      "batch 667: loss 0.399426\n",
      "batch 668: loss 0.151156\n",
      "batch 669: loss 0.118534\n",
      "batch 670: loss 0.090989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 671: loss 0.307587\n",
      "batch 672: loss 0.220766\n",
      "batch 673: loss 0.121813\n",
      "batch 674: loss 0.515533\n",
      "batch 675: loss 0.230026\n",
      "batch 676: loss 0.164555\n",
      "batch 677: loss 0.315116\n",
      "batch 678: loss 0.111578\n",
      "batch 679: loss 0.279363\n",
      "batch 680: loss 0.283586\n",
      "batch 681: loss 0.112263\n",
      "batch 682: loss 0.039423\n",
      "batch 683: loss 0.140482\n",
      "batch 684: loss 0.241883\n",
      "batch 685: loss 0.114750\n",
      "batch 686: loss 0.099858\n",
      "batch 687: loss 0.205976\n",
      "batch 688: loss 0.292076\n",
      "batch 689: loss 0.228927\n",
      "batch 690: loss 0.195845\n",
      "batch 691: loss 0.296758\n",
      "batch 692: loss 0.331865\n",
      "batch 693: loss 0.222973\n",
      "batch 694: loss 0.624967\n",
      "batch 695: loss 0.118371\n",
      "batch 696: loss 0.229395\n",
      "batch 697: loss 0.243554\n",
      "batch 698: loss 0.149969\n",
      "batch 699: loss 0.298777\n",
      "batch 700: loss 0.157781\n",
      "batch 701: loss 0.220262\n",
      "batch 702: loss 0.376054\n",
      "batch 703: loss 0.339216\n",
      "batch 704: loss 0.377037\n",
      "batch 705: loss 0.211117\n",
      "batch 706: loss 0.196745\n",
      "batch 707: loss 0.442805\n",
      "batch 708: loss 0.233756\n",
      "batch 709: loss 0.127022\n",
      "batch 710: loss 0.418172\n",
      "batch 711: loss 0.133854\n",
      "batch 712: loss 0.233710\n",
      "batch 713: loss 0.093931\n",
      "batch 714: loss 0.122736\n",
      "batch 715: loss 0.155753\n",
      "batch 716: loss 0.278363\n",
      "batch 717: loss 0.229605\n",
      "batch 718: loss 0.224721\n",
      "batch 719: loss 0.181542\n",
      "batch 720: loss 0.189209\n",
      "batch 721: loss 0.417065\n",
      "batch 722: loss 0.235103\n",
      "batch 723: loss 0.326436\n",
      "batch 724: loss 0.250227\n",
      "batch 725: loss 0.236760\n",
      "batch 726: loss 0.256590\n",
      "batch 727: loss 0.128158\n",
      "batch 728: loss 0.409264\n",
      "batch 729: loss 0.240567\n",
      "batch 730: loss 0.121865\n",
      "batch 731: loss 0.146668\n",
      "batch 732: loss 0.045789\n",
      "batch 733: loss 0.165662\n",
      "batch 734: loss 0.233360\n",
      "batch 735: loss 0.234742\n",
      "batch 736: loss 0.168657\n",
      "batch 737: loss 0.206902\n",
      "batch 738: loss 0.152426\n",
      "batch 739: loss 0.296670\n",
      "batch 740: loss 0.204155\n",
      "batch 741: loss 0.141330\n",
      "batch 742: loss 0.294033\n",
      "batch 743: loss 0.121646\n",
      "batch 744: loss 0.380430\n",
      "batch 745: loss 0.075334\n",
      "batch 746: loss 0.172369\n",
      "batch 747: loss 0.138851\n",
      "batch 748: loss 0.352068\n",
      "batch 749: loss 0.076577\n",
      "batch 750: loss 0.168924\n",
      "batch 751: loss 0.118604\n",
      "batch 752: loss 0.196489\n",
      "batch 753: loss 0.191820\n",
      "batch 754: loss 0.166619\n",
      "batch 755: loss 0.164696\n",
      "batch 756: loss 0.124183\n",
      "batch 757: loss 0.168787\n",
      "batch 758: loss 0.101217\n",
      "batch 759: loss 0.175672\n",
      "batch 760: loss 0.349933\n",
      "batch 761: loss 0.452317\n",
      "batch 762: loss 0.445262\n",
      "batch 763: loss 0.360148\n",
      "batch 764: loss 0.136136\n",
      "batch 765: loss 0.174118\n",
      "batch 766: loss 0.144404\n",
      "batch 767: loss 0.335810\n",
      "batch 768: loss 0.131010\n",
      "batch 769: loss 0.091892\n",
      "batch 770: loss 0.184038\n",
      "batch 771: loss 0.145281\n",
      "batch 772: loss 0.340541\n",
      "batch 773: loss 0.242086\n",
      "batch 774: loss 0.122449\n",
      "batch 775: loss 0.269351\n",
      "batch 776: loss 0.274487\n",
      "batch 777: loss 0.149345\n",
      "batch 778: loss 0.248930\n",
      "batch 779: loss 0.152736\n",
      "batch 780: loss 0.227909\n",
      "batch 781: loss 0.270308\n",
      "batch 782: loss 0.100874\n",
      "batch 783: loss 0.228952\n",
      "batch 784: loss 0.204663\n",
      "batch 785: loss 0.156756\n",
      "batch 786: loss 0.100500\n",
      "batch 787: loss 0.224980\n",
      "batch 788: loss 0.119338\n",
      "batch 789: loss 0.322192\n",
      "batch 790: loss 0.132366\n",
      "batch 791: loss 0.125035\n",
      "batch 792: loss 0.081401\n",
      "batch 793: loss 0.188153\n",
      "batch 794: loss 0.185566\n",
      "batch 795: loss 0.179960\n",
      "batch 796: loss 0.121601\n",
      "batch 797: loss 0.233624\n",
      "batch 798: loss 0.217768\n",
      "batch 799: loss 0.230806\n",
      "batch 800: loss 0.398969\n",
      "batch 801: loss 0.245776\n",
      "batch 802: loss 0.092985\n",
      "batch 803: loss 0.222852\n",
      "batch 804: loss 0.174726\n",
      "batch 805: loss 0.243133\n",
      "batch 806: loss 0.036621\n",
      "batch 807: loss 0.381307\n",
      "batch 808: loss 0.097402\n",
      "batch 809: loss 0.125326\n",
      "batch 810: loss 0.260112\n",
      "batch 811: loss 0.147803\n",
      "batch 812: loss 0.180288\n",
      "batch 813: loss 0.131468\n",
      "batch 814: loss 0.197005\n",
      "batch 815: loss 0.326487\n",
      "batch 816: loss 0.459160\n",
      "batch 817: loss 0.220688\n",
      "batch 818: loss 0.154744\n",
      "batch 819: loss 0.228161\n",
      "batch 820: loss 0.248051\n",
      "batch 821: loss 0.210475\n",
      "batch 822: loss 0.152908\n",
      "batch 823: loss 0.216305\n",
      "batch 824: loss 0.180966\n",
      "batch 825: loss 0.124669\n",
      "batch 826: loss 0.203988\n",
      "batch 827: loss 0.126823\n",
      "batch 828: loss 0.198999\n",
      "batch 829: loss 0.165034\n",
      "batch 830: loss 0.137946\n",
      "batch 831: loss 0.204418\n",
      "batch 832: loss 0.187387\n",
      "batch 833: loss 0.165800\n",
      "batch 834: loss 0.146648\n",
      "batch 835: loss 0.142339\n",
      "batch 836: loss 0.426730\n",
      "batch 837: loss 0.156229\n",
      "batch 838: loss 0.210161\n",
      "batch 839: loss 0.308235\n",
      "batch 840: loss 0.174815\n",
      "batch 841: loss 0.394755\n",
      "batch 842: loss 0.148865\n",
      "batch 843: loss 0.552451\n",
      "batch 844: loss 0.251362\n",
      "batch 845: loss 0.114828\n",
      "batch 846: loss 0.289078\n",
      "batch 847: loss 0.091275\n",
      "batch 848: loss 0.104124\n",
      "batch 849: loss 0.272451\n",
      "batch 850: loss 0.069049\n",
      "batch 851: loss 0.105048\n",
      "batch 852: loss 0.327216\n",
      "batch 853: loss 0.367181\n",
      "batch 854: loss 0.146650\n",
      "batch 855: loss 0.388855\n",
      "batch 856: loss 0.364609\n",
      "batch 857: loss 0.184552\n",
      "batch 858: loss 0.194142\n",
      "batch 859: loss 0.209396\n",
      "batch 860: loss 0.172266\n",
      "batch 861: loss 0.218110\n",
      "batch 862: loss 0.177415\n",
      "batch 863: loss 0.305469\n",
      "batch 864: loss 0.047256\n",
      "batch 865: loss 0.233023\n",
      "batch 866: loss 0.198785\n",
      "batch 867: loss 0.057808\n",
      "batch 868: loss 0.150428\n",
      "batch 869: loss 0.238767\n",
      "batch 870: loss 0.194685\n",
      "batch 871: loss 0.165085\n",
      "batch 872: loss 0.195804\n",
      "batch 873: loss 0.114320\n",
      "batch 874: loss 0.202700\n",
      "batch 875: loss 0.194330\n",
      "batch 876: loss 0.181607\n",
      "batch 877: loss 0.158597\n",
      "batch 878: loss 0.188029\n",
      "batch 879: loss 0.149617\n",
      "batch 880: loss 0.156185\n",
      "batch 881: loss 0.322799\n",
      "batch 882: loss 0.217167\n",
      "batch 883: loss 0.047505\n",
      "batch 884: loss 0.342449\n",
      "batch 885: loss 0.261979\n",
      "batch 886: loss 0.085022\n",
      "batch 887: loss 0.111307\n",
      "batch 888: loss 0.188355\n",
      "batch 889: loss 0.090357\n",
      "batch 890: loss 0.293398\n",
      "batch 891: loss 0.144653\n",
      "batch 892: loss 0.103373\n",
      "batch 893: loss 0.099131\n",
      "batch 894: loss 0.171239\n",
      "batch 895: loss 0.200240\n",
      "batch 896: loss 0.140271\n",
      "batch 897: loss 0.097398\n",
      "batch 898: loss 0.161743\n",
      "batch 899: loss 0.262743\n",
      "batch 900: loss 0.168751\n",
      "batch 901: loss 0.239734\n",
      "batch 902: loss 0.253983\n",
      "batch 903: loss 0.155307\n",
      "batch 904: loss 0.171417\n",
      "batch 905: loss 0.456742\n",
      "batch 906: loss 0.189189\n",
      "batch 907: loss 0.081302\n",
      "batch 908: loss 0.215776\n",
      "batch 909: loss 0.173119\n",
      "batch 910: loss 0.200401\n",
      "batch 911: loss 0.127581\n",
      "batch 912: loss 0.257117\n",
      "batch 913: loss 0.270930\n",
      "batch 914: loss 0.151320\n",
      "batch 915: loss 0.346658\n",
      "batch 916: loss 0.146486\n",
      "batch 917: loss 0.074562\n",
      "batch 918: loss 0.216678\n",
      "batch 919: loss 0.113954\n",
      "batch 920: loss 0.071169\n",
      "batch 921: loss 0.090621\n",
      "batch 922: loss 0.092538\n",
      "batch 923: loss 0.188822\n",
      "batch 924: loss 0.083858\n",
      "batch 925: loss 0.285548\n",
      "batch 926: loss 0.116984\n",
      "batch 927: loss 0.173820\n",
      "batch 928: loss 0.241570\n",
      "batch 929: loss 0.197269\n",
      "batch 930: loss 0.178952\n",
      "batch 931: loss 0.258971\n",
      "batch 932: loss 0.117691\n",
      "batch 933: loss 0.101712\n",
      "batch 934: loss 0.225882\n",
      "batch 935: loss 0.169768\n",
      "batch 936: loss 0.085339\n",
      "batch 937: loss 0.245276\n",
      "batch 938: loss 0.209072\n",
      "batch 939: loss 0.203938\n",
      "batch 940: loss 0.268904\n",
      "batch 941: loss 0.258048\n",
      "batch 942: loss 0.238766\n",
      "batch 943: loss 0.141873\n",
      "batch 944: loss 0.188408\n",
      "batch 945: loss 0.176970\n",
      "batch 946: loss 0.059678\n",
      "batch 947: loss 0.252457\n",
      "batch 948: loss 0.087894\n",
      "batch 949: loss 0.108364\n",
      "batch 950: loss 0.267710\n",
      "batch 951: loss 0.131615\n",
      "batch 952: loss 0.254802\n",
      "batch 953: loss 0.251134\n",
      "batch 954: loss 0.116041\n",
      "batch 955: loss 0.164317\n",
      "batch 956: loss 0.117534\n",
      "batch 957: loss 0.255134\n",
      "batch 958: loss 0.172395\n",
      "batch 959: loss 0.168418\n",
      "batch 960: loss 0.220517\n",
      "batch 961: loss 0.061776\n",
      "batch 962: loss 0.125640\n",
      "batch 963: loss 0.211194\n",
      "batch 964: loss 0.087785\n",
      "batch 965: loss 0.375478\n",
      "batch 966: loss 0.159639\n",
      "batch 967: loss 0.176565\n",
      "batch 968: loss 0.155780\n",
      "batch 969: loss 0.425366\n",
      "batch 970: loss 0.335050\n",
      "batch 971: loss 0.414666\n",
      "batch 972: loss 0.105002\n",
      "batch 973: loss 0.114311\n",
      "batch 974: loss 0.291951\n",
      "batch 975: loss 0.145450\n",
      "batch 976: loss 0.158975\n",
      "batch 977: loss 0.223477\n",
      "batch 978: loss 0.545210\n",
      "batch 979: loss 0.044258\n",
      "batch 980: loss 0.129192\n",
      "batch 981: loss 0.240296\n",
      "batch 982: loss 0.149871\n",
      "batch 983: loss 0.150076\n",
      "batch 984: loss 0.061269\n",
      "batch 985: loss 0.074116\n",
      "batch 986: loss 0.031583\n",
      "batch 987: loss 0.138485\n",
      "batch 988: loss 0.259843\n",
      "batch 989: loss 0.352562\n",
      "batch 990: loss 0.218851\n",
      "batch 991: loss 0.109919\n",
      "batch 992: loss 0.272248\n",
      "batch 993: loss 0.179152\n",
      "batch 994: loss 0.031996\n",
      "batch 995: loss 0.172508\n",
      "batch 996: loss 0.123026\n",
      "batch 997: loss 0.155006\n",
      "batch 998: loss 0.217621\n",
      "batch 999: loss 0.381452\n",
      "batch 1000: loss 0.193991\n",
      "batch 1001: loss 0.208183\n",
      "batch 1002: loss 0.127876\n",
      "batch 1003: loss 0.093516\n",
      "batch 1004: loss 0.230425\n",
      "batch 1005: loss 0.147063\n",
      "batch 1006: loss 0.262128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1007: loss 0.183024\n",
      "batch 1008: loss 0.081936\n",
      "batch 1009: loss 0.180952\n",
      "batch 1010: loss 0.261128\n",
      "batch 1011: loss 0.255479\n",
      "batch 1012: loss 0.292919\n",
      "batch 1013: loss 0.127793\n",
      "batch 1014: loss 0.086395\n",
      "batch 1015: loss 0.169743\n",
      "batch 1016: loss 0.056113\n",
      "batch 1017: loss 0.309687\n",
      "batch 1018: loss 0.198141\n",
      "batch 1019: loss 0.086522\n",
      "batch 1020: loss 0.123079\n",
      "batch 1021: loss 0.128092\n",
      "batch 1022: loss 0.048618\n",
      "batch 1023: loss 0.166554\n",
      "batch 1024: loss 0.086390\n",
      "batch 1025: loss 0.199687\n",
      "batch 1026: loss 0.222616\n",
      "batch 1027: loss 0.126794\n",
      "batch 1028: loss 0.066797\n",
      "batch 1029: loss 0.173118\n",
      "batch 1030: loss 0.062038\n",
      "batch 1031: loss 0.229736\n",
      "batch 1032: loss 0.165889\n",
      "batch 1033: loss 0.274059\n",
      "batch 1034: loss 0.149495\n",
      "batch 1035: loss 0.205380\n",
      "batch 1036: loss 0.119361\n",
      "batch 1037: loss 0.100177\n",
      "batch 1038: loss 0.225365\n",
      "batch 1039: loss 0.103192\n",
      "batch 1040: loss 0.095859\n",
      "batch 1041: loss 0.184541\n",
      "batch 1042: loss 0.103586\n",
      "batch 1043: loss 0.244924\n",
      "batch 1044: loss 0.107971\n",
      "batch 1045: loss 0.277043\n",
      "batch 1046: loss 0.085531\n",
      "batch 1047: loss 0.258177\n",
      "batch 1048: loss 0.149892\n",
      "batch 1049: loss 0.305565\n",
      "batch 1050: loss 0.179674\n",
      "batch 1051: loss 0.224689\n",
      "batch 1052: loss 0.184842\n",
      "batch 1053: loss 0.176791\n",
      "batch 1054: loss 0.222319\n",
      "batch 1055: loss 0.118700\n",
      "batch 1056: loss 0.091377\n",
      "batch 1057: loss 0.095135\n",
      "batch 1058: loss 0.301859\n",
      "batch 1059: loss 0.286543\n",
      "batch 1060: loss 0.154247\n",
      "batch 1061: loss 0.196059\n",
      "batch 1062: loss 0.066594\n",
      "batch 1063: loss 0.245239\n",
      "batch 1064: loss 0.223555\n",
      "batch 1065: loss 0.237014\n",
      "batch 1066: loss 0.177172\n",
      "batch 1067: loss 0.252595\n",
      "batch 1068: loss 0.279086\n",
      "batch 1069: loss 0.174730\n",
      "batch 1070: loss 0.162762\n",
      "batch 1071: loss 0.096633\n",
      "batch 1072: loss 0.108529\n",
      "batch 1073: loss 0.206105\n",
      "batch 1074: loss 0.151630\n",
      "batch 1075: loss 0.089671\n",
      "batch 1076: loss 0.199718\n",
      "batch 1077: loss 0.275980\n",
      "batch 1078: loss 0.141156\n",
      "batch 1079: loss 0.301089\n",
      "batch 1080: loss 0.241483\n",
      "batch 1081: loss 0.104832\n",
      "batch 1082: loss 0.120170\n",
      "batch 1083: loss 0.240452\n",
      "batch 1084: loss 0.138312\n",
      "batch 1085: loss 0.119377\n",
      "batch 1086: loss 0.106266\n",
      "batch 1087: loss 0.157518\n",
      "batch 1088: loss 0.188472\n",
      "batch 1089: loss 0.325269\n",
      "batch 1090: loss 0.087847\n",
      "batch 1091: loss 0.105834\n",
      "batch 1092: loss 0.201280\n",
      "batch 1093: loss 0.059974\n",
      "batch 1094: loss 0.101898\n",
      "batch 1095: loss 0.428494\n",
      "batch 1096: loss 0.298577\n",
      "batch 1097: loss 0.278529\n",
      "batch 1098: loss 0.219981\n",
      "batch 1099: loss 0.105412\n",
      "batch 1100: loss 0.152696\n",
      "batch 1101: loss 0.055657\n",
      "batch 1102: loss 0.069262\n",
      "batch 1103: loss 0.338213\n",
      "batch 1104: loss 0.159095\n",
      "batch 1105: loss 0.159195\n",
      "batch 1106: loss 0.244792\n",
      "batch 1107: loss 0.168481\n",
      "batch 1108: loss 0.243990\n",
      "batch 1109: loss 0.115591\n",
      "batch 1110: loss 0.091849\n",
      "batch 1111: loss 0.175655\n",
      "batch 1112: loss 0.137702\n",
      "batch 1113: loss 0.089625\n",
      "batch 1114: loss 0.282432\n",
      "batch 1115: loss 0.231706\n",
      "batch 1116: loss 0.170734\n",
      "batch 1117: loss 0.149707\n",
      "batch 1118: loss 0.070091\n",
      "batch 1119: loss 0.171062\n",
      "batch 1120: loss 0.073866\n",
      "batch 1121: loss 0.129377\n",
      "batch 1122: loss 0.122915\n",
      "batch 1123: loss 0.056509\n",
      "batch 1124: loss 0.276496\n",
      "batch 1125: loss 0.088011\n",
      "batch 1126: loss 0.225104\n",
      "batch 1127: loss 0.171445\n",
      "batch 1128: loss 0.254119\n",
      "batch 1129: loss 0.107111\n",
      "batch 1130: loss 0.053867\n",
      "batch 1131: loss 0.198413\n",
      "batch 1132: loss 0.091869\n",
      "batch 1133: loss 0.427369\n",
      "batch 1134: loss 0.341730\n",
      "batch 1135: loss 0.261101\n",
      "batch 1136: loss 0.256629\n",
      "batch 1137: loss 0.163694\n",
      "batch 1138: loss 0.056278\n",
      "batch 1139: loss 0.426764\n",
      "batch 1140: loss 0.265216\n",
      "batch 1141: loss 0.103992\n",
      "batch 1142: loss 0.071352\n",
      "batch 1143: loss 0.265325\n",
      "batch 1144: loss 0.107013\n",
      "batch 1145: loss 0.152516\n",
      "batch 1146: loss 0.494496\n",
      "batch 1147: loss 0.167087\n",
      "batch 1148: loss 0.149539\n",
      "batch 1149: loss 0.143875\n",
      "batch 1150: loss 0.110543\n",
      "batch 1151: loss 0.181318\n",
      "batch 1152: loss 0.240622\n",
      "batch 1153: loss 0.186606\n",
      "batch 1154: loss 0.085845\n",
      "batch 1155: loss 0.062758\n",
      "batch 1156: loss 0.248984\n",
      "batch 1157: loss 0.169459\n",
      "batch 1158: loss 0.118885\n",
      "batch 1159: loss 0.227795\n",
      "batch 1160: loss 0.080584\n",
      "batch 1161: loss 0.101522\n",
      "batch 1162: loss 0.281393\n",
      "batch 1163: loss 0.243101\n",
      "batch 1164: loss 0.092444\n",
      "batch 1165: loss 0.134157\n",
      "batch 1166: loss 0.088200\n",
      "batch 1167: loss 0.206214\n",
      "batch 1168: loss 0.141896\n",
      "batch 1169: loss 0.150805\n",
      "batch 1170: loss 0.102516\n",
      "batch 1171: loss 0.103389\n",
      "batch 1172: loss 0.110378\n",
      "batch 1173: loss 0.058972\n",
      "batch 1174: loss 0.176671\n",
      "batch 1175: loss 0.266428\n",
      "batch 1176: loss 0.174291\n",
      "batch 1177: loss 0.103441\n",
      "batch 1178: loss 0.131699\n",
      "batch 1179: loss 0.253069\n",
      "batch 1180: loss 0.102348\n",
      "batch 1181: loss 0.241624\n",
      "batch 1182: loss 0.124471\n",
      "batch 1183: loss 0.146450\n",
      "batch 1184: loss 0.177597\n",
      "batch 1185: loss 0.112235\n",
      "batch 1186: loss 0.056113\n",
      "batch 1187: loss 0.086779\n",
      "batch 1188: loss 0.141019\n",
      "batch 1189: loss 0.113097\n",
      "batch 1190: loss 0.492865\n",
      "batch 1191: loss 0.247593\n",
      "batch 1192: loss 0.140043\n",
      "batch 1193: loss 0.079639\n",
      "batch 1194: loss 0.157279\n",
      "batch 1195: loss 0.088153\n",
      "batch 1196: loss 0.146439\n",
      "batch 1197: loss 0.073419\n",
      "batch 1198: loss 0.156733\n",
      "batch 1199: loss 0.317435\n",
      "batch 1200: loss 0.375413\n",
      "batch 1201: loss 0.178431\n",
      "batch 1202: loss 0.178245\n",
      "batch 1203: loss 0.128736\n",
      "batch 1204: loss 0.294784\n",
      "batch 1205: loss 0.034411\n",
      "batch 1206: loss 0.206585\n",
      "batch 1207: loss 0.103216\n",
      "batch 1208: loss 0.137948\n",
      "batch 1209: loss 0.121176\n",
      "batch 1210: loss 0.181086\n",
      "batch 1211: loss 0.080824\n",
      "batch 1212: loss 0.094575\n",
      "batch 1213: loss 0.109224\n",
      "batch 1214: loss 0.266068\n",
      "batch 1215: loss 0.061379\n",
      "batch 1216: loss 0.099858\n",
      "batch 1217: loss 0.053800\n",
      "batch 1218: loss 0.032202\n",
      "batch 1219: loss 0.221347\n",
      "batch 1220: loss 0.235138\n",
      "batch 1221: loss 0.031830\n",
      "batch 1222: loss 0.221708\n",
      "batch 1223: loss 0.186349\n",
      "batch 1224: loss 0.172956\n",
      "batch 1225: loss 0.090825\n",
      "batch 1226: loss 0.120609\n",
      "batch 1227: loss 0.109628\n",
      "batch 1228: loss 0.023704\n",
      "batch 1229: loss 0.179374\n",
      "batch 1230: loss 0.210745\n",
      "batch 1231: loss 0.296660\n",
      "batch 1232: loss 0.178670\n",
      "batch 1233: loss 0.194525\n",
      "batch 1234: loss 0.190517\n",
      "batch 1235: loss 0.109621\n",
      "batch 1236: loss 0.115356\n",
      "batch 1237: loss 0.191023\n",
      "batch 1238: loss 0.301264\n",
      "batch 1239: loss 0.072297\n",
      "batch 1240: loss 0.079626\n",
      "batch 1241: loss 0.088206\n",
      "batch 1242: loss 0.185477\n",
      "batch 1243: loss 0.256379\n",
      "batch 1244: loss 0.063563\n",
      "batch 1245: loss 0.089028\n",
      "batch 1246: loss 0.088217\n",
      "batch 1247: loss 0.222464\n",
      "batch 1248: loss 0.298837\n",
      "batch 1249: loss 0.156673\n",
      "batch 1250: loss 0.230146\n",
      "batch 1251: loss 0.188050\n",
      "batch 1252: loss 0.442059\n",
      "batch 1253: loss 0.166395\n",
      "batch 1254: loss 0.106356\n",
      "batch 1255: loss 0.163429\n",
      "batch 1256: loss 0.136305\n",
      "batch 1257: loss 0.079172\n",
      "batch 1258: loss 0.087582\n",
      "batch 1259: loss 0.142165\n",
      "batch 1260: loss 0.219763\n",
      "batch 1261: loss 0.312549\n",
      "batch 1262: loss 0.189481\n",
      "batch 1263: loss 0.197910\n",
      "batch 1264: loss 0.427664\n",
      "batch 1265: loss 0.367429\n",
      "batch 1266: loss 0.097968\n",
      "batch 1267: loss 0.157237\n",
      "batch 1268: loss 0.336020\n",
      "batch 1269: loss 0.093415\n",
      "batch 1270: loss 0.074246\n",
      "batch 1271: loss 0.226714\n",
      "batch 1272: loss 0.161981\n",
      "batch 1273: loss 0.168410\n",
      "batch 1274: loss 0.136424\n",
      "batch 1275: loss 0.143527\n",
      "batch 1276: loss 0.225421\n",
      "batch 1277: loss 0.204335\n",
      "batch 1278: loss 0.175123\n",
      "batch 1279: loss 0.137351\n",
      "batch 1280: loss 0.368994\n",
      "batch 1281: loss 0.223661\n",
      "batch 1282: loss 0.135500\n",
      "batch 1283: loss 0.086528\n",
      "batch 1284: loss 0.037180\n",
      "batch 1285: loss 0.191817\n",
      "batch 1286: loss 0.224029\n",
      "batch 1287: loss 0.294359\n",
      "batch 1288: loss 0.184517\n",
      "batch 1289: loss 0.148052\n",
      "batch 1290: loss 0.069066\n",
      "batch 1291: loss 0.134688\n",
      "batch 1292: loss 0.126765\n",
      "batch 1293: loss 0.208224\n",
      "batch 1294: loss 0.356843\n",
      "batch 1295: loss 0.113673\n",
      "batch 1296: loss 0.156153\n",
      "batch 1297: loss 0.207268\n",
      "batch 1298: loss 0.179110\n",
      "batch 1299: loss 0.186496\n",
      "batch 1300: loss 0.163006\n",
      "batch 1301: loss 0.165903\n",
      "batch 1302: loss 0.346727\n",
      "batch 1303: loss 0.117996\n",
      "batch 1304: loss 0.243952\n",
      "batch 1305: loss 0.120604\n",
      "batch 1306: loss 0.143912\n",
      "batch 1307: loss 0.154599\n",
      "batch 1308: loss 0.336959\n",
      "batch 1309: loss 0.095520\n",
      "batch 1310: loss 0.044627\n",
      "batch 1311: loss 0.046903\n",
      "batch 1312: loss 0.110627\n",
      "batch 1313: loss 0.094389\n",
      "batch 1314: loss 0.356433\n",
      "batch 1315: loss 0.236542\n",
      "batch 1316: loss 0.166363\n",
      "batch 1317: loss 0.150610\n",
      "batch 1318: loss 0.214187\n",
      "batch 1319: loss 0.073858\n",
      "batch 1320: loss 0.086262\n",
      "batch 1321: loss 0.207643\n",
      "batch 1322: loss 0.129277\n",
      "batch 1323: loss 0.367817\n",
      "batch 1324: loss 0.098040\n",
      "batch 1325: loss 0.095589\n",
      "batch 1326: loss 0.123349\n",
      "batch 1327: loss 0.195630\n",
      "batch 1328: loss 0.037516\n",
      "batch 1329: loss 0.068353\n",
      "batch 1330: loss 0.104833\n",
      "batch 1331: loss 0.074460\n",
      "batch 1332: loss 0.096119\n",
      "batch 1333: loss 0.155978\n",
      "batch 1334: loss 0.154954\n",
      "batch 1335: loss 0.219471\n",
      "batch 1336: loss 0.117548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1337: loss 0.105712\n",
      "batch 1338: loss 0.155533\n",
      "batch 1339: loss 0.157953\n",
      "batch 1340: loss 0.176531\n",
      "batch 1341: loss 0.159907\n",
      "batch 1342: loss 0.148559\n",
      "batch 1343: loss 0.198973\n",
      "batch 1344: loss 0.190443\n",
      "batch 1345: loss 0.052039\n",
      "batch 1346: loss 0.163816\n",
      "batch 1347: loss 0.093607\n",
      "batch 1348: loss 0.107002\n",
      "batch 1349: loss 0.101950\n",
      "batch 1350: loss 0.294776\n",
      "batch 1351: loss 0.072657\n",
      "batch 1352: loss 0.162310\n",
      "batch 1353: loss 0.081606\n",
      "batch 1354: loss 0.059400\n",
      "batch 1355: loss 0.173692\n",
      "batch 1356: loss 0.155346\n",
      "batch 1357: loss 0.042431\n",
      "batch 1358: loss 0.185740\n",
      "batch 1359: loss 0.235396\n",
      "batch 1360: loss 0.242739\n",
      "batch 1361: loss 0.183902\n",
      "batch 1362: loss 0.123587\n",
      "batch 1363: loss 0.098833\n",
      "batch 1364: loss 0.130195\n",
      "batch 1365: loss 0.123339\n",
      "batch 1366: loss 0.225289\n",
      "batch 1367: loss 0.442094\n",
      "batch 1368: loss 0.239283\n",
      "batch 1369: loss 0.122808\n",
      "batch 1370: loss 0.073973\n",
      "batch 1371: loss 0.146230\n",
      "batch 1372: loss 0.173929\n",
      "batch 1373: loss 0.259297\n",
      "batch 1374: loss 0.121170\n",
      "batch 1375: loss 0.051284\n",
      "batch 1376: loss 0.072470\n",
      "batch 1377: loss 0.098729\n",
      "batch 1378: loss 0.118261\n",
      "batch 1379: loss 0.050568\n",
      "batch 1380: loss 0.174979\n",
      "batch 1381: loss 0.134159\n",
      "batch 1382: loss 0.099055\n",
      "batch 1383: loss 0.184118\n",
      "batch 1384: loss 0.118765\n",
      "batch 1385: loss 0.136191\n",
      "batch 1386: loss 0.061232\n",
      "batch 1387: loss 0.097203\n",
      "batch 1388: loss 0.155798\n",
      "batch 1389: loss 0.370132\n",
      "batch 1390: loss 0.236530\n",
      "batch 1391: loss 0.164830\n",
      "batch 1392: loss 0.169013\n",
      "batch 1393: loss 0.128587\n",
      "batch 1394: loss 0.059610\n",
      "batch 1395: loss 0.169629\n",
      "batch 1396: loss 0.239046\n",
      "batch 1397: loss 0.114356\n",
      "batch 1398: loss 0.170788\n",
      "batch 1399: loss 0.172286\n",
      "batch 1400: loss 0.271528\n",
      "batch 1401: loss 0.128796\n",
      "batch 1402: loss 0.129468\n",
      "batch 1403: loss 0.131046\n",
      "batch 1404: loss 0.081391\n",
      "batch 1405: loss 0.187779\n",
      "batch 1406: loss 0.083365\n",
      "batch 1407: loss 0.241472\n",
      "batch 1408: loss 0.110193\n",
      "batch 1409: loss 0.179780\n",
      "batch 1410: loss 0.062253\n",
      "batch 1411: loss 0.389851\n",
      "batch 1412: loss 0.098218\n",
      "batch 1413: loss 0.105238\n",
      "batch 1414: loss 0.169748\n",
      "batch 1415: loss 0.194501\n",
      "batch 1416: loss 0.087693\n",
      "batch 1417: loss 0.176846\n",
      "batch 1418: loss 0.187788\n",
      "batch 1419: loss 0.075639\n",
      "batch 1420: loss 0.078025\n",
      "batch 1421: loss 0.073694\n",
      "batch 1422: loss 0.088844\n",
      "batch 1423: loss 0.197824\n",
      "batch 1424: loss 0.212750\n",
      "batch 1425: loss 0.090573\n",
      "batch 1426: loss 0.203007\n",
      "batch 1427: loss 0.121968\n",
      "batch 1428: loss 0.090514\n",
      "batch 1429: loss 0.121400\n",
      "batch 1430: loss 0.039843\n",
      "batch 1431: loss 0.084965\n",
      "batch 1432: loss 0.183992\n",
      "batch 1433: loss 0.105955\n",
      "batch 1434: loss 0.167724\n",
      "batch 1435: loss 0.211537\n",
      "batch 1436: loss 0.138729\n",
      "batch 1437: loss 0.170017\n",
      "batch 1438: loss 0.095784\n",
      "batch 1439: loss 0.067909\n",
      "batch 1440: loss 0.078809\n",
      "batch 1441: loss 0.127837\n",
      "batch 1442: loss 0.236893\n",
      "batch 1443: loss 0.193149\n",
      "batch 1444: loss 0.140509\n",
      "batch 1445: loss 0.221264\n",
      "batch 1446: loss 0.041745\n",
      "batch 1447: loss 0.125941\n",
      "batch 1448: loss 0.259047\n",
      "batch 1449: loss 0.155289\n",
      "batch 1450: loss 0.137524\n",
      "batch 1451: loss 0.188041\n",
      "batch 1452: loss 0.051450\n",
      "batch 1453: loss 0.112986\n",
      "batch 1454: loss 0.054764\n",
      "batch 1455: loss 0.076532\n",
      "batch 1456: loss 0.175225\n",
      "batch 1457: loss 0.106133\n",
      "batch 1458: loss 0.095870\n",
      "batch 1459: loss 0.035167\n",
      "batch 1460: loss 0.232769\n",
      "batch 1461: loss 0.140968\n",
      "batch 1462: loss 0.124347\n",
      "batch 1463: loss 0.337650\n",
      "batch 1464: loss 0.041844\n",
      "batch 1465: loss 0.307502\n",
      "batch 1466: loss 0.449701\n",
      "batch 1467: loss 0.152072\n",
      "batch 1468: loss 0.046815\n",
      "batch 1469: loss 0.096349\n",
      "batch 1470: loss 0.038701\n",
      "batch 1471: loss 0.076251\n",
      "batch 1472: loss 0.312576\n",
      "batch 1473: loss 0.209052\n",
      "batch 1474: loss 0.233040\n",
      "batch 1475: loss 0.112581\n",
      "batch 1476: loss 0.168255\n",
      "batch 1477: loss 0.094638\n",
      "batch 1478: loss 0.068462\n",
      "batch 1479: loss 0.414398\n",
      "batch 1480: loss 0.081919\n",
      "batch 1481: loss 0.097553\n",
      "batch 1482: loss 0.150248\n",
      "batch 1483: loss 0.122337\n",
      "batch 1484: loss 0.284823\n",
      "batch 1485: loss 0.048043\n",
      "batch 1486: loss 0.258563\n",
      "batch 1487: loss 0.069898\n",
      "batch 1488: loss 0.191986\n",
      "batch 1489: loss 0.139959\n",
      "batch 1490: loss 0.384905\n",
      "batch 1491: loss 0.085368\n",
      "batch 1492: loss 0.251871\n",
      "batch 1493: loss 0.205479\n",
      "batch 1494: loss 0.089405\n",
      "batch 1495: loss 0.148564\n",
      "batch 1496: loss 0.211940\n",
      "batch 1497: loss 0.102374\n",
      "batch 1498: loss 0.138887\n",
      "batch 1499: loss 0.180517\n",
      "batch 1500: loss 0.106527\n",
      "batch 1501: loss 0.162688\n",
      "batch 1502: loss 0.090032\n",
      "batch 1503: loss 0.263846\n",
      "batch 1504: loss 0.189683\n",
      "batch 1505: loss 0.077430\n",
      "batch 1506: loss 0.129038\n",
      "batch 1507: loss 0.092470\n",
      "batch 1508: loss 0.023517\n",
      "batch 1509: loss 0.217230\n",
      "batch 1510: loss 0.110156\n",
      "batch 1511: loss 0.108170\n",
      "batch 1512: loss 0.230592\n",
      "batch 1513: loss 0.053998\n",
      "batch 1514: loss 0.315640\n",
      "batch 1515: loss 0.251376\n",
      "batch 1516: loss 0.062858\n",
      "batch 1517: loss 0.039500\n",
      "batch 1518: loss 0.221906\n",
      "batch 1519: loss 0.081321\n",
      "batch 1520: loss 0.074859\n",
      "batch 1521: loss 0.087411\n",
      "batch 1522: loss 0.280492\n",
      "batch 1523: loss 0.065875\n",
      "batch 1524: loss 0.081156\n",
      "batch 1525: loss 0.134585\n",
      "batch 1526: loss 0.054827\n",
      "batch 1527: loss 0.172683\n",
      "batch 1528: loss 0.080091\n",
      "batch 1529: loss 0.180472\n",
      "batch 1530: loss 0.152882\n",
      "batch 1531: loss 0.140047\n",
      "batch 1532: loss 0.377731\n",
      "batch 1533: loss 0.479099\n",
      "batch 1534: loss 0.064257\n",
      "batch 1535: loss 0.151309\n",
      "batch 1536: loss 0.078200\n",
      "batch 1537: loss 0.118990\n",
      "batch 1538: loss 0.129331\n",
      "batch 1539: loss 0.114198\n",
      "batch 1540: loss 0.175332\n",
      "batch 1541: loss 0.153133\n",
      "batch 1542: loss 0.046245\n",
      "batch 1543: loss 0.054437\n",
      "batch 1544: loss 0.342376\n",
      "batch 1545: loss 0.123210\n",
      "batch 1546: loss 0.014373\n",
      "batch 1547: loss 0.059046\n",
      "batch 1548: loss 0.089130\n",
      "batch 1549: loss 0.105538\n",
      "batch 1550: loss 0.111680\n",
      "batch 1551: loss 0.202744\n",
      "batch 1552: loss 0.185472\n",
      "batch 1553: loss 0.130032\n",
      "batch 1554: loss 0.234727\n",
      "batch 1555: loss 0.200950\n",
      "batch 1556: loss 0.072533\n",
      "batch 1557: loss 0.133955\n",
      "batch 1558: loss 0.225710\n",
      "batch 1559: loss 0.100684\n",
      "batch 1560: loss 0.242824\n",
      "batch 1561: loss 0.115051\n",
      "batch 1562: loss 0.300397\n",
      "batch 1563: loss 0.361706\n",
      "batch 1564: loss 0.141161\n",
      "batch 1565: loss 0.102994\n",
      "batch 1566: loss 0.195865\n",
      "batch 1567: loss 0.153715\n",
      "batch 1568: loss 0.164425\n",
      "batch 1569: loss 0.057470\n",
      "batch 1570: loss 0.094413\n",
      "batch 1571: loss 0.198309\n",
      "batch 1572: loss 0.213011\n",
      "batch 1573: loss 0.138979\n",
      "batch 1574: loss 0.111591\n",
      "batch 1575: loss 0.094931\n",
      "batch 1576: loss 0.057197\n",
      "batch 1577: loss 0.126717\n",
      "batch 1578: loss 0.247842\n",
      "batch 1579: loss 0.238637\n",
      "batch 1580: loss 0.082638\n",
      "batch 1581: loss 0.075930\n",
      "batch 1582: loss 0.042461\n",
      "batch 1583: loss 0.169385\n",
      "batch 1584: loss 0.165975\n",
      "batch 1585: loss 0.222165\n",
      "batch 1586: loss 0.214756\n",
      "batch 1587: loss 0.159476\n",
      "batch 1588: loss 0.168276\n",
      "batch 1589: loss 0.171638\n",
      "batch 1590: loss 0.143077\n",
      "batch 1591: loss 0.111898\n",
      "batch 1592: loss 0.236391\n",
      "batch 1593: loss 0.114166\n",
      "batch 1594: loss 0.321938\n",
      "batch 1595: loss 0.085124\n",
      "batch 1596: loss 0.152541\n",
      "batch 1597: loss 0.115985\n",
      "batch 1598: loss 0.202377\n",
      "batch 1599: loss 0.242135\n",
      "batch 1600: loss 0.154398\n",
      "batch 1601: loss 0.070770\n",
      "batch 1602: loss 0.046639\n",
      "batch 1603: loss 0.060082\n",
      "batch 1604: loss 0.084796\n",
      "batch 1605: loss 0.109767\n",
      "batch 1606: loss 0.184105\n",
      "batch 1607: loss 0.049481\n",
      "batch 1608: loss 0.113495\n",
      "batch 1609: loss 0.118120\n",
      "batch 1610: loss 0.148564\n",
      "batch 1611: loss 0.234608\n",
      "batch 1612: loss 0.177066\n",
      "batch 1613: loss 0.109996\n",
      "batch 1614: loss 0.104933\n",
      "batch 1615: loss 0.099988\n",
      "batch 1616: loss 0.028355\n",
      "batch 1617: loss 0.045868\n",
      "batch 1618: loss 0.116252\n",
      "batch 1619: loss 0.177590\n",
      "batch 1620: loss 0.049231\n",
      "batch 1621: loss 0.179570\n",
      "batch 1622: loss 0.181897\n",
      "batch 1623: loss 0.207465\n",
      "batch 1624: loss 0.075184\n",
      "batch 1625: loss 0.082885\n",
      "batch 1626: loss 0.114374\n",
      "batch 1627: loss 0.076150\n",
      "batch 1628: loss 0.069278\n",
      "batch 1629: loss 0.116570\n",
      "batch 1630: loss 0.151105\n",
      "batch 1631: loss 0.273523\n",
      "batch 1632: loss 0.109402\n",
      "batch 1633: loss 0.246972\n",
      "batch 1634: loss 0.097855\n",
      "batch 1635: loss 0.078637\n",
      "batch 1636: loss 0.101469\n",
      "batch 1637: loss 0.087207\n",
      "batch 1638: loss 0.074574\n",
      "batch 1639: loss 0.083670\n",
      "batch 1640: loss 0.120141\n",
      "batch 1641: loss 0.056225\n",
      "batch 1642: loss 0.091774\n",
      "batch 1643: loss 0.132878\n",
      "batch 1644: loss 0.162760\n",
      "batch 1645: loss 0.125071\n",
      "batch 1646: loss 0.056928\n",
      "batch 1647: loss 0.217169\n",
      "batch 1648: loss 0.142652\n",
      "batch 1649: loss 0.140938\n",
      "batch 1650: loss 0.109586\n",
      "batch 1651: loss 0.134588\n",
      "batch 1652: loss 0.105895\n",
      "batch 1653: loss 0.247465\n",
      "batch 1654: loss 0.053026\n",
      "batch 1655: loss 0.179344\n",
      "batch 1656: loss 0.107026\n",
      "batch 1657: loss 0.119002\n",
      "batch 1658: loss 0.084665\n",
      "batch 1659: loss 0.058755\n",
      "batch 1660: loss 0.093896\n",
      "batch 1661: loss 0.118044\n",
      "batch 1662: loss 0.255475\n",
      "batch 1663: loss 0.078292\n",
      "batch 1664: loss 0.033749\n",
      "batch 1665: loss 0.035603\n",
      "batch 1666: loss 0.064426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1667: loss 0.191919\n",
      "batch 1668: loss 0.271364\n",
      "batch 1669: loss 0.164512\n",
      "batch 1670: loss 0.114621\n",
      "batch 1671: loss 0.065547\n",
      "batch 1672: loss 0.090629\n",
      "batch 1673: loss 0.031071\n",
      "batch 1674: loss 0.114492\n",
      "batch 1675: loss 0.288997\n",
      "batch 1676: loss 0.239710\n",
      "batch 1677: loss 0.115536\n",
      "batch 1678: loss 0.151467\n",
      "batch 1679: loss 0.054535\n",
      "batch 1680: loss 0.128105\n",
      "batch 1681: loss 0.069096\n",
      "batch 1682: loss 0.101729\n",
      "batch 1683: loss 0.092597\n",
      "batch 1684: loss 0.212010\n",
      "batch 1685: loss 0.109846\n",
      "batch 1686: loss 0.099597\n",
      "batch 1687: loss 0.096016\n",
      "batch 1688: loss 0.131640\n",
      "batch 1689: loss 0.208038\n",
      "batch 1690: loss 0.068692\n",
      "batch 1691: loss 0.076533\n",
      "batch 1692: loss 0.098760\n",
      "batch 1693: loss 0.063942\n",
      "batch 1694: loss 0.243592\n",
      "batch 1695: loss 0.044269\n",
      "batch 1696: loss 0.052832\n",
      "batch 1697: loss 0.108460\n",
      "batch 1698: loss 0.040842\n",
      "batch 1699: loss 0.253720\n",
      "batch 1700: loss 0.038712\n",
      "batch 1701: loss 0.025822\n",
      "batch 1702: loss 0.083721\n",
      "batch 1703: loss 0.163650\n",
      "batch 1704: loss 0.105909\n",
      "batch 1705: loss 0.069169\n",
      "batch 1706: loss 0.135131\n",
      "batch 1707: loss 0.044880\n",
      "batch 1708: loss 0.219776\n",
      "batch 1709: loss 0.065681\n",
      "batch 1710: loss 0.059462\n",
      "batch 1711: loss 0.136486\n",
      "batch 1712: loss 0.088871\n",
      "batch 1713: loss 0.112145\n",
      "batch 1714: loss 0.310449\n",
      "batch 1715: loss 0.167151\n",
      "batch 1716: loss 0.192173\n",
      "batch 1717: loss 0.125286\n",
      "batch 1718: loss 0.075812\n",
      "batch 1719: loss 0.111106\n",
      "batch 1720: loss 0.234431\n",
      "batch 1721: loss 0.164042\n",
      "batch 1722: loss 0.203600\n",
      "batch 1723: loss 0.092859\n",
      "batch 1724: loss 0.138958\n",
      "batch 1725: loss 0.147550\n",
      "batch 1726: loss 0.284736\n",
      "batch 1727: loss 0.194476\n",
      "batch 1728: loss 0.097891\n",
      "batch 1729: loss 0.134815\n",
      "batch 1730: loss 0.144310\n",
      "batch 1731: loss 0.041443\n",
      "batch 1732: loss 0.229653\n",
      "batch 1733: loss 0.081668\n",
      "batch 1734: loss 0.136015\n",
      "batch 1735: loss 0.326704\n",
      "batch 1736: loss 0.078652\n",
      "batch 1737: loss 0.215759\n",
      "batch 1738: loss 0.161411\n",
      "batch 1739: loss 0.195687\n",
      "batch 1740: loss 0.117957\n",
      "batch 1741: loss 0.082414\n",
      "batch 1742: loss 0.062406\n",
      "batch 1743: loss 0.135643\n",
      "batch 1744: loss 0.139715\n",
      "batch 1745: loss 0.240213\n",
      "batch 1746: loss 0.092292\n",
      "batch 1747: loss 0.107670\n",
      "batch 1748: loss 0.062676\n",
      "batch 1749: loss 0.063226\n",
      "batch 1750: loss 0.127958\n",
      "batch 1751: loss 0.060334\n",
      "batch 1752: loss 0.129882\n",
      "batch 1753: loss 0.116789\n",
      "batch 1754: loss 0.031783\n",
      "batch 1755: loss 0.134220\n",
      "batch 1756: loss 0.103625\n",
      "batch 1757: loss 0.101885\n",
      "batch 1758: loss 0.063688\n",
      "batch 1759: loss 0.096707\n",
      "batch 1760: loss 0.094153\n",
      "batch 1761: loss 0.119248\n",
      "batch 1762: loss 0.278772\n",
      "batch 1763: loss 0.144259\n",
      "batch 1764: loss 0.152414\n",
      "batch 1765: loss 0.068969\n",
      "batch 1766: loss 0.180881\n",
      "batch 1767: loss 0.168154\n",
      "batch 1768: loss 0.106025\n",
      "batch 1769: loss 0.102921\n",
      "batch 1770: loss 0.082657\n",
      "batch 1771: loss 0.151041\n",
      "batch 1772: loss 0.093181\n",
      "batch 1773: loss 0.068409\n",
      "batch 1774: loss 0.099578\n",
      "batch 1775: loss 0.083799\n",
      "batch 1776: loss 0.144007\n",
      "batch 1777: loss 0.152898\n",
      "batch 1778: loss 0.156907\n",
      "batch 1779: loss 0.118328\n",
      "batch 1780: loss 0.132892\n",
      "batch 1781: loss 0.142688\n",
      "batch 1782: loss 0.094910\n",
      "batch 1783: loss 0.115760\n",
      "batch 1784: loss 0.033111\n",
      "batch 1785: loss 0.152196\n",
      "batch 1786: loss 0.147023\n",
      "batch 1787: loss 0.098747\n",
      "batch 1788: loss 0.092640\n",
      "batch 1789: loss 0.170873\n",
      "batch 1790: loss 0.118104\n",
      "batch 1791: loss 0.061209\n",
      "batch 1792: loss 0.228339\n",
      "batch 1793: loss 0.165529\n",
      "batch 1794: loss 0.087423\n",
      "batch 1795: loss 0.066183\n",
      "batch 1796: loss 0.073099\n",
      "batch 1797: loss 0.196878\n",
      "batch 1798: loss 0.147096\n",
      "batch 1799: loss 0.050252\n",
      "batch 1800: loss 0.069176\n",
      "batch 1801: loss 0.203241\n",
      "batch 1802: loss 0.036928\n",
      "batch 1803: loss 0.130913\n",
      "batch 1804: loss 0.097803\n",
      "batch 1805: loss 0.197442\n",
      "batch 1806: loss 0.186302\n",
      "batch 1807: loss 0.063758\n",
      "batch 1808: loss 0.137301\n",
      "batch 1809: loss 0.112924\n",
      "batch 1810: loss 0.111217\n",
      "batch 1811: loss 0.053932\n",
      "batch 1812: loss 0.176203\n",
      "batch 1813: loss 0.087164\n",
      "batch 1814: loss 0.102821\n",
      "batch 1815: loss 0.069368\n",
      "batch 1816: loss 0.126558\n",
      "batch 1817: loss 0.103376\n",
      "batch 1818: loss 0.204159\n",
      "batch 1819: loss 0.158446\n",
      "batch 1820: loss 0.092415\n",
      "batch 1821: loss 0.256569\n",
      "batch 1822: loss 0.229648\n",
      "batch 1823: loss 0.133930\n",
      "batch 1824: loss 0.090082\n",
      "batch 1825: loss 0.038799\n",
      "batch 1826: loss 0.226912\n",
      "batch 1827: loss 0.156040\n",
      "batch 1828: loss 0.055717\n",
      "batch 1829: loss 0.063494\n",
      "batch 1830: loss 0.115705\n",
      "batch 1831: loss 0.082887\n",
      "batch 1832: loss 0.213216\n",
      "batch 1833: loss 0.067648\n",
      "batch 1834: loss 0.171484\n",
      "batch 1835: loss 0.067083\n",
      "batch 1836: loss 0.192005\n",
      "batch 1837: loss 0.268526\n",
      "batch 1838: loss 0.049909\n",
      "batch 1839: loss 0.100392\n",
      "batch 1840: loss 0.214680\n",
      "batch 1841: loss 0.035819\n",
      "batch 1842: loss 0.186920\n",
      "batch 1843: loss 0.058617\n",
      "batch 1844: loss 0.142895\n",
      "batch 1845: loss 0.084470\n",
      "batch 1846: loss 0.262261\n",
      "batch 1847: loss 0.052112\n",
      "batch 1848: loss 0.064020\n",
      "batch 1849: loss 0.212836\n",
      "batch 1850: loss 0.049934\n",
      "batch 1851: loss 0.129121\n",
      "batch 1852: loss 0.217565\n",
      "batch 1853: loss 0.081559\n",
      "batch 1854: loss 0.091158\n",
      "batch 1855: loss 0.197932\n",
      "batch 1856: loss 0.021552\n",
      "batch 1857: loss 0.093305\n",
      "batch 1858: loss 0.113708\n",
      "batch 1859: loss 0.138309\n",
      "batch 1860: loss 0.140363\n",
      "batch 1861: loss 0.131826\n",
      "batch 1862: loss 0.132121\n",
      "batch 1863: loss 0.060334\n",
      "batch 1864: loss 0.194240\n",
      "batch 1865: loss 0.092220\n",
      "batch 1866: loss 0.166756\n",
      "batch 1867: loss 0.390300\n",
      "batch 1868: loss 0.160181\n",
      "batch 1869: loss 0.099785\n",
      "batch 1870: loss 0.194880\n",
      "batch 1871: loss 0.117256\n",
      "batch 1872: loss 0.118226\n",
      "batch 1873: loss 0.267408\n",
      "batch 1874: loss 0.071780\n",
      "batch 1875: loss 0.075355\n",
      "batch 1876: loss 0.122592\n",
      "batch 1877: loss 0.100411\n",
      "batch 1878: loss 0.129842\n",
      "batch 1879: loss 0.201067\n",
      "batch 1880: loss 0.128684\n",
      "batch 1881: loss 0.137603\n",
      "batch 1882: loss 0.039026\n",
      "batch 1883: loss 0.218476\n",
      "batch 1884: loss 0.239713\n",
      "batch 1885: loss 0.149450\n",
      "batch 1886: loss 0.175430\n",
      "batch 1887: loss 0.056153\n",
      "batch 1888: loss 0.125062\n",
      "batch 1889: loss 0.071914\n",
      "batch 1890: loss 0.152274\n",
      "batch 1891: loss 0.014591\n",
      "batch 1892: loss 0.072724\n",
      "batch 1893: loss 0.156443\n",
      "batch 1894: loss 0.189746\n",
      "batch 1895: loss 0.028288\n",
      "batch 1896: loss 0.077249\n",
      "batch 1897: loss 0.134022\n",
      "batch 1898: loss 0.072183\n",
      "batch 1899: loss 0.140522\n",
      "batch 1900: loss 0.097722\n",
      "batch 1901: loss 0.085176\n",
      "batch 1902: loss 0.105364\n",
      "batch 1903: loss 0.136102\n",
      "batch 1904: loss 0.239156\n",
      "batch 1905: loss 0.088580\n",
      "batch 1906: loss 0.051166\n",
      "batch 1907: loss 0.325839\n",
      "batch 1908: loss 0.290493\n",
      "batch 1909: loss 0.069662\n",
      "batch 1910: loss 0.170541\n",
      "batch 1911: loss 0.142531\n",
      "batch 1912: loss 0.082697\n",
      "batch 1913: loss 0.118181\n",
      "batch 1914: loss 0.044367\n",
      "batch 1915: loss 0.136438\n",
      "batch 1916: loss 0.092736\n",
      "batch 1917: loss 0.213565\n",
      "batch 1918: loss 0.261681\n",
      "batch 1919: loss 0.062642\n",
      "batch 1920: loss 0.097440\n",
      "batch 1921: loss 0.137778\n",
      "batch 1922: loss 0.137052\n",
      "batch 1923: loss 0.187684\n",
      "batch 1924: loss 0.098832\n",
      "batch 1925: loss 0.143678\n",
      "batch 1926: loss 0.131511\n",
      "batch 1927: loss 0.242860\n",
      "batch 1928: loss 0.189627\n",
      "batch 1929: loss 0.110518\n",
      "batch 1930: loss 0.096928\n",
      "batch 1931: loss 0.146408\n",
      "batch 1932: loss 0.058977\n",
      "batch 1933: loss 0.094491\n",
      "batch 1934: loss 0.070952\n",
      "batch 1935: loss 0.228524\n",
      "batch 1936: loss 0.196002\n",
      "batch 1937: loss 0.164590\n",
      "batch 1938: loss 0.161769\n",
      "batch 1939: loss 0.046630\n",
      "batch 1940: loss 0.159400\n",
      "batch 1941: loss 0.051636\n",
      "batch 1942: loss 0.035414\n",
      "batch 1943: loss 0.185417\n",
      "batch 1944: loss 0.115254\n",
      "batch 1945: loss 0.068971\n",
      "batch 1946: loss 0.195112\n",
      "batch 1947: loss 0.124013\n",
      "batch 1948: loss 0.148067\n",
      "batch 1949: loss 0.189090\n",
      "batch 1950: loss 0.041746\n",
      "batch 1951: loss 0.207342\n",
      "batch 1952: loss 0.142572\n",
      "batch 1953: loss 0.233948\n",
      "batch 1954: loss 0.163982\n",
      "batch 1955: loss 0.091790\n",
      "batch 1956: loss 0.060254\n",
      "batch 1957: loss 0.078012\n",
      "batch 1958: loss 0.153274\n",
      "batch 1959: loss 0.078138\n",
      "batch 1960: loss 0.106900\n",
      "batch 1961: loss 0.098520\n",
      "batch 1962: loss 0.126850\n",
      "batch 1963: loss 0.089210\n",
      "batch 1964: loss 0.130219\n",
      "batch 1965: loss 0.111980\n",
      "batch 1966: loss 0.075417\n",
      "batch 1967: loss 0.118425\n",
      "batch 1968: loss 0.108560\n",
      "batch 1969: loss 0.047347\n",
      "batch 1970: loss 0.067555\n",
      "batch 1971: loss 0.063418\n",
      "batch 1972: loss 0.132103\n",
      "batch 1973: loss 0.152191\n",
      "batch 1974: loss 0.223677\n",
      "batch 1975: loss 0.087661\n",
      "batch 1976: loss 0.182563\n",
      "batch 1977: loss 0.114541\n",
      "batch 1978: loss 0.053410\n",
      "batch 1979: loss 0.151995\n",
      "batch 1980: loss 0.109893\n",
      "batch 1981: loss 0.181975\n",
      "batch 1982: loss 0.070298\n",
      "batch 1983: loss 0.040586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1984: loss 0.338069\n",
      "batch 1985: loss 0.205374\n",
      "batch 1986: loss 0.151513\n",
      "batch 1987: loss 0.050275\n",
      "batch 1988: loss 0.128089\n",
      "batch 1989: loss 0.052899\n",
      "batch 1990: loss 0.048594\n",
      "batch 1991: loss 0.138203\n",
      "batch 1992: loss 0.255534\n",
      "batch 1993: loss 0.034887\n",
      "batch 1994: loss 0.138710\n",
      "batch 1995: loss 0.042140\n",
      "batch 1996: loss 0.139347\n",
      "batch 1997: loss 0.076639\n",
      "batch 1998: loss 0.028242\n",
      "batch 1999: loss 0.100571\n",
      "batch 2000: loss 0.059984\n",
      "batch 2001: loss 0.013961\n",
      "batch 2002: loss 0.029169\n",
      "batch 2003: loss 0.150681\n",
      "batch 2004: loss 0.162718\n",
      "batch 2005: loss 0.126981\n",
      "batch 2006: loss 0.135012\n",
      "batch 2007: loss 0.303735\n",
      "batch 2008: loss 0.055750\n",
      "batch 2009: loss 0.075356\n",
      "batch 2010: loss 0.063354\n",
      "batch 2011: loss 0.108537\n",
      "batch 2012: loss 0.223870\n",
      "batch 2013: loss 0.077912\n",
      "batch 2014: loss 0.190934\n",
      "batch 2015: loss 0.101485\n",
      "batch 2016: loss 0.122152\n",
      "batch 2017: loss 0.139718\n",
      "batch 2018: loss 0.100245\n",
      "batch 2019: loss 0.106153\n",
      "batch 2020: loss 0.061081\n",
      "batch 2021: loss 0.058454\n",
      "batch 2022: loss 0.217817\n",
      "batch 2023: loss 0.162904\n",
      "batch 2024: loss 0.072670\n",
      "batch 2025: loss 0.094059\n",
      "batch 2026: loss 0.091782\n",
      "batch 2027: loss 0.121702\n",
      "batch 2028: loss 0.341301\n",
      "batch 2029: loss 0.159656\n",
      "batch 2030: loss 0.057429\n",
      "batch 2031: loss 0.046250\n",
      "batch 2032: loss 0.180814\n",
      "batch 2033: loss 0.057538\n",
      "batch 2034: loss 0.034271\n",
      "batch 2035: loss 0.213563\n",
      "batch 2036: loss 0.093480\n",
      "batch 2037: loss 0.068100\n",
      "batch 2038: loss 0.163155\n",
      "batch 2039: loss 0.113828\n",
      "batch 2040: loss 0.103902\n",
      "batch 2041: loss 0.058016\n",
      "batch 2042: loss 0.424676\n",
      "batch 2043: loss 0.074639\n",
      "batch 2044: loss 0.026728\n",
      "batch 2045: loss 0.080617\n",
      "batch 2046: loss 0.046850\n",
      "batch 2047: loss 0.099981\n",
      "batch 2048: loss 0.135459\n",
      "batch 2049: loss 0.049663\n",
      "batch 2050: loss 0.164997\n",
      "batch 2051: loss 0.092386\n",
      "batch 2052: loss 0.066758\n",
      "batch 2053: loss 0.058832\n",
      "batch 2054: loss 0.032314\n",
      "batch 2055: loss 0.059439\n",
      "batch 2056: loss 0.052143\n",
      "batch 2057: loss 0.086947\n",
      "batch 2058: loss 0.045807\n",
      "batch 2059: loss 0.296448\n",
      "batch 2060: loss 0.149462\n",
      "batch 2061: loss 0.121399\n",
      "batch 2062: loss 0.123121\n",
      "batch 2063: loss 0.139921\n",
      "batch 2064: loss 0.059135\n",
      "batch 2065: loss 0.077735\n",
      "batch 2066: loss 0.055216\n",
      "batch 2067: loss 0.099636\n",
      "batch 2068: loss 0.104053\n",
      "batch 2069: loss 0.050710\n",
      "batch 2070: loss 0.040739\n",
      "batch 2071: loss 0.051796\n",
      "batch 2072: loss 0.082199\n",
      "batch 2073: loss 0.036833\n",
      "batch 2074: loss 0.182812\n",
      "batch 2075: loss 0.164545\n",
      "batch 2076: loss 0.137669\n",
      "batch 2077: loss 0.025829\n",
      "batch 2078: loss 0.142870\n",
      "batch 2079: loss 0.334119\n",
      "batch 2080: loss 0.087786\n",
      "batch 2081: loss 0.107246\n",
      "batch 2082: loss 0.272170\n",
      "batch 2083: loss 0.033973\n",
      "batch 2084: loss 0.056906\n",
      "batch 2085: loss 0.034313\n",
      "batch 2086: loss 0.261658\n",
      "batch 2087: loss 0.247424\n",
      "batch 2088: loss 0.042562\n",
      "batch 2089: loss 0.113490\n",
      "batch 2090: loss 0.021424\n",
      "batch 2091: loss 0.080314\n",
      "batch 2092: loss 0.044960\n",
      "batch 2093: loss 0.090340\n",
      "batch 2094: loss 0.160813\n",
      "batch 2095: loss 0.097450\n",
      "batch 2096: loss 0.037478\n",
      "batch 2097: loss 0.053179\n",
      "batch 2098: loss 0.059674\n",
      "batch 2099: loss 0.031931\n",
      "batch 2100: loss 0.061893\n",
      "batch 2101: loss 0.246680\n",
      "batch 2102: loss 0.203494\n",
      "batch 2103: loss 0.084296\n",
      "batch 2104: loss 0.100256\n",
      "batch 2105: loss 0.142557\n",
      "batch 2106: loss 0.103518\n",
      "batch 2107: loss 0.140085\n",
      "batch 2108: loss 0.122146\n",
      "batch 2109: loss 0.058820\n",
      "batch 2110: loss 0.110388\n",
      "batch 2111: loss 0.191142\n",
      "batch 2112: loss 0.319823\n",
      "batch 2113: loss 0.027741\n",
      "batch 2114: loss 0.062882\n",
      "batch 2115: loss 0.198788\n",
      "batch 2116: loss 0.120302\n",
      "batch 2117: loss 0.108999\n",
      "batch 2118: loss 0.233126\n",
      "batch 2119: loss 0.080510\n",
      "batch 2120: loss 0.066123\n",
      "batch 2121: loss 0.022899\n",
      "batch 2122: loss 0.224323\n",
      "batch 2123: loss 0.030687\n",
      "batch 2124: loss 0.138010\n",
      "batch 2125: loss 0.151065\n",
      "batch 2126: loss 0.020350\n",
      "batch 2127: loss 0.076584\n",
      "batch 2128: loss 0.144541\n",
      "batch 2129: loss 0.232480\n",
      "batch 2130: loss 0.072627\n",
      "batch 2131: loss 0.059912\n",
      "batch 2132: loss 0.201383\n",
      "batch 2133: loss 0.041199\n",
      "batch 2134: loss 0.191832\n",
      "batch 2135: loss 0.046434\n",
      "batch 2136: loss 0.136724\n",
      "batch 2137: loss 0.110709\n",
      "batch 2138: loss 0.065550\n",
      "batch 2139: loss 0.338608\n",
      "batch 2140: loss 0.288447\n",
      "batch 2141: loss 0.024836\n",
      "batch 2142: loss 0.217027\n",
      "batch 2143: loss 0.273812\n",
      "batch 2144: loss 0.234186\n",
      "batch 2145: loss 0.104250\n",
      "batch 2146: loss 0.129356\n",
      "batch 2147: loss 0.046217\n",
      "batch 2148: loss 0.111440\n",
      "batch 2149: loss 0.103302\n",
      "batch 2150: loss 0.174581\n",
      "batch 2151: loss 0.128757\n",
      "batch 2152: loss 0.058520\n",
      "batch 2153: loss 0.063212\n",
      "batch 2154: loss 0.070138\n",
      "batch 2155: loss 0.257373\n",
      "batch 2156: loss 0.085199\n",
      "batch 2157: loss 0.266634\n",
      "batch 2158: loss 0.164454\n",
      "batch 2159: loss 0.031205\n",
      "batch 2160: loss 0.030924\n",
      "batch 2161: loss 0.154545\n",
      "batch 2162: loss 0.151450\n",
      "batch 2163: loss 0.190468\n",
      "batch 2164: loss 0.484718\n",
      "batch 2165: loss 0.121968\n",
      "batch 2166: loss 0.116923\n",
      "batch 2167: loss 0.064973\n",
      "batch 2168: loss 0.040733\n",
      "batch 2169: loss 0.042419\n",
      "batch 2170: loss 0.111429\n",
      "batch 2171: loss 0.096115\n",
      "batch 2172: loss 0.086301\n",
      "batch 2173: loss 0.131586\n",
      "batch 2174: loss 0.078819\n",
      "batch 2175: loss 0.020429\n",
      "batch 2176: loss 0.142868\n",
      "batch 2177: loss 0.159621\n",
      "batch 2178: loss 0.149287\n",
      "batch 2179: loss 0.170916\n",
      "batch 2180: loss 0.095504\n",
      "batch 2181: loss 0.086378\n",
      "batch 2182: loss 0.084463\n",
      "batch 2183: loss 0.135761\n",
      "batch 2184: loss 0.031105\n",
      "batch 2185: loss 0.049883\n",
      "batch 2186: loss 0.058845\n",
      "batch 2187: loss 0.080247\n",
      "batch 2188: loss 0.049414\n",
      "batch 2189: loss 0.109263\n",
      "batch 2190: loss 0.139860\n",
      "batch 2191: loss 0.060836\n",
      "batch 2192: loss 0.210907\n",
      "batch 2193: loss 0.036212\n",
      "batch 2194: loss 0.070829\n",
      "batch 2195: loss 0.130147\n",
      "batch 2196: loss 0.112893\n",
      "batch 2197: loss 0.199129\n",
      "batch 2198: loss 0.190292\n",
      "batch 2199: loss 0.135161\n",
      "batch 2200: loss 0.048662\n",
      "batch 2201: loss 0.014739\n",
      "batch 2202: loss 0.160372\n",
      "batch 2203: loss 0.307645\n",
      "batch 2204: loss 0.067192\n",
      "batch 2205: loss 0.048185\n",
      "batch 2206: loss 0.105436\n",
      "batch 2207: loss 0.040441\n",
      "batch 2208: loss 0.110374\n",
      "batch 2209: loss 0.106182\n",
      "batch 2210: loss 0.120494\n",
      "batch 2211: loss 0.113155\n",
      "batch 2212: loss 0.091827\n",
      "batch 2213: loss 0.129862\n",
      "batch 2214: loss 0.116093\n",
      "batch 2215: loss 0.097962\n",
      "batch 2216: loss 0.197441\n",
      "batch 2217: loss 0.152115\n",
      "batch 2218: loss 0.028498\n",
      "batch 2219: loss 0.076947\n",
      "batch 2220: loss 0.050166\n",
      "batch 2221: loss 0.034634\n",
      "batch 2222: loss 0.057118\n",
      "batch 2223: loss 0.067992\n",
      "batch 2224: loss 0.071718\n",
      "batch 2225: loss 0.131293\n",
      "batch 2226: loss 0.046650\n",
      "batch 2227: loss 0.016715\n",
      "batch 2228: loss 0.109208\n",
      "batch 2229: loss 0.133306\n",
      "batch 2230: loss 0.251320\n",
      "batch 2231: loss 0.142667\n",
      "batch 2232: loss 0.085924\n",
      "batch 2233: loss 0.048783\n",
      "batch 2234: loss 0.184539\n",
      "batch 2235: loss 0.145093\n",
      "batch 2236: loss 0.033535\n",
      "batch 2237: loss 0.074208\n",
      "batch 2238: loss 0.093431\n",
      "batch 2239: loss 0.154783\n",
      "batch 2240: loss 0.086974\n",
      "batch 2241: loss 0.225466\n",
      "batch 2242: loss 0.104601\n",
      "batch 2243: loss 0.036424\n",
      "batch 2244: loss 0.016906\n",
      "batch 2245: loss 0.016584\n",
      "batch 2246: loss 0.118773\n",
      "batch 2247: loss 0.078055\n",
      "batch 2248: loss 0.186283\n",
      "batch 2249: loss 0.130133\n",
      "batch 2250: loss 0.105279\n",
      "batch 2251: loss 0.065666\n",
      "batch 2252: loss 0.192500\n",
      "batch 2253: loss 0.070752\n",
      "batch 2254: loss 0.043830\n",
      "batch 2255: loss 0.024066\n",
      "batch 2256: loss 0.139529\n",
      "batch 2257: loss 0.090541\n",
      "batch 2258: loss 0.149134\n",
      "batch 2259: loss 0.180870\n",
      "batch 2260: loss 0.052318\n",
      "batch 2261: loss 0.109607\n",
      "batch 2262: loss 0.207442\n",
      "batch 2263: loss 0.227842\n",
      "batch 2264: loss 0.269867\n",
      "batch 2265: loss 0.031744\n",
      "batch 2266: loss 0.121556\n",
      "batch 2267: loss 0.024622\n",
      "batch 2268: loss 0.101373\n",
      "batch 2269: loss 0.054118\n",
      "batch 2270: loss 0.077847\n",
      "batch 2271: loss 0.122040\n",
      "batch 2272: loss 0.060324\n",
      "batch 2273: loss 0.151471\n",
      "batch 2274: loss 0.106956\n",
      "batch 2275: loss 0.423731\n",
      "batch 2276: loss 0.095553\n",
      "batch 2277: loss 0.049545\n",
      "batch 2278: loss 0.026500\n",
      "batch 2279: loss 0.096567\n",
      "batch 2280: loss 0.068413\n",
      "batch 2281: loss 0.032984\n",
      "batch 2282: loss 0.042308\n",
      "batch 2283: loss 0.148053\n",
      "batch 2284: loss 0.104368\n",
      "batch 2285: loss 0.078545\n",
      "batch 2286: loss 0.110316\n",
      "batch 2287: loss 0.152431\n",
      "batch 2288: loss 0.125643\n",
      "batch 2289: loss 0.090097\n",
      "batch 2290: loss 0.039578\n",
      "batch 2291: loss 0.297471\n",
      "batch 2292: loss 0.072755\n",
      "batch 2293: loss 0.068335\n",
      "batch 2294: loss 0.125745\n",
      "batch 2295: loss 0.020157\n",
      "batch 2296: loss 0.109046\n",
      "batch 2297: loss 0.063395\n",
      "batch 2298: loss 0.086390\n",
      "batch 2299: loss 0.120597\n",
      "batch 2300: loss 0.146528\n",
      "batch 2301: loss 0.129306\n",
      "batch 2302: loss 0.058377\n",
      "batch 2303: loss 0.029163\n",
      "batch 2304: loss 0.068741\n",
      "batch 2305: loss 0.188238\n",
      "batch 2306: loss 0.290826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2307: loss 0.085654\n",
      "batch 2308: loss 0.048532\n",
      "batch 2309: loss 0.098790\n",
      "batch 2310: loss 0.214955\n",
      "batch 2311: loss 0.079815\n",
      "batch 2312: loss 0.038442\n",
      "batch 2313: loss 0.051276\n",
      "batch 2314: loss 0.077344\n",
      "batch 2315: loss 0.145799\n",
      "batch 2316: loss 0.148183\n",
      "batch 2317: loss 0.102565\n",
      "batch 2318: loss 0.014244\n",
      "batch 2319: loss 0.128690\n",
      "batch 2320: loss 0.095857\n",
      "batch 2321: loss 0.063952\n",
      "batch 2322: loss 0.048430\n",
      "batch 2323: loss 0.049694\n",
      "batch 2324: loss 0.128550\n",
      "batch 2325: loss 0.024017\n",
      "batch 2326: loss 0.084360\n",
      "batch 2327: loss 0.129401\n",
      "batch 2328: loss 0.077026\n",
      "batch 2329: loss 0.148490\n",
      "batch 2330: loss 0.075023\n",
      "batch 2331: loss 0.053520\n",
      "batch 2332: loss 0.072578\n",
      "batch 2333: loss 0.079242\n",
      "batch 2334: loss 0.018953\n",
      "batch 2335: loss 0.051816\n",
      "batch 2336: loss 0.134985\n",
      "batch 2337: loss 0.027085\n",
      "batch 2338: loss 0.056548\n",
      "batch 2339: loss 0.109317\n",
      "batch 2340: loss 0.063402\n",
      "batch 2341: loss 0.097704\n",
      "batch 2342: loss 0.039748\n",
      "batch 2343: loss 0.105427\n",
      "batch 2344: loss 0.018795\n",
      "batch 2345: loss 0.113688\n",
      "batch 2346: loss 0.161307\n",
      "batch 2347: loss 0.150538\n",
      "batch 2348: loss 0.034437\n",
      "batch 2349: loss 0.183291\n",
      "batch 2350: loss 0.054346\n",
      "batch 2351: loss 0.393810\n",
      "batch 2352: loss 0.137696\n",
      "batch 2353: loss 0.040447\n",
      "batch 2354: loss 0.139464\n",
      "batch 2355: loss 0.192859\n",
      "batch 2356: loss 0.042862\n",
      "batch 2357: loss 0.100200\n",
      "batch 2358: loss 0.035845\n",
      "batch 2359: loss 0.024372\n",
      "batch 2360: loss 0.088841\n",
      "batch 2361: loss 0.129113\n",
      "batch 2362: loss 0.030142\n",
      "batch 2363: loss 0.040950\n",
      "batch 2364: loss 0.115777\n",
      "batch 2365: loss 0.080595\n",
      "batch 2366: loss 0.035177\n",
      "batch 2367: loss 0.076720\n",
      "batch 2368: loss 0.076276\n",
      "batch 2369: loss 0.042681\n",
      "batch 2370: loss 0.045781\n",
      "batch 2371: loss 0.169086\n",
      "batch 2372: loss 0.083923\n",
      "batch 2373: loss 0.047691\n",
      "batch 2374: loss 0.058619\n",
      "batch 2375: loss 0.125597\n",
      "batch 2376: loss 0.169298\n",
      "batch 2377: loss 0.074123\n",
      "batch 2378: loss 0.095751\n",
      "batch 2379: loss 0.071551\n",
      "batch 2380: loss 0.035452\n",
      "batch 2381: loss 0.083752\n",
      "batch 2382: loss 0.147892\n",
      "batch 2383: loss 0.137774\n",
      "batch 2384: loss 0.072213\n",
      "batch 2385: loss 0.045253\n",
      "batch 2386: loss 0.079198\n",
      "batch 2387: loss 0.067759\n",
      "batch 2388: loss 0.054600\n",
      "batch 2389: loss 0.051407\n",
      "batch 2390: loss 0.030402\n",
      "batch 2391: loss 0.044807\n",
      "batch 2392: loss 0.053247\n",
      "batch 2393: loss 0.018761\n",
      "batch 2394: loss 0.067390\n",
      "batch 2395: loss 0.050070\n",
      "batch 2396: loss 0.080529\n",
      "batch 2397: loss 0.047625\n",
      "batch 2398: loss 0.043882\n",
      "batch 2399: loss 0.143563\n",
      "batch 2400: loss 0.057695\n",
      "batch 2401: loss 0.099146\n",
      "batch 2402: loss 0.020900\n",
      "batch 2403: loss 0.027030\n",
      "batch 2404: loss 0.072570\n",
      "batch 2405: loss 0.173703\n",
      "batch 2406: loss 0.034262\n",
      "batch 2407: loss 0.247426\n",
      "batch 2408: loss 0.233648\n",
      "batch 2409: loss 0.079286\n",
      "batch 2410: loss 0.109328\n",
      "batch 2411: loss 0.028701\n",
      "batch 2412: loss 0.287472\n",
      "batch 2413: loss 0.127775\n",
      "batch 2414: loss 0.066500\n",
      "batch 2415: loss 0.127833\n",
      "batch 2416: loss 0.093222\n",
      "batch 2417: loss 0.038604\n",
      "batch 2418: loss 0.053902\n",
      "batch 2419: loss 0.097639\n",
      "batch 2420: loss 0.038131\n",
      "batch 2421: loss 0.176360\n",
      "batch 2422: loss 0.033192\n",
      "batch 2423: loss 0.037537\n",
      "batch 2424: loss 0.100616\n",
      "batch 2425: loss 0.219857\n",
      "batch 2426: loss 0.046500\n",
      "batch 2427: loss 0.111785\n",
      "batch 2428: loss 0.068753\n",
      "batch 2429: loss 0.183020\n",
      "batch 2430: loss 0.112531\n",
      "batch 2431: loss 0.065667\n",
      "batch 2432: loss 0.092719\n",
      "batch 2433: loss 0.145302\n",
      "batch 2434: loss 0.025270\n",
      "batch 2435: loss 0.062651\n",
      "batch 2436: loss 0.051889\n",
      "batch 2437: loss 0.083402\n",
      "batch 2438: loss 0.046851\n",
      "batch 2439: loss 0.107638\n",
      "batch 2440: loss 0.294015\n",
      "batch 2441: loss 0.245502\n",
      "batch 2442: loss 0.184865\n",
      "batch 2443: loss 0.077554\n",
      "batch 2444: loss 0.226409\n",
      "batch 2445: loss 0.063611\n",
      "batch 2446: loss 0.244562\n",
      "batch 2447: loss 0.070889\n",
      "batch 2448: loss 0.066911\n",
      "batch 2449: loss 0.042451\n",
      "batch 2450: loss 0.049487\n",
      "batch 2451: loss 0.072486\n",
      "batch 2452: loss 0.130108\n",
      "batch 2453: loss 0.067020\n",
      "batch 2454: loss 0.066002\n",
      "batch 2455: loss 0.041846\n",
      "batch 2456: loss 0.029741\n",
      "batch 2457: loss 0.024809\n",
      "batch 2458: loss 0.162502\n",
      "batch 2459: loss 0.191604\n",
      "batch 2460: loss 0.061446\n",
      "batch 2461: loss 0.146538\n",
      "batch 2462: loss 0.020924\n",
      "batch 2463: loss 0.031916\n",
      "batch 2464: loss 0.065864\n",
      "batch 2465: loss 0.107510\n",
      "batch 2466: loss 0.216214\n",
      "batch 2467: loss 0.064125\n",
      "batch 2468: loss 0.058867\n",
      "batch 2469: loss 0.112253\n",
      "batch 2470: loss 0.026202\n",
      "batch 2471: loss 0.037899\n",
      "batch 2472: loss 0.167505\n",
      "batch 2473: loss 0.073393\n",
      "batch 2474: loss 0.095435\n",
      "batch 2475: loss 0.130822\n",
      "batch 2476: loss 0.014837\n",
      "batch 2477: loss 0.237290\n",
      "batch 2478: loss 0.101447\n",
      "batch 2479: loss 0.017080\n",
      "batch 2480: loss 0.076833\n",
      "batch 2481: loss 0.091382\n",
      "batch 2482: loss 0.128380\n",
      "batch 2483: loss 0.079307\n",
      "batch 2484: loss 0.119056\n",
      "batch 2485: loss 0.037895\n",
      "batch 2486: loss 0.075560\n",
      "batch 2487: loss 0.128484\n",
      "batch 2488: loss 0.051493\n",
      "batch 2489: loss 0.042693\n",
      "batch 2490: loss 0.041837\n",
      "batch 2491: loss 0.037666\n",
      "batch 2492: loss 0.045183\n",
      "batch 2493: loss 0.045188\n",
      "batch 2494: loss 0.018403\n",
      "batch 2495: loss 0.044385\n",
      "batch 2496: loss 0.071648\n",
      "batch 2497: loss 0.019982\n",
      "batch 2498: loss 0.138896\n",
      "batch 2499: loss 0.033366\n",
      "batch 2500: loss 0.019225\n",
      "batch 2501: loss 0.140002\n",
      "batch 2502: loss 0.095073\n",
      "batch 2503: loss 0.009877\n",
      "batch 2504: loss 0.118133\n",
      "batch 2505: loss 0.102856\n",
      "batch 2506: loss 0.074004\n",
      "batch 2507: loss 0.069932\n",
      "batch 2508: loss 0.038781\n",
      "batch 2509: loss 0.019154\n",
      "batch 2510: loss 0.247626\n",
      "batch 2511: loss 0.071022\n",
      "batch 2512: loss 0.021364\n",
      "batch 2513: loss 0.095693\n",
      "batch 2514: loss 0.069203\n",
      "batch 2515: loss 0.068909\n",
      "batch 2516: loss 0.060970\n",
      "batch 2517: loss 0.136949\n",
      "batch 2518: loss 0.105739\n",
      "batch 2519: loss 0.024836\n",
      "batch 2520: loss 0.025609\n",
      "batch 2521: loss 0.156193\n",
      "batch 2522: loss 0.068337\n",
      "batch 2523: loss 0.080917\n",
      "batch 2524: loss 0.225862\n",
      "batch 2525: loss 0.089142\n",
      "batch 2526: loss 0.048765\n",
      "batch 2527: loss 0.042159\n",
      "batch 2528: loss 0.035680\n",
      "batch 2529: loss 0.045392\n",
      "batch 2530: loss 0.207631\n",
      "batch 2531: loss 0.067667\n",
      "batch 2532: loss 0.026995\n",
      "batch 2533: loss 0.210261\n",
      "batch 2534: loss 0.192968\n",
      "batch 2535: loss 0.043982\n",
      "batch 2536: loss 0.149269\n",
      "batch 2537: loss 0.132389\n",
      "batch 2538: loss 0.024634\n",
      "batch 2539: loss 0.047800\n",
      "batch 2540: loss 0.134962\n",
      "batch 2541: loss 0.201313\n",
      "batch 2542: loss 0.181833\n",
      "batch 2543: loss 0.182665\n",
      "batch 2544: loss 0.074304\n",
      "batch 2545: loss 0.090758\n",
      "batch 2546: loss 0.062916\n",
      "batch 2547: loss 0.120337\n",
      "batch 2548: loss 0.204157\n",
      "batch 2549: loss 0.139080\n",
      "batch 2550: loss 0.048812\n",
      "batch 2551: loss 0.118324\n",
      "batch 2552: loss 0.136136\n",
      "batch 2553: loss 0.048456\n",
      "batch 2554: loss 0.134603\n",
      "batch 2555: loss 0.066520\n",
      "batch 2556: loss 0.082664\n",
      "batch 2557: loss 0.151750\n",
      "batch 2558: loss 0.025588\n",
      "batch 2559: loss 0.031982\n",
      "batch 2560: loss 0.145522\n",
      "batch 2561: loss 0.030476\n",
      "batch 2562: loss 0.084469\n",
      "batch 2563: loss 0.113581\n",
      "batch 2564: loss 0.043345\n",
      "batch 2565: loss 0.063713\n",
      "batch 2566: loss 0.467955\n",
      "batch 2567: loss 0.099103\n",
      "batch 2568: loss 0.026414\n",
      "batch 2569: loss 0.117247\n",
      "batch 2570: loss 0.086771\n",
      "batch 2571: loss 0.081179\n",
      "batch 2572: loss 0.205831\n",
      "batch 2573: loss 0.157906\n",
      "batch 2574: loss 0.210084\n",
      "batch 2575: loss 0.164971\n",
      "batch 2576: loss 0.060260\n",
      "batch 2577: loss 0.068453\n",
      "batch 2578: loss 0.079219\n",
      "batch 2579: loss 0.168395\n",
      "batch 2580: loss 0.098310\n",
      "batch 2581: loss 0.051278\n",
      "batch 2582: loss 0.081368\n",
      "batch 2583: loss 0.065991\n",
      "batch 2584: loss 0.092811\n",
      "batch 2585: loss 0.072426\n",
      "batch 2586: loss 0.191927\n",
      "batch 2587: loss 0.027190\n",
      "batch 2588: loss 0.159959\n",
      "batch 2589: loss 0.235324\n",
      "batch 2590: loss 0.041458\n",
      "batch 2591: loss 0.052236\n",
      "batch 2592: loss 0.072737\n",
      "batch 2593: loss 0.129714\n",
      "batch 2594: loss 0.076233\n",
      "batch 2595: loss 0.130348\n",
      "batch 2596: loss 0.202972\n",
      "batch 2597: loss 0.130727\n",
      "batch 2598: loss 0.117001\n",
      "batch 2599: loss 0.042062\n",
      "batch 2600: loss 0.062199\n",
      "batch 2601: loss 0.238742\n",
      "batch 2602: loss 0.082617\n",
      "batch 2603: loss 0.191609\n",
      "batch 2604: loss 0.131025\n",
      "batch 2605: loss 0.116421\n",
      "batch 2606: loss 0.174659\n",
      "batch 2607: loss 0.171810\n",
      "batch 2608: loss 0.115636\n",
      "batch 2609: loss 0.096603\n",
      "batch 2610: loss 0.212644\n",
      "batch 2611: loss 0.142373\n",
      "batch 2612: loss 0.030974\n",
      "batch 2613: loss 0.069144\n",
      "batch 2614: loss 0.033948\n",
      "batch 2615: loss 0.179655\n",
      "batch 2616: loss 0.025176\n",
      "batch 2617: loss 0.281859\n",
      "batch 2618: loss 0.017982\n",
      "batch 2619: loss 0.114914\n",
      "batch 2620: loss 0.085564\n",
      "batch 2621: loss 0.020380\n",
      "batch 2622: loss 0.080247\n",
      "batch 2623: loss 0.141042\n",
      "batch 2624: loss 0.027144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2625: loss 0.148422\n",
      "batch 2626: loss 0.170192\n",
      "batch 2627: loss 0.048746\n",
      "batch 2628: loss 0.016543\n",
      "batch 2629: loss 0.062964\n",
      "batch 2630: loss 0.127797\n",
      "batch 2631: loss 0.233678\n",
      "batch 2632: loss 0.031054\n",
      "batch 2633: loss 0.087522\n",
      "batch 2634: loss 0.131216\n",
      "batch 2635: loss 0.130945\n",
      "batch 2636: loss 0.026782\n",
      "batch 2637: loss 0.209969\n",
      "batch 2638: loss 0.110550\n",
      "batch 2639: loss 0.109873\n",
      "batch 2640: loss 0.081385\n",
      "batch 2641: loss 0.043050\n",
      "batch 2642: loss 0.103544\n",
      "batch 2643: loss 0.075925\n",
      "batch 2644: loss 0.173354\n",
      "batch 2645: loss 0.046762\n",
      "batch 2646: loss 0.051487\n",
      "batch 2647: loss 0.238469\n",
      "batch 2648: loss 0.115029\n",
      "batch 2649: loss 0.209466\n",
      "batch 2650: loss 0.156277\n",
      "batch 2651: loss 0.152834\n",
      "batch 2652: loss 0.067869\n",
      "batch 2653: loss 0.102717\n",
      "batch 2654: loss 0.300146\n",
      "batch 2655: loss 0.117085\n",
      "batch 2656: loss 0.063847\n",
      "batch 2657: loss 0.063040\n",
      "batch 2658: loss 0.183007\n",
      "batch 2659: loss 0.160736\n",
      "batch 2660: loss 0.032056\n",
      "batch 2661: loss 0.066408\n",
      "batch 2662: loss 0.106707\n",
      "batch 2663: loss 0.176179\n",
      "batch 2664: loss 0.071696\n",
      "batch 2665: loss 0.109636\n",
      "batch 2666: loss 0.054143\n",
      "batch 2667: loss 0.024565\n",
      "batch 2668: loss 0.093065\n",
      "batch 2669: loss 0.078750\n",
      "batch 2670: loss 0.063775\n",
      "batch 2671: loss 0.066125\n",
      "batch 2672: loss 0.044737\n",
      "batch 2673: loss 0.147233\n",
      "batch 2674: loss 0.151840\n",
      "batch 2675: loss 0.094245\n",
      "batch 2676: loss 0.309225\n",
      "batch 2677: loss 0.044272\n",
      "batch 2678: loss 0.090367\n",
      "batch 2679: loss 0.039319\n",
      "batch 2680: loss 0.136559\n",
      "batch 2681: loss 0.032485\n",
      "batch 2682: loss 0.065260\n",
      "batch 2683: loss 0.072928\n",
      "batch 2684: loss 0.170720\n",
      "batch 2685: loss 0.143876\n",
      "batch 2686: loss 0.068193\n",
      "batch 2687: loss 0.048248\n",
      "batch 2688: loss 0.110831\n",
      "batch 2689: loss 0.074000\n",
      "batch 2690: loss 0.181464\n",
      "batch 2691: loss 0.158833\n",
      "batch 2692: loss 0.124188\n",
      "batch 2693: loss 0.066574\n",
      "batch 2694: loss 0.030134\n",
      "batch 2695: loss 0.128196\n",
      "batch 2696: loss 0.205853\n",
      "batch 2697: loss 0.052468\n",
      "batch 2698: loss 0.135859\n",
      "batch 2699: loss 0.099312\n",
      "batch 2700: loss 0.225730\n",
      "batch 2701: loss 0.041980\n",
      "batch 2702: loss 0.117835\n",
      "batch 2703: loss 0.040806\n",
      "batch 2704: loss 0.069230\n",
      "batch 2705: loss 0.120491\n",
      "batch 2706: loss 0.058739\n",
      "batch 2707: loss 0.050695\n",
      "batch 2708: loss 0.223375\n",
      "batch 2709: loss 0.107482\n",
      "batch 2710: loss 0.125525\n",
      "batch 2711: loss 0.118468\n",
      "batch 2712: loss 0.051025\n",
      "batch 2713: loss 0.393235\n",
      "batch 2714: loss 0.043597\n",
      "batch 2715: loss 0.059570\n",
      "batch 2716: loss 0.174356\n",
      "batch 2717: loss 0.232418\n",
      "batch 2718: loss 0.070768\n",
      "batch 2719: loss 0.160467\n",
      "batch 2720: loss 0.164177\n",
      "batch 2721: loss 0.062927\n",
      "batch 2722: loss 0.104108\n",
      "batch 2723: loss 0.041212\n",
      "batch 2724: loss 0.040313\n",
      "batch 2725: loss 0.077821\n",
      "batch 2726: loss 0.129315\n",
      "batch 2727: loss 0.150060\n",
      "batch 2728: loss 0.152828\n",
      "batch 2729: loss 0.159707\n",
      "batch 2730: loss 0.122697\n",
      "batch 2731: loss 0.063932\n",
      "batch 2732: loss 0.043234\n",
      "batch 2733: loss 0.164907\n",
      "batch 2734: loss 0.104885\n",
      "batch 2735: loss 0.021500\n",
      "batch 2736: loss 0.022432\n",
      "batch 2737: loss 0.066608\n",
      "batch 2738: loss 0.079711\n",
      "batch 2739: loss 0.060535\n",
      "batch 2740: loss 0.129432\n",
      "batch 2741: loss 0.047615\n",
      "batch 2742: loss 0.040390\n",
      "batch 2743: loss 0.198049\n",
      "batch 2744: loss 0.178768\n",
      "batch 2745: loss 0.136814\n",
      "batch 2746: loss 0.029733\n",
      "batch 2747: loss 0.041907\n",
      "batch 2748: loss 0.172157\n",
      "batch 2749: loss 0.036321\n",
      "batch 2750: loss 0.081141\n",
      "batch 2751: loss 0.065180\n",
      "batch 2752: loss 0.185583\n",
      "batch 2753: loss 0.048982\n",
      "batch 2754: loss 0.075815\n",
      "batch 2755: loss 0.028670\n",
      "batch 2756: loss 0.050658\n",
      "batch 2757: loss 0.078704\n",
      "batch 2758: loss 0.067563\n",
      "batch 2759: loss 0.064702\n",
      "batch 2760: loss 0.091907\n",
      "batch 2761: loss 0.044518\n",
      "batch 2762: loss 0.158291\n",
      "batch 2763: loss 0.074840\n",
      "batch 2764: loss 0.070160\n",
      "batch 2765: loss 0.037780\n",
      "batch 2766: loss 0.126487\n",
      "batch 2767: loss 0.068056\n",
      "batch 2768: loss 0.036134\n",
      "batch 2769: loss 0.051092\n",
      "batch 2770: loss 0.051090\n",
      "batch 2771: loss 0.122000\n",
      "batch 2772: loss 0.032452\n",
      "batch 2773: loss 0.223737\n",
      "batch 2774: loss 0.109018\n",
      "batch 2775: loss 0.106993\n",
      "batch 2776: loss 0.174494\n",
      "batch 2777: loss 0.176491\n",
      "batch 2778: loss 0.064097\n",
      "batch 2779: loss 0.100475\n",
      "batch 2780: loss 0.036899\n",
      "batch 2781: loss 0.116350\n",
      "batch 2782: loss 0.204987\n",
      "batch 2783: loss 0.085678\n",
      "batch 2784: loss 0.023045\n",
      "batch 2785: loss 0.023629\n",
      "batch 2786: loss 0.052883\n",
      "batch 2787: loss 0.064916\n",
      "batch 2788: loss 0.069665\n",
      "batch 2789: loss 0.044012\n",
      "batch 2790: loss 0.050713\n",
      "batch 2791: loss 0.114318\n",
      "batch 2792: loss 0.049814\n",
      "batch 2793: loss 0.041914\n",
      "batch 2794: loss 0.265246\n",
      "batch 2795: loss 0.050488\n",
      "batch 2796: loss 0.149133\n",
      "batch 2797: loss 0.119360\n",
      "batch 2798: loss 0.140874\n",
      "batch 2799: loss 0.110890\n",
      "batch 2800: loss 0.039435\n",
      "batch 2801: loss 0.067102\n",
      "batch 2802: loss 0.149219\n",
      "batch 2803: loss 0.110554\n",
      "batch 2804: loss 0.043981\n",
      "batch 2805: loss 0.074563\n",
      "batch 2806: loss 0.055591\n",
      "batch 2807: loss 0.039492\n",
      "batch 2808: loss 0.189694\n",
      "batch 2809: loss 0.116631\n",
      "batch 2810: loss 0.014437\n",
      "batch 2811: loss 0.027026\n",
      "batch 2812: loss 0.138171\n",
      "batch 2813: loss 0.048377\n",
      "batch 2814: loss 0.047082\n",
      "batch 2815: loss 0.110042\n",
      "batch 2816: loss 0.024468\n",
      "batch 2817: loss 0.057322\n",
      "batch 2818: loss 0.080424\n",
      "batch 2819: loss 0.067325\n",
      "batch 2820: loss 0.249141\n",
      "batch 2821: loss 0.091308\n",
      "batch 2822: loss 0.077056\n",
      "batch 2823: loss 0.049799\n",
      "batch 2824: loss 0.026726\n",
      "batch 2825: loss 0.109313\n",
      "batch 2826: loss 0.027269\n",
      "batch 2827: loss 0.033862\n",
      "batch 2828: loss 0.126506\n",
      "batch 2829: loss 0.150753\n",
      "batch 2830: loss 0.139886\n",
      "batch 2831: loss 0.070020\n",
      "batch 2832: loss 0.084150\n",
      "batch 2833: loss 0.329232\n",
      "batch 2834: loss 0.044553\n",
      "batch 2835: loss 0.107749\n",
      "batch 2836: loss 0.088462\n",
      "batch 2837: loss 0.056616\n",
      "batch 2838: loss 0.070875\n",
      "batch 2839: loss 0.076208\n",
      "batch 2840: loss 0.158119\n",
      "batch 2841: loss 0.062876\n",
      "batch 2842: loss 0.164074\n",
      "batch 2843: loss 0.038297\n",
      "batch 2844: loss 0.105032\n",
      "batch 2845: loss 0.054259\n",
      "batch 2846: loss 0.104073\n",
      "batch 2847: loss 0.075355\n",
      "batch 2848: loss 0.032633\n",
      "batch 2849: loss 0.159341\n",
      "batch 2850: loss 0.032973\n",
      "batch 2851: loss 0.037536\n",
      "batch 2852: loss 0.160593\n",
      "batch 2853: loss 0.047915\n",
      "batch 2854: loss 0.072817\n",
      "batch 2855: loss 0.152629\n",
      "batch 2856: loss 0.090654\n",
      "batch 2857: loss 0.074172\n",
      "batch 2858: loss 0.126162\n",
      "batch 2859: loss 0.084375\n",
      "batch 2860: loss 0.062939\n",
      "batch 2861: loss 0.056896\n",
      "batch 2862: loss 0.030033\n",
      "batch 2863: loss 0.033891\n",
      "batch 2864: loss 0.228767\n",
      "batch 2865: loss 0.095905\n",
      "batch 2866: loss 0.378812\n",
      "batch 2867: loss 0.174824\n",
      "batch 2868: loss 0.135066\n",
      "batch 2869: loss 0.094193\n",
      "batch 2870: loss 0.043147\n",
      "batch 2871: loss 0.134696\n",
      "batch 2872: loss 0.028940\n",
      "batch 2873: loss 0.151882\n",
      "batch 2874: loss 0.077551\n",
      "batch 2875: loss 0.013838\n",
      "batch 2876: loss 0.227746\n",
      "batch 2877: loss 0.138306\n",
      "batch 2878: loss 0.047919\n",
      "batch 2879: loss 0.191932\n",
      "batch 2880: loss 0.023751\n",
      "batch 2881: loss 0.042843\n",
      "batch 2882: loss 0.013171\n",
      "batch 2883: loss 0.036289\n",
      "batch 2884: loss 0.030846\n",
      "batch 2885: loss 0.065194\n",
      "batch 2886: loss 0.106571\n",
      "batch 2887: loss 0.051271\n",
      "batch 2888: loss 0.053122\n",
      "batch 2889: loss 0.051590\n",
      "batch 2890: loss 0.072890\n",
      "batch 2891: loss 0.252942\n",
      "batch 2892: loss 0.120088\n",
      "batch 2893: loss 0.212752\n",
      "batch 2894: loss 0.067682\n",
      "batch 2895: loss 0.096525\n",
      "batch 2896: loss 0.105335\n",
      "batch 2897: loss 0.023155\n",
      "batch 2898: loss 0.058320\n",
      "batch 2899: loss 0.030105\n",
      "batch 2900: loss 0.028266\n",
      "batch 2901: loss 0.014543\n",
      "batch 2902: loss 0.034254\n",
      "batch 2903: loss 0.051808\n",
      "batch 2904: loss 0.054317\n",
      "batch 2905: loss 0.085486\n",
      "batch 2906: loss 0.025704\n",
      "batch 2907: loss 0.113992\n",
      "batch 2908: loss 0.036437\n",
      "batch 2909: loss 0.062617\n",
      "batch 2910: loss 0.133385\n",
      "batch 2911: loss 0.037440\n",
      "batch 2912: loss 0.021354\n",
      "batch 2913: loss 0.161077\n",
      "batch 2914: loss 0.083233\n",
      "batch 2915: loss 0.146864\n",
      "batch 2916: loss 0.041514\n",
      "batch 2917: loss 0.057126\n",
      "batch 2918: loss 0.239887\n",
      "batch 2919: loss 0.113621\n",
      "batch 2920: loss 0.022430\n",
      "batch 2921: loss 0.104964\n",
      "batch 2922: loss 0.064091\n",
      "batch 2923: loss 0.089277\n",
      "batch 2924: loss 0.119907\n",
      "batch 2925: loss 0.024164\n",
      "batch 2926: loss 0.144888\n",
      "batch 2927: loss 0.097839\n",
      "batch 2928: loss 0.022677\n",
      "batch 2929: loss 0.242483\n",
      "batch 2930: loss 0.238703\n",
      "batch 2931: loss 0.099076\n",
      "batch 2932: loss 0.034602\n",
      "batch 2933: loss 0.108579\n",
      "batch 2934: loss 0.082924\n",
      "batch 2935: loss 0.325530\n",
      "batch 2936: loss 0.042619\n",
      "batch 2937: loss 0.028814\n",
      "batch 2938: loss 0.079043\n",
      "batch 2939: loss 0.193877\n",
      "batch 2940: loss 0.053394\n",
      "batch 2941: loss 0.045893\n",
      "batch 2942: loss 0.247308\n",
      "batch 2943: loss 0.032145\n",
      "batch 2944: loss 0.051459\n",
      "batch 2945: loss 0.078057\n",
      "batch 2946: loss 0.097611\n",
      "batch 2947: loss 0.061858\n",
      "batch 2948: loss 0.058874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2949: loss 0.122649\n",
      "batch 2950: loss 0.123206\n",
      "batch 2951: loss 0.068499\n",
      "batch 2952: loss 0.174247\n",
      "batch 2953: loss 0.104440\n",
      "batch 2954: loss 0.112625\n",
      "batch 2955: loss 0.035503\n",
      "batch 2956: loss 0.090060\n",
      "batch 2957: loss 0.085778\n",
      "batch 2958: loss 0.156244\n",
      "batch 2959: loss 0.040684\n",
      "batch 2960: loss 0.082601\n",
      "batch 2961: loss 0.119738\n",
      "batch 2962: loss 0.101498\n",
      "batch 2963: loss 0.075988\n",
      "batch 2964: loss 0.212676\n",
      "batch 2965: loss 0.145113\n",
      "batch 2966: loss 0.061625\n",
      "batch 2967: loss 0.035240\n",
      "batch 2968: loss 0.116599\n",
      "batch 2969: loss 0.084185\n",
      "batch 2970: loss 0.037422\n",
      "batch 2971: loss 0.086104\n",
      "batch 2972: loss 0.062329\n",
      "batch 2973: loss 0.041335\n",
      "batch 2974: loss 0.045459\n",
      "batch 2975: loss 0.048951\n",
      "batch 2976: loss 0.087877\n",
      "batch 2977: loss 0.105934\n",
      "batch 2978: loss 0.016680\n",
      "batch 2979: loss 0.054149\n",
      "batch 2980: loss 0.244298\n",
      "batch 2981: loss 0.050327\n",
      "batch 2982: loss 0.100670\n",
      "batch 2983: loss 0.036633\n",
      "batch 2984: loss 0.072157\n",
      "batch 2985: loss 0.020456\n",
      "batch 2986: loss 0.071219\n",
      "batch 2987: loss 0.035618\n",
      "batch 2988: loss 0.345306\n",
      "batch 2989: loss 0.112432\n",
      "batch 2990: loss 0.034433\n",
      "batch 2991: loss 0.054124\n",
      "batch 2992: loss 0.133517\n",
      "batch 2993: loss 0.116108\n",
      "batch 2994: loss 0.034264\n",
      "batch 2995: loss 0.185665\n",
      "batch 2996: loss 0.024210\n",
      "batch 2997: loss 0.047657\n",
      "batch 2998: loss 0.049590\n",
      "batch 2999: loss 0.070008\n",
      "batch 3000: loss 0.073130\n",
      "batch 3001: loss 0.082508\n",
      "batch 3002: loss 0.174452\n",
      "batch 3003: loss 0.063646\n",
      "batch 3004: loss 0.020884\n",
      "batch 3005: loss 0.020266\n",
      "batch 3006: loss 0.081123\n",
      "batch 3007: loss 0.068832\n",
      "batch 3008: loss 0.235407\n",
      "batch 3009: loss 0.144039\n",
      "batch 3010: loss 0.076926\n",
      "batch 3011: loss 0.040720\n",
      "batch 3012: loss 0.091498\n",
      "batch 3013: loss 0.050802\n",
      "batch 3014: loss 0.044217\n",
      "batch 3015: loss 0.150587\n",
      "batch 3016: loss 0.081880\n",
      "batch 3017: loss 0.093896\n",
      "batch 3018: loss 0.115024\n",
      "batch 3019: loss 0.287447\n",
      "batch 3020: loss 0.259151\n",
      "batch 3021: loss 0.022133\n",
      "batch 3022: loss 0.059499\n",
      "batch 3023: loss 0.093484\n",
      "batch 3024: loss 0.118479\n",
      "batch 3025: loss 0.039522\n",
      "batch 3026: loss 0.088391\n",
      "batch 3027: loss 0.026077\n",
      "batch 3028: loss 0.031426\n",
      "batch 3029: loss 0.162168\n",
      "batch 3030: loss 0.058707\n",
      "batch 3031: loss 0.113036\n",
      "batch 3032: loss 0.055116\n",
      "batch 3033: loss 0.071295\n",
      "batch 3034: loss 0.013617\n",
      "batch 3035: loss 0.050023\n",
      "batch 3036: loss 0.027427\n",
      "batch 3037: loss 0.099361\n",
      "batch 3038: loss 0.087566\n",
      "batch 3039: loss 0.148685\n",
      "batch 3040: loss 0.035431\n",
      "batch 3041: loss 0.061921\n",
      "batch 3042: loss 0.050166\n",
      "batch 3043: loss 0.012033\n",
      "batch 3044: loss 0.263198\n",
      "batch 3045: loss 0.117375\n",
      "batch 3046: loss 0.147321\n",
      "batch 3047: loss 0.030131\n",
      "batch 3048: loss 0.070600\n",
      "batch 3049: loss 0.042107\n",
      "batch 3050: loss 0.102210\n",
      "batch 3051: loss 0.099239\n",
      "batch 3052: loss 0.148884\n",
      "batch 3053: loss 0.089224\n",
      "batch 3054: loss 0.052396\n",
      "batch 3055: loss 0.224810\n",
      "batch 3056: loss 0.082971\n",
      "batch 3057: loss 0.079948\n",
      "batch 3058: loss 0.115372\n",
      "batch 3059: loss 0.065166\n",
      "batch 3060: loss 0.050657\n",
      "batch 3061: loss 0.080029\n",
      "batch 3062: loss 0.112070\n",
      "batch 3063: loss 0.125385\n",
      "batch 3064: loss 0.018838\n",
      "batch 3065: loss 0.094217\n",
      "batch 3066: loss 0.026459\n",
      "batch 3067: loss 0.030122\n",
      "batch 3068: loss 0.029873\n",
      "batch 3069: loss 0.095246\n",
      "batch 3070: loss 0.040486\n",
      "batch 3071: loss 0.078922\n",
      "batch 3072: loss 0.054735\n",
      "batch 3073: loss 0.150172\n",
      "batch 3074: loss 0.024445\n",
      "batch 3075: loss 0.136872\n",
      "batch 3076: loss 0.068102\n",
      "batch 3077: loss 0.189296\n",
      "batch 3078: loss 0.079861\n",
      "batch 3079: loss 0.023066\n",
      "batch 3080: loss 0.047311\n",
      "batch 3081: loss 0.152541\n",
      "batch 3082: loss 0.049487\n",
      "batch 3083: loss 0.038659\n",
      "batch 3084: loss 0.022973\n",
      "batch 3085: loss 0.074669\n",
      "batch 3086: loss 0.277691\n",
      "batch 3087: loss 0.086468\n",
      "batch 3088: loss 0.091612\n",
      "batch 3089: loss 0.170688\n",
      "batch 3090: loss 0.059909\n",
      "batch 3091: loss 0.048149\n",
      "batch 3092: loss 0.023249\n",
      "batch 3093: loss 0.016136\n",
      "batch 3094: loss 0.059323\n",
      "batch 3095: loss 0.069068\n",
      "batch 3096: loss 0.056988\n",
      "batch 3097: loss 0.085052\n",
      "batch 3098: loss 0.022894\n",
      "batch 3099: loss 0.080025\n",
      "batch 3100: loss 0.064151\n",
      "batch 3101: loss 0.019147\n",
      "batch 3102: loss 0.054684\n",
      "batch 3103: loss 0.130919\n",
      "batch 3104: loss 0.030800\n",
      "batch 3105: loss 0.049138\n",
      "batch 3106: loss 0.044936\n",
      "batch 3107: loss 0.040383\n",
      "batch 3108: loss 0.125187\n",
      "batch 3109: loss 0.044031\n",
      "batch 3110: loss 0.095004\n",
      "batch 3111: loss 0.043175\n",
      "batch 3112: loss 0.036781\n",
      "batch 3113: loss 0.019178\n",
      "batch 3114: loss 0.033157\n",
      "batch 3115: loss 0.096271\n",
      "batch 3116: loss 0.077370\n",
      "batch 3117: loss 0.036156\n",
      "batch 3118: loss 0.105034\n",
      "batch 3119: loss 0.027248\n",
      "batch 3120: loss 0.131845\n",
      "batch 3121: loss 0.053199\n",
      "batch 3122: loss 0.101075\n",
      "batch 3123: loss 0.091246\n",
      "batch 3124: loss 0.039842\n",
      "batch 3125: loss 0.018715\n",
      "batch 3126: loss 0.095040\n",
      "batch 3127: loss 0.061735\n",
      "batch 3128: loss 0.264888\n",
      "batch 3129: loss 0.037415\n",
      "batch 3130: loss 0.031548\n",
      "batch 3131: loss 0.049324\n",
      "batch 3132: loss 0.136949\n",
      "batch 3133: loss 0.213943\n",
      "batch 3134: loss 0.170078\n",
      "batch 3135: loss 0.151143\n",
      "batch 3136: loss 0.355457\n",
      "batch 3137: loss 0.109868\n",
      "batch 3138: loss 0.096561\n",
      "batch 3139: loss 0.185903\n",
      "batch 3140: loss 0.238533\n",
      "batch 3141: loss 0.115287\n",
      "batch 3142: loss 0.077492\n",
      "batch 3143: loss 0.022731\n",
      "batch 3144: loss 0.121761\n",
      "batch 3145: loss 0.088454\n",
      "batch 3146: loss 0.119755\n",
      "batch 3147: loss 0.168075\n",
      "batch 3148: loss 0.044189\n",
      "batch 3149: loss 0.146311\n",
      "batch 3150: loss 0.178274\n",
      "batch 3151: loss 0.079665\n",
      "batch 3152: loss 0.023108\n",
      "batch 3153: loss 0.089145\n",
      "batch 3154: loss 0.204585\n",
      "batch 3155: loss 0.062175\n",
      "batch 3156: loss 0.069181\n",
      "batch 3157: loss 0.199238\n",
      "batch 3158: loss 0.102484\n",
      "batch 3159: loss 0.096855\n",
      "batch 3160: loss 0.018254\n",
      "batch 3161: loss 0.059030\n",
      "batch 3162: loss 0.089398\n",
      "batch 3163: loss 0.111708\n",
      "batch 3164: loss 0.094667\n",
      "batch 3165: loss 0.124932\n",
      "batch 3166: loss 0.086463\n",
      "batch 3167: loss 0.042600\n",
      "batch 3168: loss 0.114174\n",
      "batch 3169: loss 0.020568\n",
      "batch 3170: loss 0.082305\n",
      "batch 3171: loss 0.044595\n",
      "batch 3172: loss 0.055358\n",
      "batch 3173: loss 0.034789\n",
      "batch 3174: loss 0.072183\n",
      "batch 3175: loss 0.077085\n",
      "batch 3176: loss 0.054577\n",
      "batch 3177: loss 0.084246\n",
      "batch 3178: loss 0.099126\n",
      "batch 3179: loss 0.115630\n",
      "batch 3180: loss 0.045612\n",
      "batch 3181: loss 0.074001\n",
      "batch 3182: loss 0.077390\n",
      "batch 3183: loss 0.092451\n",
      "batch 3184: loss 0.109184\n",
      "batch 3185: loss 0.058865\n",
      "batch 3186: loss 0.116419\n",
      "batch 3187: loss 0.062328\n",
      "batch 3188: loss 0.381067\n",
      "batch 3189: loss 0.072458\n",
      "batch 3190: loss 0.042424\n",
      "batch 3191: loss 0.150122\n",
      "batch 3192: loss 0.057391\n",
      "batch 3193: loss 0.032866\n",
      "batch 3194: loss 0.114759\n",
      "batch 3195: loss 0.027967\n",
      "batch 3196: loss 0.025679\n",
      "batch 3197: loss 0.095671\n",
      "batch 3198: loss 0.055701\n",
      "batch 3199: loss 0.010825\n",
      "batch 3200: loss 0.065016\n",
      "batch 3201: loss 0.076938\n",
      "batch 3202: loss 0.048420\n",
      "batch 3203: loss 0.021832\n",
      "batch 3204: loss 0.094185\n",
      "batch 3205: loss 0.025535\n",
      "batch 3206: loss 0.034983\n",
      "batch 3207: loss 0.050524\n",
      "batch 3208: loss 0.044549\n",
      "batch 3209: loss 0.047813\n",
      "batch 3210: loss 0.132845\n",
      "batch 3211: loss 0.101330\n",
      "batch 3212: loss 0.068149\n",
      "batch 3213: loss 0.084356\n",
      "batch 3214: loss 0.175481\n",
      "batch 3215: loss 0.039197\n",
      "batch 3216: loss 0.038729\n",
      "batch 3217: loss 0.078761\n",
      "batch 3218: loss 0.034915\n",
      "batch 3219: loss 0.065981\n",
      "batch 3220: loss 0.100453\n",
      "batch 3221: loss 0.015346\n",
      "batch 3222: loss 0.038942\n",
      "batch 3223: loss 0.015656\n",
      "batch 3224: loss 0.138436\n",
      "batch 3225: loss 0.126451\n",
      "batch 3226: loss 0.058455\n",
      "batch 3227: loss 0.170309\n",
      "batch 3228: loss 0.123139\n",
      "batch 3229: loss 0.060951\n",
      "batch 3230: loss 0.191270\n",
      "batch 3231: loss 0.061706\n",
      "batch 3232: loss 0.048034\n",
      "batch 3233: loss 0.022904\n",
      "batch 3234: loss 0.016980\n",
      "batch 3235: loss 0.021938\n",
      "batch 3236: loss 0.136966\n",
      "batch 3237: loss 0.032577\n",
      "batch 3238: loss 0.049748\n",
      "batch 3239: loss 0.088962\n",
      "batch 3240: loss 0.022130\n",
      "batch 3241: loss 0.179031\n",
      "batch 3242: loss 0.073477\n",
      "batch 3243: loss 0.226144\n",
      "batch 3244: loss 0.063145\n",
      "batch 3245: loss 0.186740\n",
      "batch 3246: loss 0.075124\n",
      "batch 3247: loss 0.172737\n",
      "batch 3248: loss 0.139366\n",
      "batch 3249: loss 0.072361\n",
      "batch 3250: loss 0.290333\n",
      "batch 3251: loss 0.097830\n",
      "batch 3252: loss 0.020214\n",
      "batch 3253: loss 0.037401\n",
      "batch 3254: loss 0.047355\n",
      "batch 3255: loss 0.040529\n",
      "batch 3256: loss 0.053276\n",
      "batch 3257: loss 0.038382\n",
      "batch 3258: loss 0.068826\n",
      "batch 3259: loss 0.133689\n",
      "batch 3260: loss 0.076490\n",
      "batch 3261: loss 0.088292\n",
      "batch 3262: loss 0.032333\n",
      "batch 3263: loss 0.171671\n",
      "batch 3264: loss 0.152797\n",
      "batch 3265: loss 0.055689\n",
      "batch 3266: loss 0.301726\n",
      "batch 3267: loss 0.023726\n",
      "batch 3268: loss 0.047876\n",
      "batch 3269: loss 0.022662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3270: loss 0.048087\n",
      "batch 3271: loss 0.042031\n",
      "batch 3272: loss 0.099916\n",
      "batch 3273: loss 0.042168\n",
      "batch 3274: loss 0.068926\n",
      "batch 3275: loss 0.187258\n",
      "batch 3276: loss 0.072540\n",
      "batch 3277: loss 0.107825\n",
      "batch 3278: loss 0.144581\n",
      "batch 3279: loss 0.028905\n",
      "batch 3280: loss 0.022014\n",
      "batch 3281: loss 0.048205\n",
      "batch 3282: loss 0.057875\n",
      "batch 3283: loss 0.034256\n",
      "batch 3284: loss 0.083597\n",
      "batch 3285: loss 0.021371\n",
      "batch 3286: loss 0.021131\n",
      "batch 3287: loss 0.049936\n",
      "batch 3288: loss 0.063442\n",
      "batch 3289: loss 0.048913\n",
      "batch 3290: loss 0.034564\n",
      "batch 3291: loss 0.115933\n",
      "batch 3292: loss 0.019991\n",
      "batch 3293: loss 0.017764\n",
      "batch 3294: loss 0.027433\n",
      "batch 3295: loss 0.032049\n",
      "batch 3296: loss 0.045619\n",
      "batch 3297: loss 0.184796\n",
      "batch 3298: loss 0.044626\n",
      "batch 3299: loss 0.064683\n",
      "batch 3300: loss 0.055410\n",
      "batch 3301: loss 0.122447\n",
      "batch 3302: loss 0.105594\n",
      "batch 3303: loss 0.058523\n",
      "batch 3304: loss 0.264514\n",
      "batch 3305: loss 0.391223\n",
      "batch 3306: loss 0.092125\n",
      "batch 3307: loss 0.027107\n",
      "batch 3308: loss 0.017283\n",
      "batch 3309: loss 0.237945\n",
      "batch 3310: loss 0.134311\n",
      "batch 3311: loss 0.027930\n",
      "batch 3312: loss 0.014459\n",
      "batch 3313: loss 0.014421\n",
      "batch 3314: loss 0.173409\n",
      "batch 3315: loss 0.032312\n",
      "batch 3316: loss 0.051131\n",
      "batch 3317: loss 0.154002\n",
      "batch 3318: loss 0.053132\n",
      "batch 3319: loss 0.105250\n",
      "batch 3320: loss 0.049781\n",
      "batch 3321: loss 0.036992\n",
      "batch 3322: loss 0.030740\n",
      "batch 3323: loss 0.140961\n",
      "batch 3324: loss 0.062916\n",
      "batch 3325: loss 0.143284\n",
      "batch 3326: loss 0.177969\n",
      "batch 3327: loss 0.067968\n",
      "batch 3328: loss 0.066209\n",
      "batch 3329: loss 0.180570\n",
      "batch 3330: loss 0.057014\n",
      "batch 3331: loss 0.086062\n",
      "batch 3332: loss 0.062758\n",
      "batch 3333: loss 0.034400\n",
      "batch 3334: loss 0.025660\n",
      "batch 3335: loss 0.091840\n",
      "batch 3336: loss 0.094387\n",
      "batch 3337: loss 0.137110\n",
      "batch 3338: loss 0.036009\n",
      "batch 3339: loss 0.143449\n",
      "batch 3340: loss 0.078735\n",
      "batch 3341: loss 0.014965\n",
      "batch 3342: loss 0.119270\n",
      "batch 3343: loss 0.018648\n",
      "batch 3344: loss 0.016075\n",
      "batch 3345: loss 0.077038\n",
      "batch 3346: loss 0.082166\n",
      "batch 3347: loss 0.102569\n",
      "batch 3348: loss 0.098163\n",
      "batch 3349: loss 0.042332\n",
      "batch 3350: loss 0.076417\n",
      "batch 3351: loss 0.026396\n",
      "batch 3352: loss 0.050531\n",
      "batch 3353: loss 0.147267\n",
      "batch 3354: loss 0.039933\n",
      "batch 3355: loss 0.037297\n",
      "batch 3356: loss 0.035462\n",
      "batch 3357: loss 0.024569\n",
      "batch 3358: loss 0.074766\n",
      "batch 3359: loss 0.135813\n",
      "batch 3360: loss 0.044114\n",
      "batch 3361: loss 0.139779\n",
      "batch 3362: loss 0.086061\n",
      "batch 3363: loss 0.095713\n",
      "batch 3364: loss 0.040635\n",
      "batch 3365: loss 0.017951\n",
      "batch 3366: loss 0.173428\n",
      "batch 3367: loss 0.107641\n",
      "batch 3368: loss 0.039380\n",
      "batch 3369: loss 0.079573\n",
      "batch 3370: loss 0.098950\n",
      "batch 3371: loss 0.029956\n",
      "batch 3372: loss 0.056573\n",
      "batch 3373: loss 0.066959\n",
      "batch 3374: loss 0.020208\n",
      "batch 3375: loss 0.111665\n",
      "batch 3376: loss 0.187243\n",
      "batch 3377: loss 0.035838\n",
      "batch 3378: loss 0.101489\n",
      "batch 3379: loss 0.155278\n",
      "batch 3380: loss 0.118727\n",
      "batch 3381: loss 0.138617\n",
      "batch 3382: loss 0.043738\n",
      "batch 3383: loss 0.134459\n",
      "batch 3384: loss 0.029768\n",
      "batch 3385: loss 0.056396\n",
      "batch 3386: loss 0.015088\n",
      "batch 3387: loss 0.055468\n",
      "batch 3388: loss 0.116863\n",
      "batch 3389: loss 0.123341\n",
      "batch 3390: loss 0.104465\n",
      "batch 3391: loss 0.190426\n",
      "batch 3392: loss 0.169243\n",
      "batch 3393: loss 0.040938\n",
      "batch 3394: loss 0.034062\n",
      "batch 3395: loss 0.066371\n",
      "batch 3396: loss 0.053543\n",
      "batch 3397: loss 0.147259\n",
      "batch 3398: loss 0.021875\n",
      "batch 3399: loss 0.219993\n",
      "batch 3400: loss 0.074950\n",
      "batch 3401: loss 0.085576\n",
      "batch 3402: loss 0.035729\n",
      "batch 3403: loss 0.038888\n",
      "batch 3404: loss 0.025863\n",
      "batch 3405: loss 0.027192\n",
      "batch 3406: loss 0.186856\n",
      "batch 3407: loss 0.051403\n",
      "batch 3408: loss 0.150386\n",
      "batch 3409: loss 0.049953\n",
      "batch 3410: loss 0.007263\n",
      "batch 3411: loss 0.095575\n",
      "batch 3412: loss 0.078383\n",
      "batch 3413: loss 0.028050\n",
      "batch 3414: loss 0.089192\n",
      "batch 3415: loss 0.037887\n",
      "batch 3416: loss 0.156183\n",
      "batch 3417: loss 0.118253\n",
      "batch 3418: loss 0.020963\n",
      "batch 3419: loss 0.087487\n",
      "batch 3420: loss 0.058792\n",
      "batch 3421: loss 0.085971\n",
      "batch 3422: loss 0.084080\n",
      "batch 3423: loss 0.074461\n",
      "batch 3424: loss 0.167868\n",
      "batch 3425: loss 0.077311\n",
      "batch 3426: loss 0.046486\n",
      "batch 3427: loss 0.228877\n",
      "batch 3428: loss 0.016502\n",
      "batch 3429: loss 0.070713\n",
      "batch 3430: loss 0.068006\n",
      "batch 3431: loss 0.136921\n",
      "batch 3432: loss 0.128604\n",
      "batch 3433: loss 0.218642\n",
      "batch 3434: loss 0.060028\n",
      "batch 3435: loss 0.051705\n",
      "batch 3436: loss 0.026172\n",
      "batch 3437: loss 0.116881\n",
      "batch 3438: loss 0.039092\n",
      "batch 3439: loss 0.275914\n",
      "batch 3440: loss 0.083737\n",
      "batch 3441: loss 0.089968\n",
      "batch 3442: loss 0.015271\n",
      "batch 3443: loss 0.063690\n",
      "batch 3444: loss 0.130805\n",
      "batch 3445: loss 0.045885\n",
      "batch 3446: loss 0.065890\n",
      "batch 3447: loss 0.029469\n",
      "batch 3448: loss 0.080838\n",
      "batch 3449: loss 0.086248\n",
      "batch 3450: loss 0.105496\n",
      "batch 3451: loss 0.167804\n",
      "batch 3452: loss 0.039732\n",
      "batch 3453: loss 0.053326\n",
      "batch 3454: loss 0.048647\n",
      "batch 3455: loss 0.054649\n",
      "batch 3456: loss 0.076091\n",
      "batch 3457: loss 0.018380\n",
      "batch 3458: loss 0.039441\n",
      "batch 3459: loss 0.066206\n",
      "batch 3460: loss 0.017452\n",
      "batch 3461: loss 0.101577\n",
      "batch 3462: loss 0.067008\n",
      "batch 3463: loss 0.166208\n",
      "batch 3464: loss 0.210355\n",
      "batch 3465: loss 0.010227\n",
      "batch 3466: loss 0.139825\n",
      "batch 3467: loss 0.091543\n",
      "batch 3468: loss 0.023242\n",
      "batch 3469: loss 0.028531\n",
      "batch 3470: loss 0.118699\n",
      "batch 3471: loss 0.103160\n",
      "batch 3472: loss 0.034305\n",
      "batch 3473: loss 0.290485\n",
      "batch 3474: loss 0.032900\n",
      "batch 3475: loss 0.019856\n",
      "batch 3476: loss 0.182680\n",
      "batch 3477: loss 0.046452\n",
      "batch 3478: loss 0.106005\n",
      "batch 3479: loss 0.046882\n",
      "batch 3480: loss 0.029961\n",
      "batch 3481: loss 0.079177\n",
      "batch 3482: loss 0.080599\n",
      "batch 3483: loss 0.053857\n",
      "batch 3484: loss 0.026098\n",
      "batch 3485: loss 0.108824\n",
      "batch 3486: loss 0.192700\n",
      "batch 3487: loss 0.022515\n",
      "batch 3488: loss 0.080753\n",
      "batch 3489: loss 0.099574\n",
      "batch 3490: loss 0.045039\n",
      "batch 3491: loss 0.106921\n",
      "batch 3492: loss 0.221973\n",
      "batch 3493: loss 0.112049\n",
      "batch 3494: loss 0.080183\n",
      "batch 3495: loss 0.208258\n",
      "batch 3496: loss 0.086854\n",
      "batch 3497: loss 0.070980\n",
      "batch 3498: loss 0.033046\n",
      "batch 3499: loss 0.040840\n",
      "batch 3500: loss 0.045675\n",
      "batch 3501: loss 0.068079\n",
      "batch 3502: loss 0.025683\n",
      "batch 3503: loss 0.022478\n",
      "batch 3504: loss 0.049275\n",
      "batch 3505: loss 0.052737\n",
      "batch 3506: loss 0.050520\n",
      "batch 3507: loss 0.119132\n",
      "batch 3508: loss 0.133080\n",
      "batch 3509: loss 0.061657\n",
      "batch 3510: loss 0.093659\n",
      "batch 3511: loss 0.027633\n",
      "batch 3512: loss 0.047942\n",
      "batch 3513: loss 0.048157\n",
      "batch 3514: loss 0.122638\n",
      "batch 3515: loss 0.062006\n",
      "batch 3516: loss 0.120614\n",
      "batch 3517: loss 0.031240\n",
      "batch 3518: loss 0.056949\n",
      "batch 3519: loss 0.054850\n",
      "batch 3520: loss 0.142805\n",
      "batch 3521: loss 0.049798\n",
      "batch 3522: loss 0.082948\n",
      "batch 3523: loss 0.074815\n",
      "batch 3524: loss 0.023884\n",
      "batch 3525: loss 0.059760\n",
      "batch 3526: loss 0.111848\n",
      "batch 3527: loss 0.028543\n",
      "batch 3528: loss 0.098354\n",
      "batch 3529: loss 0.037302\n",
      "batch 3530: loss 0.035600\n",
      "batch 3531: loss 0.213214\n",
      "batch 3532: loss 0.087721\n",
      "batch 3533: loss 0.059968\n",
      "batch 3534: loss 0.042613\n",
      "batch 3535: loss 0.067129\n",
      "batch 3536: loss 0.125821\n",
      "batch 3537: loss 0.009755\n",
      "batch 3538: loss 0.126529\n",
      "batch 3539: loss 0.183575\n",
      "batch 3540: loss 0.160790\n",
      "batch 3541: loss 0.026178\n",
      "batch 3542: loss 0.020473\n",
      "batch 3543: loss 0.029146\n",
      "batch 3544: loss 0.102286\n",
      "batch 3545: loss 0.066131\n",
      "batch 3546: loss 0.054246\n",
      "batch 3547: loss 0.018946\n",
      "batch 3548: loss 0.059020\n",
      "batch 3549: loss 0.173640\n",
      "batch 3550: loss 0.108598\n",
      "batch 3551: loss 0.111272\n",
      "batch 3552: loss 0.218178\n",
      "batch 3553: loss 0.063850\n",
      "batch 3554: loss 0.048836\n",
      "batch 3555: loss 0.193723\n",
      "batch 3556: loss 0.063152\n",
      "batch 3557: loss 0.056812\n",
      "batch 3558: loss 0.026914\n",
      "batch 3559: loss 0.077024\n",
      "batch 3560: loss 0.066683\n",
      "batch 3561: loss 0.019857\n",
      "batch 3562: loss 0.182438\n",
      "batch 3563: loss 0.177213\n",
      "batch 3564: loss 0.055797\n",
      "batch 3565: loss 0.024039\n",
      "batch 3566: loss 0.024550\n",
      "batch 3567: loss 0.266941\n",
      "batch 3568: loss 0.087696\n",
      "batch 3569: loss 0.046558\n",
      "batch 3570: loss 0.012290\n",
      "batch 3571: loss 0.130038\n",
      "batch 3572: loss 0.049035\n",
      "batch 3573: loss 0.063783\n",
      "batch 3574: loss 0.049536\n",
      "batch 3575: loss 0.100611\n",
      "batch 3576: loss 0.127116\n",
      "batch 3577: loss 0.065246\n",
      "batch 3578: loss 0.028737\n",
      "batch 3579: loss 0.206463\n",
      "batch 3580: loss 0.048874\n",
      "batch 3581: loss 0.020735\n",
      "batch 3582: loss 0.021084\n",
      "batch 3583: loss 0.059939\n",
      "batch 3584: loss 0.144701\n",
      "batch 3585: loss 0.108112\n",
      "batch 3586: loss 0.039860\n",
      "batch 3587: loss 0.031637\n",
      "batch 3588: loss 0.008018\n",
      "batch 3589: loss 0.069380\n",
      "batch 3590: loss 0.047217\n",
      "batch 3591: loss 0.052919\n",
      "batch 3592: loss 0.027528\n",
      "batch 3593: loss 0.056073\n",
      "batch 3594: loss 0.038064\n",
      "batch 3595: loss 0.104413\n",
      "batch 3596: loss 0.070972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3597: loss 0.024209\n",
      "batch 3598: loss 0.064908\n",
      "batch 3599: loss 0.038546\n",
      "batch 3600: loss 0.034774\n",
      "batch 3601: loss 0.063823\n",
      "batch 3602: loss 0.093266\n",
      "batch 3603: loss 0.032292\n",
      "batch 3604: loss 0.045125\n",
      "batch 3605: loss 0.046418\n",
      "batch 3606: loss 0.056887\n",
      "batch 3607: loss 0.062002\n",
      "batch 3608: loss 0.060759\n",
      "batch 3609: loss 0.107352\n",
      "batch 3610: loss 0.121627\n",
      "batch 3611: loss 0.049324\n",
      "batch 3612: loss 0.088695\n",
      "batch 3613: loss 0.036219\n",
      "batch 3614: loss 0.018759\n",
      "batch 3615: loss 0.098624\n",
      "batch 3616: loss 0.031614\n",
      "batch 3617: loss 0.014056\n",
      "batch 3618: loss 0.083641\n",
      "batch 3619: loss 0.015501\n",
      "batch 3620: loss 0.050207\n",
      "batch 3621: loss 0.079229\n",
      "batch 3622: loss 0.016249\n",
      "batch 3623: loss 0.165745\n",
      "batch 3624: loss 0.018931\n",
      "batch 3625: loss 0.228733\n",
      "batch 3626: loss 0.030733\n",
      "batch 3627: loss 0.022670\n",
      "batch 3628: loss 0.087370\n",
      "batch 3629: loss 0.059328\n",
      "batch 3630: loss 0.065138\n",
      "batch 3631: loss 0.050593\n",
      "batch 3632: loss 0.116381\n",
      "batch 3633: loss 0.099293\n",
      "batch 3634: loss 0.250530\n",
      "batch 3635: loss 0.060376\n",
      "batch 3636: loss 0.018186\n",
      "batch 3637: loss 0.064850\n",
      "batch 3638: loss 0.246567\n",
      "batch 3639: loss 0.044385\n",
      "batch 3640: loss 0.226418\n",
      "batch 3641: loss 0.034688\n",
      "batch 3642: loss 0.052743\n",
      "batch 3643: loss 0.064874\n",
      "batch 3644: loss 0.095436\n",
      "batch 3645: loss 0.054196\n",
      "batch 3646: loss 0.011810\n",
      "batch 3647: loss 0.181852\n",
      "batch 3648: loss 0.294155\n",
      "batch 3649: loss 0.044779\n",
      "batch 3650: loss 0.158286\n",
      "batch 3651: loss 0.143329\n",
      "batch 3652: loss 0.211816\n",
      "batch 3653: loss 0.013567\n",
      "batch 3654: loss 0.039885\n",
      "batch 3655: loss 0.082022\n",
      "batch 3656: loss 0.031492\n",
      "batch 3657: loss 0.045059\n",
      "batch 3658: loss 0.051005\n",
      "batch 3659: loss 0.086385\n",
      "batch 3660: loss 0.052953\n",
      "batch 3661: loss 0.094175\n",
      "batch 3662: loss 0.038411\n",
      "batch 3663: loss 0.075467\n",
      "batch 3664: loss 0.089847\n",
      "batch 3665: loss 0.026961\n",
      "batch 3666: loss 0.078465\n",
      "batch 3667: loss 0.020272\n",
      "batch 3668: loss 0.090667\n",
      "batch 3669: loss 0.147314\n",
      "batch 3670: loss 0.012044\n",
      "batch 3671: loss 0.029290\n",
      "batch 3672: loss 0.049188\n",
      "batch 3673: loss 0.271062\n",
      "batch 3674: loss 0.069399\n",
      "batch 3675: loss 0.069517\n",
      "batch 3676: loss 0.018709\n",
      "batch 3677: loss 0.011386\n",
      "batch 3678: loss 0.188160\n",
      "batch 3679: loss 0.141432\n",
      "batch 3680: loss 0.095052\n",
      "batch 3681: loss 0.039377\n",
      "batch 3682: loss 0.076332\n",
      "batch 3683: loss 0.072145\n",
      "batch 3684: loss 0.077425\n",
      "batch 3685: loss 0.019483\n",
      "batch 3686: loss 0.066437\n",
      "batch 3687: loss 0.160720\n",
      "batch 3688: loss 0.042859\n",
      "batch 3689: loss 0.065572\n",
      "batch 3690: loss 0.075952\n",
      "batch 3691: loss 0.065237\n",
      "batch 3692: loss 0.106782\n",
      "batch 3693: loss 0.149716\n",
      "batch 3694: loss 0.083007\n",
      "batch 3695: loss 0.019016\n",
      "batch 3696: loss 0.076582\n",
      "batch 3697: loss 0.158919\n",
      "batch 3698: loss 0.078929\n",
      "batch 3699: loss 0.127653\n",
      "batch 3700: loss 0.045613\n",
      "batch 3701: loss 0.207101\n",
      "batch 3702: loss 0.047144\n",
      "batch 3703: loss 0.014298\n",
      "batch 3704: loss 0.108974\n",
      "batch 3705: loss 0.191340\n",
      "batch 3706: loss 0.071864\n",
      "batch 3707: loss 0.163968\n",
      "batch 3708: loss 0.045855\n",
      "batch 3709: loss 0.021723\n",
      "batch 3710: loss 0.148260\n",
      "batch 3711: loss 0.040456\n",
      "batch 3712: loss 0.111269\n",
      "batch 3713: loss 0.062498\n",
      "batch 3714: loss 0.056590\n",
      "batch 3715: loss 0.274693\n",
      "batch 3716: loss 0.133027\n",
      "batch 3717: loss 0.181331\n",
      "batch 3718: loss 0.093550\n",
      "batch 3719: loss 0.140566\n",
      "batch 3720: loss 0.022538\n",
      "batch 3721: loss 0.024849\n",
      "batch 3722: loss 0.136234\n",
      "batch 3723: loss 0.047723\n",
      "batch 3724: loss 0.154643\n",
      "batch 3725: loss 0.038224\n",
      "batch 3726: loss 0.045303\n",
      "batch 3727: loss 0.186183\n",
      "batch 3728: loss 0.117917\n",
      "batch 3729: loss 0.060930\n",
      "batch 3730: loss 0.109435\n",
      "batch 3731: loss 0.062520\n",
      "batch 3732: loss 0.181430\n",
      "batch 3733: loss 0.053802\n",
      "batch 3734: loss 0.031459\n",
      "batch 3735: loss 0.142261\n",
      "batch 3736: loss 0.125532\n",
      "batch 3737: loss 0.019570\n",
      "batch 3738: loss 0.023335\n",
      "batch 3739: loss 0.035696\n",
      "batch 3740: loss 0.025159\n",
      "batch 3741: loss 0.047407\n",
      "batch 3742: loss 0.140955\n",
      "batch 3743: loss 0.296224\n",
      "batch 3744: loss 0.092599\n",
      "batch 3745: loss 0.020530\n",
      "batch 3746: loss 0.100994\n",
      "batch 3747: loss 0.041672\n",
      "batch 3748: loss 0.118658\n",
      "batch 3749: loss 0.075866\n",
      "batch 3750: loss 0.038901\n",
      "batch 3751: loss 0.038476\n",
      "batch 3752: loss 0.069721\n",
      "batch 3753: loss 0.135222\n",
      "batch 3754: loss 0.013481\n",
      "batch 3755: loss 0.022114\n",
      "batch 3756: loss 0.094994\n",
      "batch 3757: loss 0.037302\n",
      "batch 3758: loss 0.024697\n",
      "batch 3759: loss 0.113778\n",
      "batch 3760: loss 0.038125\n",
      "batch 3761: loss 0.086703\n",
      "batch 3762: loss 0.108345\n",
      "batch 3763: loss 0.168409\n",
      "batch 3764: loss 0.068523\n",
      "batch 3765: loss 0.042369\n",
      "batch 3766: loss 0.092760\n",
      "batch 3767: loss 0.100840\n",
      "batch 3768: loss 0.037436\n",
      "batch 3769: loss 0.384847\n",
      "batch 3770: loss 0.041988\n",
      "batch 3771: loss 0.052173\n",
      "batch 3772: loss 0.062018\n",
      "batch 3773: loss 0.007244\n",
      "batch 3774: loss 0.062639\n",
      "batch 3775: loss 0.051044\n",
      "batch 3776: loss 0.047262\n",
      "batch 3777: loss 0.141191\n",
      "batch 3778: loss 0.150813\n",
      "batch 3779: loss 0.250403\n",
      "batch 3780: loss 0.081279\n",
      "batch 3781: loss 0.027246\n",
      "batch 3782: loss 0.035680\n",
      "batch 3783: loss 0.060121\n",
      "batch 3784: loss 0.073429\n",
      "batch 3785: loss 0.022222\n",
      "batch 3786: loss 0.084051\n",
      "batch 3787: loss 0.014275\n",
      "batch 3788: loss 0.039687\n",
      "batch 3789: loss 0.034678\n",
      "batch 3790: loss 0.054562\n",
      "batch 3791: loss 0.039361\n",
      "batch 3792: loss 0.036831\n",
      "batch 3793: loss 0.036115\n",
      "batch 3794: loss 0.050732\n",
      "batch 3795: loss 0.015257\n",
      "batch 3796: loss 0.049487\n",
      "batch 3797: loss 0.244467\n",
      "batch 3798: loss 0.142373\n",
      "batch 3799: loss 0.016245\n",
      "batch 3800: loss 0.058448\n",
      "batch 3801: loss 0.029836\n",
      "batch 3802: loss 0.061891\n",
      "batch 3803: loss 0.051790\n",
      "batch 3804: loss 0.108417\n",
      "batch 3805: loss 0.052154\n",
      "batch 3806: loss 0.058512\n",
      "batch 3807: loss 0.069627\n",
      "batch 3808: loss 0.144362\n",
      "batch 3809: loss 0.204547\n",
      "batch 3810: loss 0.034266\n",
      "batch 3811: loss 0.148033\n",
      "batch 3812: loss 0.057047\n",
      "batch 3813: loss 0.072651\n",
      "batch 3814: loss 0.037546\n",
      "batch 3815: loss 0.057759\n",
      "batch 3816: loss 0.012926\n",
      "batch 3817: loss 0.088536\n",
      "batch 3818: loss 0.103225\n",
      "batch 3819: loss 0.035819\n",
      "batch 3820: loss 0.047809\n",
      "batch 3821: loss 0.058446\n",
      "batch 3822: loss 0.050741\n",
      "batch 3823: loss 0.150900\n",
      "batch 3824: loss 0.276637\n",
      "batch 3825: loss 0.054927\n",
      "batch 3826: loss 0.076525\n",
      "batch 3827: loss 0.075806\n",
      "batch 3828: loss 0.091612\n",
      "batch 3829: loss 0.044719\n",
      "batch 3830: loss 0.098969\n",
      "batch 3831: loss 0.027385\n",
      "batch 3832: loss 0.034137\n",
      "batch 3833: loss 0.087555\n",
      "batch 3834: loss 0.029550\n",
      "batch 3835: loss 0.152769\n",
      "batch 3836: loss 0.087071\n",
      "batch 3837: loss 0.034235\n",
      "batch 3838: loss 0.051017\n",
      "batch 3839: loss 0.060456\n",
      "batch 3840: loss 0.067993\n",
      "batch 3841: loss 0.100521\n",
      "batch 3842: loss 0.083374\n",
      "batch 3843: loss 0.066930\n",
      "batch 3844: loss 0.074232\n",
      "batch 3845: loss 0.164841\n",
      "batch 3846: loss 0.085333\n",
      "batch 3847: loss 0.041213\n",
      "batch 3848: loss 0.025272\n",
      "batch 3849: loss 0.025669\n",
      "batch 3850: loss 0.181151\n",
      "batch 3851: loss 0.080502\n",
      "batch 3852: loss 0.064653\n",
      "batch 3853: loss 0.148214\n",
      "batch 3854: loss 0.027340\n",
      "batch 3855: loss 0.027180\n",
      "batch 3856: loss 0.011608\n",
      "batch 3857: loss 0.053515\n",
      "batch 3858: loss 0.176584\n",
      "batch 3859: loss 0.015419\n",
      "batch 3860: loss 0.119539\n",
      "batch 3861: loss 0.029521\n",
      "batch 3862: loss 0.230005\n",
      "batch 3863: loss 0.042920\n",
      "batch 3864: loss 0.125962\n",
      "batch 3865: loss 0.220289\n",
      "batch 3866: loss 0.050471\n",
      "batch 3867: loss 0.078963\n",
      "batch 3868: loss 0.034873\n",
      "batch 3869: loss 0.066141\n",
      "batch 3870: loss 0.063370\n",
      "batch 3871: loss 0.138616\n",
      "batch 3872: loss 0.029909\n",
      "batch 3873: loss 0.052410\n",
      "batch 3874: loss 0.073439\n",
      "batch 3875: loss 0.143220\n",
      "batch 3876: loss 0.197243\n",
      "batch 3877: loss 0.042072\n",
      "batch 3878: loss 0.074423\n",
      "batch 3879: loss 0.059309\n",
      "batch 3880: loss 0.055389\n",
      "batch 3881: loss 0.070495\n",
      "batch 3882: loss 0.239258\n",
      "batch 3883: loss 0.053963\n",
      "batch 3884: loss 0.096025\n",
      "batch 3885: loss 0.013560\n",
      "batch 3886: loss 0.052929\n",
      "batch 3887: loss 0.124975\n",
      "batch 3888: loss 0.073651\n",
      "batch 3889: loss 0.086012\n",
      "batch 3890: loss 0.128078\n",
      "batch 3891: loss 0.026980\n",
      "batch 3892: loss 0.021244\n",
      "batch 3893: loss 0.031115\n",
      "batch 3894: loss 0.089639\n",
      "batch 3895: loss 0.066416\n",
      "batch 3896: loss 0.094854\n",
      "batch 3897: loss 0.034889\n",
      "batch 3898: loss 0.077268\n",
      "batch 3899: loss 0.042408\n",
      "batch 3900: loss 0.040022\n",
      "batch 3901: loss 0.106983\n",
      "batch 3902: loss 0.102747\n",
      "batch 3903: loss 0.073429\n",
      "batch 3904: loss 0.035361\n",
      "batch 3905: loss 0.150926\n",
      "batch 3906: loss 0.084015\n",
      "batch 3907: loss 0.070472\n",
      "batch 3908: loss 0.017268\n",
      "batch 3909: loss 0.054366\n",
      "batch 3910: loss 0.162560\n",
      "batch 3911: loss 0.035529\n",
      "batch 3912: loss 0.058670\n",
      "batch 3913: loss 0.030124\n",
      "batch 3914: loss 0.031036\n",
      "batch 3915: loss 0.040597\n",
      "batch 3916: loss 0.081477\n",
      "batch 3917: loss 0.020890\n",
      "batch 3918: loss 0.065062\n",
      "batch 3919: loss 0.061412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3920: loss 0.113410\n",
      "batch 3921: loss 0.031732\n",
      "batch 3922: loss 0.058294\n",
      "batch 3923: loss 0.026584\n",
      "batch 3924: loss 0.048565\n",
      "batch 3925: loss 0.026928\n",
      "batch 3926: loss 0.116468\n",
      "batch 3927: loss 0.082449\n",
      "batch 3928: loss 0.040227\n",
      "batch 3929: loss 0.025592\n",
      "batch 3930: loss 0.152661\n",
      "batch 3931: loss 0.134901\n",
      "batch 3932: loss 0.015751\n",
      "batch 3933: loss 0.088623\n",
      "batch 3934: loss 0.068105\n",
      "batch 3935: loss 0.045543\n",
      "batch 3936: loss 0.058348\n",
      "batch 3937: loss 0.012351\n",
      "batch 3938: loss 0.026144\n",
      "batch 3939: loss 0.085721\n",
      "batch 3940: loss 0.028213\n",
      "batch 3941: loss 0.039326\n",
      "batch 3942: loss 0.090892\n",
      "batch 3943: loss 0.361556\n",
      "batch 3944: loss 0.089392\n",
      "batch 3945: loss 0.069100\n",
      "batch 3946: loss 0.012872\n",
      "batch 3947: loss 0.078243\n",
      "batch 3948: loss 0.038310\n",
      "batch 3949: loss 0.044867\n",
      "batch 3950: loss 0.153389\n",
      "batch 3951: loss 0.157602\n",
      "batch 3952: loss 0.078285\n",
      "batch 3953: loss 0.293053\n",
      "batch 3954: loss 0.069894\n",
      "batch 3955: loss 0.049015\n",
      "batch 3956: loss 0.050087\n",
      "batch 3957: loss 0.037478\n",
      "batch 3958: loss 0.158638\n",
      "batch 3959: loss 0.094963\n",
      "batch 3960: loss 0.068840\n",
      "batch 3961: loss 0.013083\n",
      "batch 3962: loss 0.062706\n",
      "batch 3963: loss 0.036431\n",
      "batch 3964: loss 0.034488\n",
      "batch 3965: loss 0.018325\n",
      "batch 3966: loss 0.363922\n",
      "batch 3967: loss 0.033425\n",
      "batch 3968: loss 0.048251\n",
      "batch 3969: loss 0.027759\n",
      "batch 3970: loss 0.027946\n",
      "batch 3971: loss 0.183380\n",
      "batch 3972: loss 0.046573\n",
      "batch 3973: loss 0.027804\n",
      "batch 3974: loss 0.139341\n",
      "batch 3975: loss 0.059776\n",
      "batch 3976: loss 0.127449\n",
      "batch 3977: loss 0.046197\n",
      "batch 3978: loss 0.064834\n",
      "batch 3979: loss 0.027489\n",
      "batch 3980: loss 0.087043\n",
      "batch 3981: loss 0.023687\n",
      "batch 3982: loss 0.006998\n",
      "batch 3983: loss 0.078117\n",
      "batch 3984: loss 0.065138\n",
      "batch 3985: loss 0.034727\n",
      "batch 3986: loss 0.078838\n",
      "batch 3987: loss 0.031581\n",
      "batch 3988: loss 0.025905\n",
      "batch 3989: loss 0.024247\n",
      "batch 3990: loss 0.040946\n",
      "batch 3991: loss 0.025814\n",
      "batch 3992: loss 0.034887\n",
      "batch 3993: loss 0.248554\n",
      "batch 3994: loss 0.058821\n",
      "batch 3995: loss 0.078075\n",
      "batch 3996: loss 0.067234\n",
      "batch 3997: loss 0.061417\n",
      "batch 3998: loss 0.053417\n",
      "batch 3999: loss 0.047451\n",
      "batch 4000: loss 0.034358\n",
      "batch 4001: loss 0.015199\n",
      "batch 4002: loss 0.151350\n",
      "batch 4003: loss 0.099262\n",
      "batch 4004: loss 0.030951\n",
      "batch 4005: loss 0.145774\n",
      "batch 4006: loss 0.139886\n",
      "batch 4007: loss 0.042203\n",
      "batch 4008: loss 0.038588\n",
      "batch 4009: loss 0.143017\n",
      "batch 4010: loss 0.029424\n",
      "batch 4011: loss 0.030517\n",
      "batch 4012: loss 0.013920\n",
      "batch 4013: loss 0.061198\n",
      "batch 4014: loss 0.074129\n",
      "batch 4015: loss 0.063890\n",
      "batch 4016: loss 0.033023\n",
      "batch 4017: loss 0.186110\n",
      "batch 4018: loss 0.014284\n",
      "batch 4019: loss 0.091742\n",
      "batch 4020: loss 0.156080\n",
      "batch 4021: loss 0.034192\n",
      "batch 4022: loss 0.110257\n",
      "batch 4023: loss 0.072680\n",
      "batch 4024: loss 0.191733\n",
      "batch 4025: loss 0.011027\n",
      "batch 4026: loss 0.079232\n",
      "batch 4027: loss 0.084529\n",
      "batch 4028: loss 0.067426\n",
      "batch 4029: loss 0.015549\n",
      "batch 4030: loss 0.013576\n",
      "batch 4031: loss 0.177699\n",
      "batch 4032: loss 0.026608\n",
      "batch 4033: loss 0.010502\n",
      "batch 4034: loss 0.099161\n",
      "batch 4035: loss 0.036160\n",
      "batch 4036: loss 0.029450\n",
      "batch 4037: loss 0.084139\n",
      "batch 4038: loss 0.049495\n",
      "batch 4039: loss 0.179214\n",
      "batch 4040: loss 0.087371\n",
      "batch 4041: loss 0.188119\n",
      "batch 4042: loss 0.115386\n",
      "batch 4043: loss 0.039833\n",
      "batch 4044: loss 0.098736\n",
      "batch 4045: loss 0.151490\n",
      "batch 4046: loss 0.052837\n",
      "batch 4047: loss 0.031174\n",
      "batch 4048: loss 0.073485\n",
      "batch 4049: loss 0.114052\n",
      "batch 4050: loss 0.109418\n",
      "batch 4051: loss 0.118981\n",
      "batch 4052: loss 0.126889\n",
      "batch 4053: loss 0.101600\n",
      "batch 4054: loss 0.062020\n",
      "batch 4055: loss 0.012494\n",
      "batch 4056: loss 0.129360\n",
      "batch 4057: loss 0.079344\n",
      "batch 4058: loss 0.199289\n",
      "batch 4059: loss 0.190771\n",
      "batch 4060: loss 0.017954\n",
      "batch 4061: loss 0.026697\n",
      "batch 4062: loss 0.046202\n",
      "batch 4063: loss 0.120408\n",
      "batch 4064: loss 0.033144\n",
      "batch 4065: loss 0.220727\n",
      "batch 4066: loss 0.286319\n",
      "batch 4067: loss 0.059849\n",
      "batch 4068: loss 0.033091\n",
      "batch 4069: loss 0.069736\n",
      "batch 4070: loss 0.051554\n",
      "batch 4071: loss 0.099325\n",
      "batch 4072: loss 0.025264\n",
      "batch 4073: loss 0.038988\n",
      "batch 4074: loss 0.090153\n",
      "batch 4075: loss 0.078583\n",
      "batch 4076: loss 0.049562\n",
      "batch 4077: loss 0.068227\n",
      "batch 4078: loss 0.172996\n",
      "batch 4079: loss 0.050364\n",
      "batch 4080: loss 0.050142\n",
      "batch 4081: loss 0.024373\n",
      "batch 4082: loss 0.122635\n",
      "batch 4083: loss 0.038403\n",
      "batch 4084: loss 0.036112\n",
      "batch 4085: loss 0.172632\n",
      "batch 4086: loss 0.087909\n",
      "batch 4087: loss 0.010879\n",
      "batch 4088: loss 0.038599\n",
      "batch 4089: loss 0.061960\n",
      "batch 4090: loss 0.151038\n",
      "batch 4091: loss 0.053917\n",
      "batch 4092: loss 0.122855\n",
      "batch 4093: loss 0.015249\n",
      "batch 4094: loss 0.010318\n",
      "batch 4095: loss 0.066971\n",
      "batch 4096: loss 0.007807\n",
      "batch 4097: loss 0.082722\n",
      "batch 4098: loss 0.084699\n",
      "batch 4099: loss 0.038857\n",
      "batch 4100: loss 0.144380\n",
      "batch 4101: loss 0.045050\n",
      "batch 4102: loss 0.029557\n",
      "batch 4103: loss 0.165477\n",
      "batch 4104: loss 0.258590\n",
      "batch 4105: loss 0.037318\n",
      "batch 4106: loss 0.012766\n",
      "batch 4107: loss 0.032632\n",
      "batch 4108: loss 0.016072\n",
      "batch 4109: loss 0.018896\n",
      "batch 4110: loss 0.053778\n",
      "batch 4111: loss 0.052889\n",
      "batch 4112: loss 0.060073\n",
      "batch 4113: loss 0.049310\n",
      "batch 4114: loss 0.189197\n",
      "batch 4115: loss 0.123203\n",
      "batch 4116: loss 0.064943\n",
      "batch 4117: loss 0.055135\n",
      "batch 4118: loss 0.068355\n",
      "batch 4119: loss 0.068723\n",
      "batch 4120: loss 0.032050\n",
      "batch 4121: loss 0.080799\n",
      "batch 4122: loss 0.049789\n",
      "batch 4123: loss 0.067982\n",
      "batch 4124: loss 0.015688\n",
      "batch 4125: loss 0.101636\n",
      "batch 4126: loss 0.093027\n",
      "batch 4127: loss 0.041902\n",
      "batch 4128: loss 0.147779\n",
      "batch 4129: loss 0.093409\n",
      "batch 4130: loss 0.106236\n",
      "batch 4131: loss 0.032144\n",
      "batch 4132: loss 0.016311\n",
      "batch 4133: loss 0.094196\n",
      "batch 4134: loss 0.138029\n",
      "batch 4135: loss 0.012416\n",
      "batch 4136: loss 0.089910\n",
      "batch 4137: loss 0.039643\n",
      "batch 4138: loss 0.040044\n",
      "batch 4139: loss 0.054499\n",
      "batch 4140: loss 0.073530\n",
      "batch 4141: loss 0.125463\n",
      "batch 4142: loss 0.065487\n",
      "batch 4143: loss 0.207516\n",
      "batch 4144: loss 0.041776\n",
      "batch 4145: loss 0.092038\n",
      "batch 4146: loss 0.030420\n",
      "batch 4147: loss 0.035504\n",
      "batch 4148: loss 0.246436\n",
      "batch 4149: loss 0.136504\n",
      "batch 4150: loss 0.057616\n",
      "batch 4151: loss 0.087403\n",
      "batch 4152: loss 0.079956\n",
      "batch 4153: loss 0.172265\n",
      "batch 4154: loss 0.069522\n",
      "batch 4155: loss 0.047752\n",
      "batch 4156: loss 0.084067\n",
      "batch 4157: loss 0.013949\n",
      "batch 4158: loss 0.071939\n",
      "batch 4159: loss 0.131651\n",
      "batch 4160: loss 0.053927\n",
      "batch 4161: loss 0.043121\n",
      "batch 4162: loss 0.077623\n",
      "batch 4163: loss 0.011206\n",
      "batch 4164: loss 0.046651\n",
      "batch 4165: loss 0.099967\n",
      "batch 4166: loss 0.046316\n",
      "batch 4167: loss 0.027242\n",
      "batch 4168: loss 0.076306\n",
      "batch 4169: loss 0.030464\n",
      "batch 4170: loss 0.128824\n",
      "batch 4171: loss 0.021292\n",
      "batch 4172: loss 0.214714\n",
      "batch 4173: loss 0.063941\n",
      "batch 4174: loss 0.120983\n",
      "batch 4175: loss 0.124722\n",
      "batch 4176: loss 0.030178\n",
      "batch 4177: loss 0.161339\n",
      "batch 4178: loss 0.045406\n",
      "batch 4179: loss 0.039552\n",
      "batch 4180: loss 0.029612\n",
      "batch 4181: loss 0.089721\n",
      "batch 4182: loss 0.069987\n",
      "batch 4183: loss 0.080066\n",
      "batch 4184: loss 0.059126\n",
      "batch 4185: loss 0.045626\n",
      "batch 4186: loss 0.093555\n",
      "batch 4187: loss 0.154265\n",
      "batch 4188: loss 0.021129\n",
      "batch 4189: loss 0.041246\n",
      "batch 4190: loss 0.074107\n",
      "batch 4191: loss 0.018936\n",
      "batch 4192: loss 0.054172\n",
      "batch 4193: loss 0.050845\n",
      "batch 4194: loss 0.021361\n",
      "batch 4195: loss 0.063097\n",
      "batch 4196: loss 0.173630\n",
      "batch 4197: loss 0.088410\n",
      "batch 4198: loss 0.022024\n",
      "batch 4199: loss 0.007811\n",
      "batch 4200: loss 0.033894\n",
      "batch 4201: loss 0.079738\n",
      "batch 4202: loss 0.010230\n",
      "batch 4203: loss 0.030314\n",
      "batch 4204: loss 0.024634\n",
      "batch 4205: loss 0.016832\n",
      "batch 4206: loss 0.096876\n",
      "batch 4207: loss 0.029720\n",
      "batch 4208: loss 0.151197\n",
      "batch 4209: loss 0.108819\n",
      "batch 4210: loss 0.082519\n",
      "batch 4211: loss 0.034433\n",
      "batch 4212: loss 0.033404\n",
      "batch 4213: loss 0.056338\n",
      "batch 4214: loss 0.004027\n",
      "batch 4215: loss 0.095869\n",
      "batch 4216: loss 0.064955\n",
      "batch 4217: loss 0.014511\n",
      "batch 4218: loss 0.048307\n",
      "batch 4219: loss 0.158641\n",
      "batch 4220: loss 0.075583\n",
      "batch 4221: loss 0.020376\n",
      "batch 4222: loss 0.036333\n",
      "batch 4223: loss 0.048113\n",
      "batch 4224: loss 0.123372\n",
      "batch 4225: loss 0.096406\n",
      "batch 4226: loss 0.061738\n",
      "batch 4227: loss 0.033227\n",
      "batch 4228: loss 0.036137\n",
      "batch 4229: loss 0.095278\n",
      "batch 4230: loss 0.108570\n",
      "batch 4231: loss 0.042779\n",
      "batch 4232: loss 0.144986\n",
      "batch 4233: loss 0.167341\n",
      "batch 4234: loss 0.013420\n",
      "batch 4235: loss 0.062583\n",
      "batch 4236: loss 0.065321\n",
      "batch 4237: loss 0.020923\n",
      "batch 4238: loss 0.076429\n",
      "batch 4239: loss 0.021139\n",
      "batch 4240: loss 0.065398\n",
      "batch 4241: loss 0.010865\n",
      "batch 4242: loss 0.044423\n",
      "batch 4243: loss 0.090493\n",
      "batch 4244: loss 0.033073\n",
      "batch 4245: loss 0.046717\n",
      "batch 4246: loss 0.046883\n",
      "batch 4247: loss 0.035689\n",
      "batch 4248: loss 0.072049\n",
      "batch 4249: loss 0.037035\n",
      "batch 4250: loss 0.094852\n",
      "batch 4251: loss 0.171945\n",
      "batch 4252: loss 0.035672\n",
      "batch 4253: loss 0.146191\n",
      "batch 4254: loss 0.179198\n",
      "batch 4255: loss 0.139629\n",
      "batch 4256: loss 0.066247\n",
      "batch 4257: loss 0.112568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4258: loss 0.022335\n",
      "batch 4259: loss 0.021005\n",
      "batch 4260: loss 0.127513\n",
      "batch 4261: loss 0.051023\n",
      "batch 4262: loss 0.085884\n",
      "batch 4263: loss 0.023551\n",
      "batch 4264: loss 0.069674\n",
      "batch 4265: loss 0.045650\n",
      "batch 4266: loss 0.049050\n",
      "batch 4267: loss 0.040029\n",
      "batch 4268: loss 0.041682\n",
      "batch 4269: loss 0.026319\n",
      "batch 4270: loss 0.027208\n",
      "batch 4271: loss 0.054077\n",
      "batch 4272: loss 0.064208\n",
      "batch 4273: loss 0.058174\n",
      "batch 4274: loss 0.067044\n",
      "batch 4275: loss 0.206763\n",
      "batch 4276: loss 0.082800\n",
      "batch 4277: loss 0.054930\n",
      "batch 4278: loss 0.023321\n",
      "batch 4279: loss 0.118478\n",
      "batch 4280: loss 0.155046\n",
      "batch 4281: loss 0.035896\n",
      "batch 4282: loss 0.046694\n",
      "batch 4283: loss 0.024254\n",
      "batch 4284: loss 0.126729\n",
      "batch 4285: loss 0.042423\n",
      "batch 4286: loss 0.024950\n",
      "batch 4287: loss 0.011779\n",
      "batch 4288: loss 0.031556\n",
      "batch 4289: loss 0.103582\n",
      "batch 4290: loss 0.014289\n",
      "batch 4291: loss 0.044085\n",
      "batch 4292: loss 0.032566\n",
      "batch 4293: loss 0.060912\n",
      "batch 4294: loss 0.097818\n",
      "batch 4295: loss 0.095698\n",
      "batch 4296: loss 0.009943\n",
      "batch 4297: loss 0.088705\n",
      "batch 4298: loss 0.067418\n",
      "batch 4299: loss 0.036829\n",
      "batch 4300: loss 0.054387\n",
      "batch 4301: loss 0.074101\n",
      "batch 4302: loss 0.074995\n",
      "batch 4303: loss 0.204455\n",
      "batch 4304: loss 0.175712\n",
      "batch 4305: loss 0.005098\n",
      "batch 4306: loss 0.061803\n",
      "batch 4307: loss 0.027537\n",
      "batch 4308: loss 0.077936\n",
      "batch 4309: loss 0.058022\n",
      "batch 4310: loss 0.053102\n",
      "batch 4311: loss 0.079282\n",
      "batch 4312: loss 0.084216\n",
      "batch 4313: loss 0.045272\n",
      "batch 4314: loss 0.129265\n",
      "batch 4315: loss 0.057922\n",
      "batch 4316: loss 0.081404\n",
      "batch 4317: loss 0.104379\n",
      "batch 4318: loss 0.011254\n",
      "batch 4319: loss 0.080119\n",
      "batch 4320: loss 0.049294\n",
      "batch 4321: loss 0.163425\n",
      "batch 4322: loss 0.149748\n",
      "batch 4323: loss 0.066214\n",
      "batch 4324: loss 0.015572\n",
      "batch 4325: loss 0.032831\n",
      "batch 4326: loss 0.033864\n",
      "batch 4327: loss 0.035804\n",
      "batch 4328: loss 0.038365\n",
      "batch 4329: loss 0.100626\n",
      "batch 4330: loss 0.039724\n",
      "batch 4331: loss 0.043602\n",
      "batch 4332: loss 0.163020\n",
      "batch 4333: loss 0.154820\n",
      "batch 4334: loss 0.166422\n",
      "batch 4335: loss 0.058331\n",
      "batch 4336: loss 0.218329\n",
      "batch 4337: loss 0.052296\n",
      "batch 4338: loss 0.117972\n",
      "batch 4339: loss 0.045457\n",
      "batch 4340: loss 0.039717\n",
      "batch 4341: loss 0.104663\n",
      "batch 4342: loss 0.036146\n",
      "batch 4343: loss 0.065578\n",
      "batch 4344: loss 0.034741\n",
      "batch 4345: loss 0.030687\n",
      "batch 4346: loss 0.010578\n",
      "batch 4347: loss 0.167464\n",
      "batch 4348: loss 0.085357\n",
      "batch 4349: loss 0.089239\n",
      "batch 4350: loss 0.053305\n",
      "batch 4351: loss 0.060962\n",
      "batch 4352: loss 0.015802\n",
      "batch 4353: loss 0.011151\n",
      "batch 4354: loss 0.074447\n",
      "batch 4355: loss 0.060995\n",
      "batch 4356: loss 0.038973\n",
      "batch 4357: loss 0.030657\n",
      "batch 4358: loss 0.047036\n",
      "batch 4359: loss 0.081996\n",
      "batch 4360: loss 0.078133\n",
      "batch 4361: loss 0.246134\n",
      "batch 4362: loss 0.041806\n",
      "batch 4363: loss 0.074957\n",
      "batch 4364: loss 0.081836\n",
      "batch 4365: loss 0.075647\n",
      "batch 4366: loss 0.144458\n",
      "batch 4367: loss 0.114244\n",
      "batch 4368: loss 0.065347\n",
      "batch 4369: loss 0.086219\n",
      "batch 4370: loss 0.037822\n",
      "batch 4371: loss 0.039338\n",
      "batch 4372: loss 0.015715\n",
      "batch 4373: loss 0.025874\n",
      "batch 4374: loss 0.060747\n",
      "batch 4375: loss 0.044225\n",
      "batch 4376: loss 0.113716\n",
      "batch 4377: loss 0.144117\n",
      "batch 4378: loss 0.047411\n",
      "batch 4379: loss 0.036797\n",
      "batch 4380: loss 0.184606\n",
      "batch 4381: loss 0.217376\n",
      "batch 4382: loss 0.025261\n",
      "batch 4383: loss 0.062524\n",
      "batch 4384: loss 0.026745\n",
      "batch 4385: loss 0.022757\n",
      "batch 4386: loss 0.064863\n",
      "batch 4387: loss 0.019510\n",
      "batch 4388: loss 0.084046\n",
      "batch 4389: loss 0.061718\n",
      "batch 4390: loss 0.066157\n",
      "batch 4391: loss 0.018230\n",
      "batch 4392: loss 0.071028\n",
      "batch 4393: loss 0.077660\n",
      "batch 4394: loss 0.057617\n",
      "batch 4395: loss 0.088423\n",
      "batch 4396: loss 0.024789\n",
      "batch 4397: loss 0.129199\n",
      "batch 4398: loss 0.008356\n",
      "batch 4399: loss 0.028504\n",
      "batch 4400: loss 0.087598\n",
      "batch 4401: loss 0.090306\n",
      "batch 4402: loss 0.143963\n",
      "batch 4403: loss 0.075089\n",
      "batch 4404: loss 0.031953\n",
      "batch 4405: loss 0.154126\n",
      "batch 4406: loss 0.016949\n",
      "batch 4407: loss 0.015877\n",
      "batch 4408: loss 0.020762\n",
      "batch 4409: loss 0.072070\n",
      "batch 4410: loss 0.112063\n",
      "batch 4411: loss 0.051087\n",
      "batch 4412: loss 0.043968\n",
      "batch 4413: loss 0.014140\n",
      "batch 4414: loss 0.055255\n",
      "batch 4415: loss 0.163885\n",
      "batch 4416: loss 0.026308\n",
      "batch 4417: loss 0.014533\n",
      "batch 4418: loss 0.082917\n",
      "batch 4419: loss 0.023190\n",
      "batch 4420: loss 0.027165\n",
      "batch 4421: loss 0.072744\n",
      "batch 4422: loss 0.020328\n",
      "batch 4423: loss 0.026511\n",
      "batch 4424: loss 0.040284\n",
      "batch 4425: loss 0.014580\n",
      "batch 4426: loss 0.029746\n",
      "batch 4427: loss 0.015051\n",
      "batch 4428: loss 0.038192\n",
      "batch 4429: loss 0.063398\n",
      "batch 4430: loss 0.015917\n",
      "batch 4431: loss 0.100849\n",
      "batch 4432: loss 0.124478\n",
      "batch 4433: loss 0.130180\n",
      "batch 4434: loss 0.070180\n",
      "batch 4435: loss 0.056572\n",
      "batch 4436: loss 0.007518\n",
      "batch 4437: loss 0.103893\n",
      "batch 4438: loss 0.055758\n",
      "batch 4439: loss 0.234586\n",
      "batch 4440: loss 0.030362\n",
      "batch 4441: loss 0.015398\n",
      "batch 4442: loss 0.113309\n",
      "batch 4443: loss 0.056673\n",
      "batch 4444: loss 0.106413\n",
      "batch 4445: loss 0.008405\n",
      "batch 4446: loss 0.086460\n",
      "batch 4447: loss 0.061625\n",
      "batch 4448: loss 0.047861\n",
      "batch 4449: loss 0.064123\n",
      "batch 4450: loss 0.020958\n",
      "batch 4451: loss 0.038796\n",
      "batch 4452: loss 0.241451\n",
      "batch 4453: loss 0.047226\n",
      "batch 4454: loss 0.023116\n",
      "batch 4455: loss 0.118545\n",
      "batch 4456: loss 0.061821\n",
      "batch 4457: loss 0.030151\n",
      "batch 4458: loss 0.066639\n",
      "batch 4459: loss 0.020908\n",
      "batch 4460: loss 0.035736\n",
      "batch 4461: loss 0.039104\n",
      "batch 4462: loss 0.010088\n",
      "batch 4463: loss 0.197965\n",
      "batch 4464: loss 0.045586\n",
      "batch 4465: loss 0.032685\n",
      "batch 4466: loss 0.103928\n",
      "batch 4467: loss 0.048599\n",
      "batch 4468: loss 0.057942\n",
      "batch 4469: loss 0.210939\n",
      "batch 4470: loss 0.090331\n",
      "batch 4471: loss 0.076971\n",
      "batch 4472: loss 0.086363\n",
      "batch 4473: loss 0.015267\n",
      "batch 4474: loss 0.065473\n",
      "batch 4475: loss 0.032696\n",
      "batch 4476: loss 0.263617\n",
      "batch 4477: loss 0.048708\n",
      "batch 4478: loss 0.066617\n",
      "batch 4479: loss 0.046060\n",
      "batch 4480: loss 0.082604\n",
      "batch 4481: loss 0.037559\n",
      "batch 4482: loss 0.035945\n",
      "batch 4483: loss 0.079489\n",
      "batch 4484: loss 0.044087\n",
      "batch 4485: loss 0.026285\n",
      "batch 4486: loss 0.075031\n",
      "batch 4487: loss 0.017963\n",
      "batch 4488: loss 0.068589\n",
      "batch 4489: loss 0.037952\n",
      "batch 4490: loss 0.115419\n",
      "batch 4491: loss 0.035691\n",
      "batch 4492: loss 0.044374\n",
      "batch 4493: loss 0.238532\n",
      "batch 4494: loss 0.109567\n",
      "batch 4495: loss 0.019077\n",
      "batch 4496: loss 0.063386\n",
      "batch 4497: loss 0.034015\n",
      "batch 4498: loss 0.103663\n",
      "batch 4499: loss 0.130435\n",
      "batch 4500: loss 0.055998\n",
      "batch 4501: loss 0.037447\n",
      "batch 4502: loss 0.110906\n",
      "batch 4503: loss 0.194530\n",
      "batch 4504: loss 0.141085\n",
      "batch 4505: loss 0.013551\n",
      "batch 4506: loss 0.043913\n",
      "batch 4507: loss 0.158366\n",
      "batch 4508: loss 0.070545\n",
      "batch 4509: loss 0.131740\n",
      "batch 4510: loss 0.035249\n",
      "batch 4511: loss 0.041847\n",
      "batch 4512: loss 0.057422\n",
      "batch 4513: loss 0.145547\n",
      "batch 4514: loss 0.036400\n",
      "batch 4515: loss 0.174797\n",
      "batch 4516: loss 0.024436\n",
      "batch 4517: loss 0.166045\n",
      "batch 4518: loss 0.047653\n",
      "batch 4519: loss 0.170227\n",
      "batch 4520: loss 0.052341\n",
      "batch 4521: loss 0.017425\n",
      "batch 4522: loss 0.187081\n",
      "batch 4523: loss 0.225495\n",
      "batch 4524: loss 0.035133\n",
      "batch 4525: loss 0.175318\n",
      "batch 4526: loss 0.016565\n",
      "batch 4527: loss 0.040987\n",
      "batch 4528: loss 0.057128\n",
      "batch 4529: loss 0.041892\n",
      "batch 4530: loss 0.098324\n",
      "batch 4531: loss 0.033650\n",
      "batch 4532: loss 0.240618\n",
      "batch 4533: loss 0.056745\n",
      "batch 4534: loss 0.052046\n",
      "batch 4535: loss 0.068305\n",
      "batch 4536: loss 0.017760\n",
      "batch 4537: loss 0.125059\n",
      "batch 4538: loss 0.074397\n",
      "batch 4539: loss 0.053166\n",
      "batch 4540: loss 0.034916\n",
      "batch 4541: loss 0.061273\n",
      "batch 4542: loss 0.011241\n",
      "batch 4543: loss 0.153432\n",
      "batch 4544: loss 0.048211\n",
      "batch 4545: loss 0.404231\n",
      "batch 4546: loss 0.107945\n",
      "batch 4547: loss 0.043076\n",
      "batch 4548: loss 0.028943\n",
      "batch 4549: loss 0.110845\n",
      "batch 4550: loss 0.019350\n",
      "batch 4551: loss 0.010467\n",
      "batch 4552: loss 0.024085\n",
      "batch 4553: loss 0.051525\n",
      "batch 4554: loss 0.032417\n",
      "batch 4555: loss 0.020764\n",
      "batch 4556: loss 0.013030\n",
      "batch 4557: loss 0.045297\n",
      "batch 4558: loss 0.051671\n",
      "batch 4559: loss 0.029388\n",
      "batch 4560: loss 0.012580\n",
      "batch 4561: loss 0.109276\n",
      "batch 4562: loss 0.058224\n",
      "batch 4563: loss 0.056678\n",
      "batch 4564: loss 0.013065\n",
      "batch 4565: loss 0.023958\n",
      "batch 4566: loss 0.370867\n",
      "batch 4567: loss 0.109565\n",
      "batch 4568: loss 0.203117\n",
      "batch 4569: loss 0.126867\n",
      "batch 4570: loss 0.038916\n",
      "batch 4571: loss 0.195360\n",
      "batch 4572: loss 0.067824\n",
      "batch 4573: loss 0.024941\n",
      "batch 4574: loss 0.061279\n",
      "batch 4575: loss 0.133844\n",
      "batch 4576: loss 0.038127\n",
      "batch 4577: loss 0.054238\n",
      "batch 4578: loss 0.075579\n",
      "batch 4579: loss 0.042838\n",
      "batch 4580: loss 0.195284\n",
      "batch 4581: loss 0.037678\n",
      "batch 4582: loss 0.055200\n",
      "batch 4583: loss 0.012659\n",
      "batch 4584: loss 0.033017\n",
      "batch 4585: loss 0.088160\n",
      "batch 4586: loss 0.020516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4587: loss 0.060238\n",
      "batch 4588: loss 0.086598\n",
      "batch 4589: loss 0.032024\n",
      "batch 4590: loss 0.041044\n",
      "batch 4591: loss 0.032422\n",
      "batch 4592: loss 0.079249\n",
      "batch 4593: loss 0.024185\n",
      "batch 4594: loss 0.065739\n",
      "batch 4595: loss 0.033849\n",
      "batch 4596: loss 0.052961\n",
      "batch 4597: loss 0.142928\n",
      "batch 4598: loss 0.059938\n",
      "batch 4599: loss 0.017988\n",
      "batch 4600: loss 0.038209\n",
      "batch 4601: loss 0.095799\n",
      "batch 4602: loss 0.113902\n",
      "batch 4603: loss 0.085157\n",
      "batch 4604: loss 0.046512\n",
      "batch 4605: loss 0.050492\n",
      "batch 4606: loss 0.026773\n",
      "batch 4607: loss 0.033692\n",
      "batch 4608: loss 0.058071\n",
      "batch 4609: loss 0.119010\n",
      "batch 4610: loss 0.041549\n",
      "batch 4611: loss 0.053987\n",
      "batch 4612: loss 0.068901\n",
      "batch 4613: loss 0.112362\n",
      "batch 4614: loss 0.044882\n",
      "batch 4615: loss 0.183583\n",
      "batch 4616: loss 0.045638\n",
      "batch 4617: loss 0.020825\n",
      "batch 4618: loss 0.010966\n",
      "batch 4619: loss 0.092356\n",
      "batch 4620: loss 0.059010\n",
      "batch 4621: loss 0.020776\n",
      "batch 4622: loss 0.228348\n",
      "batch 4623: loss 0.031292\n",
      "batch 4624: loss 0.039888\n",
      "batch 4625: loss 0.085970\n",
      "batch 4626: loss 0.021915\n",
      "batch 4627: loss 0.077679\n",
      "batch 4628: loss 0.021761\n",
      "batch 4629: loss 0.017651\n",
      "batch 4630: loss 0.051461\n",
      "batch 4631: loss 0.024441\n",
      "batch 4632: loss 0.048828\n",
      "batch 4633: loss 0.149871\n",
      "batch 4634: loss 0.114935\n",
      "batch 4635: loss 0.124123\n",
      "batch 4636: loss 0.011656\n",
      "batch 4637: loss 0.030648\n",
      "batch 4638: loss 0.080732\n",
      "batch 4639: loss 0.124385\n",
      "batch 4640: loss 0.057397\n",
      "batch 4641: loss 0.022474\n",
      "batch 4642: loss 0.041248\n",
      "batch 4643: loss 0.012638\n",
      "batch 4644: loss 0.130942\n",
      "batch 4645: loss 0.040976\n",
      "batch 4646: loss 0.077504\n",
      "batch 4647: loss 0.068774\n",
      "batch 4648: loss 0.071794\n",
      "batch 4649: loss 0.112806\n",
      "batch 4650: loss 0.004657\n",
      "batch 4651: loss 0.005232\n",
      "batch 4652: loss 0.023038\n",
      "batch 4653: loss 0.052270\n",
      "batch 4654: loss 0.123982\n",
      "batch 4655: loss 0.061007\n",
      "batch 4656: loss 0.072298\n",
      "batch 4657: loss 0.067922\n",
      "batch 4658: loss 0.009327\n",
      "batch 4659: loss 0.031022\n",
      "batch 4660: loss 0.044403\n",
      "batch 4661: loss 0.035876\n",
      "batch 4662: loss 0.028040\n",
      "batch 4663: loss 0.025291\n",
      "batch 4664: loss 0.106652\n",
      "batch 4665: loss 0.075110\n",
      "batch 4666: loss 0.044523\n",
      "batch 4667: loss 0.120991\n",
      "batch 4668: loss 0.113836\n",
      "batch 4669: loss 0.074926\n",
      "batch 4670: loss 0.330827\n",
      "batch 4671: loss 0.053585\n",
      "batch 4672: loss 0.031303\n",
      "batch 4673: loss 0.032228\n",
      "batch 4674: loss 0.058999\n",
      "batch 4675: loss 0.071947\n",
      "batch 4676: loss 0.112833\n",
      "batch 4677: loss 0.062449\n",
      "batch 4678: loss 0.015431\n",
      "batch 4679: loss 0.364104\n",
      "batch 4680: loss 0.066478\n",
      "batch 4681: loss 0.108548\n",
      "batch 4682: loss 0.106291\n",
      "batch 4683: loss 0.028502\n",
      "batch 4684: loss 0.078972\n",
      "batch 4685: loss 0.061021\n",
      "batch 4686: loss 0.056441\n",
      "batch 4687: loss 0.025413\n",
      "batch 4688: loss 0.030180\n",
      "batch 4689: loss 0.068703\n",
      "batch 4690: loss 0.076932\n",
      "batch 4691: loss 0.029225\n",
      "batch 4692: loss 0.074306\n",
      "batch 4693: loss 0.056973\n",
      "batch 4694: loss 0.026587\n",
      "batch 4695: loss 0.066109\n",
      "batch 4696: loss 0.054364\n",
      "batch 4697: loss 0.039806\n",
      "batch 4698: loss 0.101932\n",
      "batch 4699: loss 0.023163\n",
      "batch 4700: loss 0.060560\n",
      "batch 4701: loss 0.344892\n",
      "batch 4702: loss 0.088361\n",
      "batch 4703: loss 0.090551\n",
      "batch 4704: loss 0.027310\n",
      "batch 4705: loss 0.100387\n",
      "batch 4706: loss 0.123779\n",
      "batch 4707: loss 0.016541\n",
      "batch 4708: loss 0.068028\n",
      "batch 4709: loss 0.059711\n",
      "batch 4710: loss 0.029183\n",
      "batch 4711: loss 0.152919\n",
      "batch 4712: loss 0.017789\n",
      "batch 4713: loss 0.071017\n",
      "batch 4714: loss 0.010144\n",
      "batch 4715: loss 0.029236\n",
      "batch 4716: loss 0.094174\n",
      "batch 4717: loss 0.040417\n",
      "batch 4718: loss 0.014265\n",
      "batch 4719: loss 0.069386\n",
      "batch 4720: loss 0.054545\n",
      "batch 4721: loss 0.184554\n",
      "batch 4722: loss 0.024197\n",
      "batch 4723: loss 0.116799\n",
      "batch 4724: loss 0.012738\n",
      "batch 4725: loss 0.076646\n",
      "batch 4726: loss 0.026290\n",
      "batch 4727: loss 0.040655\n",
      "batch 4728: loss 0.041656\n",
      "batch 4729: loss 0.060814\n",
      "batch 4730: loss 0.039330\n",
      "batch 4731: loss 0.110384\n",
      "batch 4732: loss 0.009295\n",
      "batch 4733: loss 0.032222\n",
      "batch 4734: loss 0.036100\n",
      "batch 4735: loss 0.009334\n",
      "batch 4736: loss 0.152294\n",
      "batch 4737: loss 0.083207\n",
      "batch 4738: loss 0.025519\n",
      "batch 4739: loss 0.012200\n",
      "batch 4740: loss 0.066750\n",
      "batch 4741: loss 0.130116\n",
      "batch 4742: loss 0.023487\n",
      "batch 4743: loss 0.044738\n",
      "batch 4744: loss 0.077701\n",
      "batch 4745: loss 0.066836\n",
      "batch 4746: loss 0.101988\n",
      "batch 4747: loss 0.073011\n",
      "batch 4748: loss 0.056732\n",
      "batch 4749: loss 0.070392\n",
      "batch 4750: loss 0.005196\n",
      "batch 4751: loss 0.050970\n",
      "batch 4752: loss 0.021522\n",
      "batch 4753: loss 0.023282\n",
      "batch 4754: loss 0.055949\n",
      "batch 4755: loss 0.216104\n",
      "batch 4756: loss 0.036904\n",
      "batch 4757: loss 0.049551\n",
      "batch 4758: loss 0.158778\n",
      "batch 4759: loss 0.049440\n",
      "batch 4760: loss 0.017186\n",
      "batch 4761: loss 0.010430\n",
      "batch 4762: loss 0.049898\n",
      "batch 4763: loss 0.015464\n",
      "batch 4764: loss 0.015826\n",
      "batch 4765: loss 0.007009\n",
      "batch 4766: loss 0.047442\n",
      "batch 4767: loss 0.087749\n",
      "batch 4768: loss 0.050232\n",
      "batch 4769: loss 0.051778\n",
      "batch 4770: loss 0.054539\n",
      "batch 4771: loss 0.031321\n",
      "batch 4772: loss 0.050972\n",
      "batch 4773: loss 0.010593\n",
      "batch 4774: loss 0.020689\n",
      "batch 4775: loss 0.126521\n",
      "batch 4776: loss 0.016123\n",
      "batch 4777: loss 0.040924\n",
      "batch 4778: loss 0.006815\n",
      "batch 4779: loss 0.156131\n",
      "batch 4780: loss 0.014930\n",
      "batch 4781: loss 0.077493\n",
      "batch 4782: loss 0.024940\n",
      "batch 4783: loss 0.019825\n",
      "batch 4784: loss 0.066747\n",
      "batch 4785: loss 0.103375\n",
      "batch 4786: loss 0.042941\n",
      "batch 4787: loss 0.009018\n",
      "batch 4788: loss 0.027907\n",
      "batch 4789: loss 0.016334\n",
      "batch 4790: loss 0.053568\n",
      "batch 4791: loss 0.013992\n",
      "batch 4792: loss 0.038914\n",
      "batch 4793: loss 0.042289\n",
      "batch 4794: loss 0.033520\n",
      "batch 4795: loss 0.200664\n",
      "batch 4796: loss 0.093248\n",
      "batch 4797: loss 0.211865\n",
      "batch 4798: loss 0.078472\n",
      "batch 4799: loss 0.018809\n",
      "batch 4800: loss 0.018841\n",
      "batch 4801: loss 0.122918\n",
      "batch 4802: loss 0.030765\n",
      "batch 4803: loss 0.165027\n",
      "batch 4804: loss 0.163155\n",
      "batch 4805: loss 0.016279\n",
      "batch 4806: loss 0.037955\n",
      "batch 4807: loss 0.133882\n",
      "batch 4808: loss 0.021447\n",
      "batch 4809: loss 0.027912\n",
      "batch 4810: loss 0.101115\n",
      "batch 4811: loss 0.044269\n",
      "batch 4812: loss 0.153194\n",
      "batch 4813: loss 0.054443\n",
      "batch 4814: loss 0.072736\n",
      "batch 4815: loss 0.234307\n",
      "batch 4816: loss 0.027703\n",
      "batch 4817: loss 0.021837\n",
      "batch 4818: loss 0.052702\n",
      "batch 4819: loss 0.267372\n",
      "batch 4820: loss 0.038877\n",
      "batch 4821: loss 0.035585\n",
      "batch 4822: loss 0.006239\n",
      "batch 4823: loss 0.057697\n",
      "batch 4824: loss 0.046541\n",
      "batch 4825: loss 0.031063\n",
      "batch 4826: loss 0.064592\n",
      "batch 4827: loss 0.010562\n",
      "batch 4828: loss 0.045771\n",
      "batch 4829: loss 0.043153\n",
      "batch 4830: loss 0.052422\n",
      "batch 4831: loss 0.018600\n",
      "batch 4832: loss 0.064610\n",
      "batch 4833: loss 0.090314\n",
      "batch 4834: loss 0.035453\n",
      "batch 4835: loss 0.059507\n",
      "batch 4836: loss 0.051488\n",
      "batch 4837: loss 0.063637\n",
      "batch 4838: loss 0.018875\n",
      "batch 4839: loss 0.204030\n",
      "batch 4840: loss 0.151404\n",
      "batch 4841: loss 0.075009\n",
      "batch 4842: loss 0.077546\n",
      "batch 4843: loss 0.025397\n",
      "batch 4844: loss 0.026866\n",
      "batch 4845: loss 0.066888\n",
      "batch 4846: loss 0.010405\n",
      "batch 4847: loss 0.023757\n",
      "batch 4848: loss 0.081438\n",
      "batch 4849: loss 0.084522\n",
      "batch 4850: loss 0.028518\n",
      "batch 4851: loss 0.020839\n",
      "batch 4852: loss 0.009600\n",
      "batch 4853: loss 0.005653\n",
      "batch 4854: loss 0.057048\n",
      "batch 4855: loss 0.045722\n",
      "batch 4856: loss 0.050542\n",
      "batch 4857: loss 0.118868\n",
      "batch 4858: loss 0.030437\n",
      "batch 4859: loss 0.053716\n",
      "batch 4860: loss 0.085017\n",
      "batch 4861: loss 0.039026\n",
      "batch 4862: loss 0.023561\n",
      "batch 4863: loss 0.025000\n",
      "batch 4864: loss 0.114614\n",
      "batch 4865: loss 0.220636\n",
      "batch 4866: loss 0.017611\n",
      "batch 4867: loss 0.015292\n",
      "batch 4868: loss 0.144993\n",
      "batch 4869: loss 0.004939\n",
      "batch 4870: loss 0.012860\n",
      "batch 4871: loss 0.044641\n",
      "batch 4872: loss 0.018202\n",
      "batch 4873: loss 0.085772\n",
      "batch 4874: loss 0.025123\n",
      "batch 4875: loss 0.009735\n",
      "batch 4876: loss 0.087096\n",
      "batch 4877: loss 0.045940\n",
      "batch 4878: loss 0.061263\n",
      "batch 4879: loss 0.064438\n",
      "batch 4880: loss 0.060327\n",
      "batch 4881: loss 0.037498\n",
      "batch 4882: loss 0.173724\n",
      "batch 4883: loss 0.058505\n",
      "batch 4884: loss 0.027488\n",
      "batch 4885: loss 0.029750\n",
      "batch 4886: loss 0.034832\n",
      "batch 4887: loss 0.135376\n",
      "batch 4888: loss 0.050332\n",
      "batch 4889: loss 0.013206\n",
      "batch 4890: loss 0.063798\n",
      "batch 4891: loss 0.025213\n",
      "batch 4892: loss 0.144164\n",
      "batch 4893: loss 0.124290\n",
      "batch 4894: loss 0.017604\n",
      "batch 4895: loss 0.089676\n",
      "batch 4896: loss 0.111157\n",
      "batch 4897: loss 0.109689\n",
      "batch 4898: loss 0.015985\n",
      "batch 4899: loss 0.017966\n",
      "batch 4900: loss 0.072511\n",
      "batch 4901: loss 0.020840\n",
      "batch 4902: loss 0.026986\n",
      "batch 4903: loss 0.040508\n",
      "batch 4904: loss 0.044611\n",
      "batch 4905: loss 0.075057\n",
      "batch 4906: loss 0.085950\n",
      "batch 4907: loss 0.018532\n",
      "batch 4908: loss 0.041639\n",
      "batch 4909: loss 0.098160\n",
      "batch 4910: loss 0.113912\n",
      "batch 4911: loss 0.041182\n",
      "batch 4912: loss 0.052409\n",
      "batch 4913: loss 0.013377\n",
      "batch 4914: loss 0.058462\n",
      "batch 4915: loss 0.063733\n",
      "batch 4916: loss 0.025153\n",
      "batch 4917: loss 0.019179\n",
      "batch 4918: loss 0.054372\n",
      "batch 4919: loss 0.139072\n",
      "batch 4920: loss 0.044607\n",
      "batch 4921: loss 0.105574\n",
      "batch 4922: loss 0.059027\n",
      "batch 4923: loss 0.035572\n",
      "batch 4924: loss 0.032322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4925: loss 0.059068\n",
      "batch 4926: loss 0.024068\n",
      "batch 4927: loss 0.008375\n",
      "batch 4928: loss 0.014386\n",
      "batch 4929: loss 0.037972\n",
      "batch 4930: loss 0.007925\n",
      "batch 4931: loss 0.049006\n",
      "batch 4932: loss 0.040981\n",
      "batch 4933: loss 0.023075\n",
      "batch 4934: loss 0.061384\n",
      "batch 4935: loss 0.053056\n",
      "batch 4936: loss 0.109165\n",
      "batch 4937: loss 0.132044\n",
      "batch 4938: loss 0.027464\n",
      "batch 4939: loss 0.142891\n",
      "batch 4940: loss 0.068196\n",
      "batch 4941: loss 0.034645\n",
      "batch 4942: loss 0.014634\n",
      "batch 4943: loss 0.009962\n",
      "batch 4944: loss 0.171067\n",
      "batch 4945: loss 0.110138\n",
      "batch 4946: loss 0.053149\n",
      "batch 4947: loss 0.060241\n",
      "batch 4948: loss 0.019837\n",
      "batch 4949: loss 0.021466\n",
      "batch 4950: loss 0.053432\n",
      "batch 4951: loss 0.044486\n",
      "batch 4952: loss 0.043553\n",
      "batch 4953: loss 0.189424\n",
      "batch 4954: loss 0.050736\n",
      "batch 4955: loss 0.182849\n",
      "batch 4956: loss 0.034988\n",
      "batch 4957: loss 0.104446\n",
      "batch 4958: loss 0.065058\n",
      "batch 4959: loss 0.016486\n",
      "batch 4960: loss 0.205147\n",
      "batch 4961: loss 0.023791\n",
      "batch 4962: loss 0.050722\n",
      "batch 4963: loss 0.056844\n",
      "batch 4964: loss 0.084259\n",
      "batch 4965: loss 0.032384\n",
      "batch 4966: loss 0.207382\n",
      "batch 4967: loss 0.017130\n",
      "batch 4968: loss 0.041886\n",
      "batch 4969: loss 0.068898\n",
      "batch 4970: loss 0.035167\n",
      "batch 4971: loss 0.048662\n",
      "batch 4972: loss 0.035260\n",
      "batch 4973: loss 0.046257\n",
      "batch 4974: loss 0.025398\n",
      "batch 4975: loss 0.067921\n",
      "batch 4976: loss 0.063767\n",
      "batch 4977: loss 0.019287\n",
      "batch 4978: loss 0.076335\n",
      "batch 4979: loss 0.013134\n",
      "batch 4980: loss 0.180057\n",
      "batch 4981: loss 0.028210\n",
      "batch 4982: loss 0.018112\n",
      "batch 4983: loss 0.061785\n",
      "batch 4984: loss 0.110388\n",
      "batch 4985: loss 0.022970\n",
      "batch 4986: loss 0.078666\n",
      "batch 4987: loss 0.019171\n",
      "batch 4988: loss 0.015698\n",
      "batch 4989: loss 0.029352\n",
      "batch 4990: loss 0.014905\n",
      "batch 4991: loss 0.009254\n",
      "batch 4992: loss 0.058219\n",
      "batch 4993: loss 0.073914\n",
      "batch 4994: loss 0.090019\n",
      "batch 4995: loss 0.031806\n",
      "batch 4996: loss 0.042676\n",
      "batch 4997: loss 0.073564\n",
      "batch 4998: loss 0.137263\n",
      "batch 4999: loss 0.090887\n",
      "batch 5000: loss 0.046179\n",
      "batch 5001: loss 0.068511\n",
      "batch 5002: loss 0.014292\n",
      "batch 5003: loss 0.067530\n",
      "batch 5004: loss 0.022864\n",
      "batch 5005: loss 0.036017\n",
      "batch 5006: loss 0.037052\n",
      "batch 5007: loss 0.027575\n",
      "batch 5008: loss 0.026352\n",
      "batch 5009: loss 0.054587\n",
      "batch 5010: loss 0.023885\n",
      "batch 5011: loss 0.120079\n",
      "batch 5012: loss 0.056891\n",
      "batch 5013: loss 0.043917\n",
      "batch 5014: loss 0.022033\n",
      "batch 5015: loss 0.106066\n",
      "batch 5016: loss 0.057641\n",
      "batch 5017: loss 0.036893\n",
      "batch 5018: loss 0.079072\n",
      "batch 5019: loss 0.065424\n",
      "batch 5020: loss 0.110663\n",
      "batch 5021: loss 0.072740\n",
      "batch 5022: loss 0.056401\n",
      "batch 5023: loss 0.014591\n",
      "batch 5024: loss 0.073206\n",
      "batch 5025: loss 0.045110\n",
      "batch 5026: loss 0.042601\n",
      "batch 5027: loss 0.175642\n",
      "batch 5028: loss 0.110308\n",
      "batch 5029: loss 0.041822\n",
      "batch 5030: loss 0.053351\n",
      "batch 5031: loss 0.091401\n",
      "batch 5032: loss 0.054262\n",
      "batch 5033: loss 0.050947\n",
      "batch 5034: loss 0.021435\n",
      "batch 5035: loss 0.005381\n",
      "batch 5036: loss 0.094852\n",
      "batch 5037: loss 0.019848\n",
      "batch 5038: loss 0.104079\n",
      "batch 5039: loss 0.072859\n",
      "batch 5040: loss 0.027685\n",
      "batch 5041: loss 0.085809\n",
      "batch 5042: loss 0.038568\n",
      "batch 5043: loss 0.028430\n",
      "batch 5044: loss 0.039878\n",
      "batch 5045: loss 0.063446\n",
      "batch 5046: loss 0.064199\n",
      "batch 5047: loss 0.065893\n",
      "batch 5048: loss 0.021580\n",
      "batch 5049: loss 0.033984\n",
      "batch 5050: loss 0.100299\n",
      "batch 5051: loss 0.075948\n",
      "batch 5052: loss 0.125819\n",
      "batch 5053: loss 0.023159\n",
      "batch 5054: loss 0.020790\n",
      "batch 5055: loss 0.052665\n",
      "batch 5056: loss 0.177465\n",
      "batch 5057: loss 0.211613\n",
      "batch 5058: loss 0.107137\n",
      "batch 5059: loss 0.076429\n",
      "batch 5060: loss 0.089561\n",
      "batch 5061: loss 0.053766\n",
      "batch 5062: loss 0.039400\n",
      "batch 5063: loss 0.087723\n",
      "batch 5064: loss 0.227040\n",
      "batch 5065: loss 0.053997\n",
      "batch 5066: loss 0.083308\n",
      "batch 5067: loss 0.059656\n",
      "batch 5068: loss 0.030883\n",
      "batch 5069: loss 0.070463\n",
      "batch 5070: loss 0.010169\n",
      "batch 5071: loss 0.046955\n",
      "batch 5072: loss 0.032219\n",
      "batch 5073: loss 0.073509\n",
      "batch 5074: loss 0.031775\n",
      "batch 5075: loss 0.097236\n",
      "batch 5076: loss 0.054477\n",
      "batch 5077: loss 0.037546\n",
      "batch 5078: loss 0.057896\n",
      "batch 5079: loss 0.032946\n",
      "batch 5080: loss 0.025870\n",
      "batch 5081: loss 0.018893\n",
      "batch 5082: loss 0.026162\n",
      "batch 5083: loss 0.082402\n",
      "batch 5084: loss 0.036095\n",
      "batch 5085: loss 0.041343\n",
      "batch 5086: loss 0.019177\n",
      "batch 5087: loss 0.083836\n",
      "batch 5088: loss 0.045890\n",
      "batch 5089: loss 0.050414\n",
      "batch 5090: loss 0.023244\n",
      "batch 5091: loss 0.051294\n",
      "batch 5092: loss 0.075454\n",
      "batch 5093: loss 0.015267\n",
      "batch 5094: loss 0.042727\n",
      "batch 5095: loss 0.029804\n",
      "batch 5096: loss 0.014579\n",
      "batch 5097: loss 0.164146\n",
      "batch 5098: loss 0.043391\n",
      "batch 5099: loss 0.086402\n",
      "batch 5100: loss 0.033564\n",
      "batch 5101: loss 0.085735\n",
      "batch 5102: loss 0.091271\n",
      "batch 5103: loss 0.039816\n",
      "batch 5104: loss 0.036296\n",
      "batch 5105: loss 0.035952\n",
      "batch 5106: loss 0.051509\n",
      "batch 5107: loss 0.018849\n",
      "batch 5108: loss 0.043783\n",
      "batch 5109: loss 0.034475\n",
      "batch 5110: loss 0.038418\n",
      "batch 5111: loss 0.035952\n",
      "batch 5112: loss 0.055653\n",
      "batch 5113: loss 0.033193\n",
      "batch 5114: loss 0.008730\n",
      "batch 5115: loss 0.028061\n",
      "batch 5116: loss 0.003707\n",
      "batch 5117: loss 0.010413\n",
      "batch 5118: loss 0.036793\n",
      "batch 5119: loss 0.022731\n",
      "batch 5120: loss 0.029862\n",
      "batch 5121: loss 0.017693\n",
      "batch 5122: loss 0.023832\n",
      "batch 5123: loss 0.051282\n",
      "batch 5124: loss 0.039280\n",
      "batch 5125: loss 0.075071\n",
      "batch 5126: loss 0.017489\n",
      "batch 5127: loss 0.026159\n",
      "batch 5128: loss 0.018693\n",
      "batch 5129: loss 0.030977\n",
      "batch 5130: loss 0.018012\n",
      "batch 5131: loss 0.034311\n",
      "batch 5132: loss 0.018923\n",
      "batch 5133: loss 0.093495\n",
      "batch 5134: loss 0.091378\n",
      "batch 5135: loss 0.026535\n",
      "batch 5136: loss 0.049376\n",
      "batch 5137: loss 0.038957\n",
      "batch 5138: loss 0.021351\n",
      "batch 5139: loss 0.010970\n",
      "batch 5140: loss 0.019365\n",
      "batch 5141: loss 0.054126\n",
      "batch 5142: loss 0.069797\n",
      "batch 5143: loss 0.026074\n",
      "batch 5144: loss 0.089925\n",
      "batch 5145: loss 0.056462\n",
      "batch 5146: loss 0.020582\n",
      "batch 5147: loss 0.020188\n",
      "batch 5148: loss 0.023271\n",
      "batch 5149: loss 0.040023\n",
      "batch 5150: loss 0.014368\n",
      "batch 5151: loss 0.097869\n",
      "batch 5152: loss 0.072430\n",
      "batch 5153: loss 0.017281\n",
      "batch 5154: loss 0.077766\n",
      "batch 5155: loss 0.051564\n",
      "batch 5156: loss 0.077007\n",
      "batch 5157: loss 0.023698\n",
      "batch 5158: loss 0.131858\n",
      "batch 5159: loss 0.013287\n",
      "batch 5160: loss 0.018767\n",
      "batch 5161: loss 0.092451\n",
      "batch 5162: loss 0.015609\n",
      "batch 5163: loss 0.019725\n",
      "batch 5164: loss 0.010418\n",
      "batch 5165: loss 0.009394\n",
      "batch 5166: loss 0.018218\n",
      "batch 5167: loss 0.091168\n",
      "batch 5168: loss 0.014821\n",
      "batch 5169: loss 0.032881\n",
      "batch 5170: loss 0.016376\n",
      "batch 5171: loss 0.161293\n",
      "batch 5172: loss 0.043507\n",
      "batch 5173: loss 0.003917\n",
      "batch 5174: loss 0.106245\n",
      "batch 5175: loss 0.140751\n",
      "batch 5176: loss 0.018676\n",
      "batch 5177: loss 0.053400\n",
      "batch 5178: loss 0.020436\n",
      "batch 5179: loss 0.042659\n",
      "batch 5180: loss 0.053909\n",
      "batch 5181: loss 0.044662\n",
      "batch 5182: loss 0.169179\n",
      "batch 5183: loss 0.078899\n",
      "batch 5184: loss 0.036634\n",
      "batch 5185: loss 0.034793\n",
      "batch 5186: loss 0.070280\n",
      "batch 5187: loss 0.020831\n",
      "batch 5188: loss 0.014938\n",
      "batch 5189: loss 0.080177\n",
      "batch 5190: loss 0.008626\n",
      "batch 5191: loss 0.038830\n",
      "batch 5192: loss 0.027007\n",
      "batch 5193: loss 0.050668\n",
      "batch 5194: loss 0.023077\n",
      "batch 5195: loss 0.053124\n",
      "batch 5196: loss 0.070894\n",
      "batch 5197: loss 0.021061\n",
      "batch 5198: loss 0.021016\n",
      "batch 5199: loss 0.022554\n",
      "batch 5200: loss 0.150865\n",
      "batch 5201: loss 0.142678\n",
      "batch 5202: loss 0.075165\n",
      "batch 5203: loss 0.087262\n",
      "batch 5204: loss 0.047789\n",
      "batch 5205: loss 0.016510\n",
      "batch 5206: loss 0.025760\n",
      "batch 5207: loss 0.019463\n",
      "batch 5208: loss 0.151771\n",
      "batch 5209: loss 0.060847\n",
      "batch 5210: loss 0.055930\n",
      "batch 5211: loss 0.030402\n",
      "batch 5212: loss 0.166808\n",
      "batch 5213: loss 0.136970\n",
      "batch 5214: loss 0.031150\n",
      "batch 5215: loss 0.029656\n",
      "batch 5216: loss 0.037756\n",
      "batch 5217: loss 0.037602\n",
      "batch 5218: loss 0.070796\n",
      "batch 5219: loss 0.094375\n",
      "batch 5220: loss 0.044989\n",
      "batch 5221: loss 0.022526\n",
      "batch 5222: loss 0.061986\n",
      "batch 5223: loss 0.057593\n",
      "batch 5224: loss 0.032340\n",
      "batch 5225: loss 0.100942\n",
      "batch 5226: loss 0.018709\n",
      "batch 5227: loss 0.027916\n",
      "batch 5228: loss 0.038442\n",
      "batch 5229: loss 0.023340\n",
      "batch 5230: loss 0.047959\n",
      "batch 5231: loss 0.061878\n",
      "batch 5232: loss 0.013011\n",
      "batch 5233: loss 0.024906\n",
      "batch 5234: loss 0.028078\n",
      "batch 5235: loss 0.029285\n",
      "batch 5236: loss 0.167234\n",
      "batch 5237: loss 0.043211\n",
      "batch 5238: loss 0.026833\n",
      "batch 5239: loss 0.038431\n",
      "batch 5240: loss 0.031296\n",
      "batch 5241: loss 0.018033\n",
      "batch 5242: loss 0.128084\n",
      "batch 5243: loss 0.033574\n",
      "batch 5244: loss 0.041516\n",
      "batch 5245: loss 0.016866\n",
      "batch 5246: loss 0.016913\n",
      "batch 5247: loss 0.037495\n",
      "batch 5248: loss 0.027726\n",
      "batch 5249: loss 0.063050\n",
      "batch 5250: loss 0.015603\n",
      "batch 5251: loss 0.067926\n",
      "batch 5252: loss 0.075993\n",
      "batch 5253: loss 0.016876\n",
      "batch 5254: loss 0.068767\n",
      "batch 5255: loss 0.085665\n",
      "batch 5256: loss 0.050988\n",
      "batch 5257: loss 0.029807\n",
      "batch 5258: loss 0.081439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5259: loss 0.012181\n",
      "batch 5260: loss 0.042393\n",
      "batch 5261: loss 0.032362\n",
      "batch 5262: loss 0.030788\n",
      "batch 5263: loss 0.030735\n",
      "batch 5264: loss 0.042034\n",
      "batch 5265: loss 0.031638\n",
      "batch 5266: loss 0.037420\n",
      "batch 5267: loss 0.163279\n",
      "batch 5268: loss 0.086296\n",
      "batch 5269: loss 0.031362\n",
      "batch 5270: loss 0.113860\n",
      "batch 5271: loss 0.029407\n",
      "batch 5272: loss 0.068642\n",
      "batch 5273: loss 0.157731\n",
      "batch 5274: loss 0.052617\n",
      "batch 5275: loss 0.021486\n",
      "batch 5276: loss 0.076284\n",
      "batch 5277: loss 0.103882\n",
      "batch 5278: loss 0.039706\n",
      "batch 5279: loss 0.054951\n",
      "batch 5280: loss 0.041249\n",
      "batch 5281: loss 0.109525\n",
      "batch 5282: loss 0.013946\n",
      "batch 5283: loss 0.044263\n",
      "batch 5284: loss 0.029460\n",
      "batch 5285: loss 0.038420\n",
      "batch 5286: loss 0.045486\n",
      "batch 5287: loss 0.043933\n",
      "batch 5288: loss 0.010934\n",
      "batch 5289: loss 0.065579\n",
      "batch 5290: loss 0.034338\n",
      "batch 5291: loss 0.186293\n",
      "batch 5292: loss 0.054375\n",
      "batch 5293: loss 0.013441\n",
      "batch 5294: loss 0.056478\n",
      "batch 5295: loss 0.040187\n",
      "batch 5296: loss 0.014858\n",
      "batch 5297: loss 0.055489\n",
      "batch 5298: loss 0.033708\n",
      "batch 5299: loss 0.101810\n",
      "batch 5300: loss 0.041990\n",
      "batch 5301: loss 0.110183\n",
      "batch 5302: loss 0.144251\n",
      "batch 5303: loss 0.079589\n",
      "batch 5304: loss 0.015304\n",
      "batch 5305: loss 0.008822\n",
      "batch 5306: loss 0.021674\n",
      "batch 5307: loss 0.055123\n",
      "batch 5308: loss 0.059543\n",
      "batch 5309: loss 0.058301\n",
      "batch 5310: loss 0.009851\n",
      "batch 5311: loss 0.022706\n",
      "batch 5312: loss 0.027648\n",
      "batch 5313: loss 0.047929\n",
      "batch 5314: loss 0.063855\n",
      "batch 5315: loss 0.018285\n",
      "batch 5316: loss 0.055602\n",
      "batch 5317: loss 0.036138\n",
      "batch 5318: loss 0.060661\n",
      "batch 5319: loss 0.019249\n",
      "batch 5320: loss 0.018019\n",
      "batch 5321: loss 0.072258\n",
      "batch 5322: loss 0.016199\n",
      "batch 5323: loss 0.010511\n",
      "batch 5324: loss 0.102045\n",
      "batch 5325: loss 0.013217\n",
      "batch 5326: loss 0.058502\n",
      "batch 5327: loss 0.087867\n",
      "batch 5328: loss 0.035406\n",
      "batch 5329: loss 0.085436\n",
      "batch 5330: loss 0.021989\n",
      "batch 5331: loss 0.017756\n",
      "batch 5332: loss 0.088895\n",
      "batch 5333: loss 0.129871\n",
      "batch 5334: loss 0.127853\n",
      "batch 5335: loss 0.013586\n",
      "batch 5336: loss 0.094057\n",
      "batch 5337: loss 0.026142\n",
      "batch 5338: loss 0.049338\n",
      "batch 5339: loss 0.107997\n",
      "batch 5340: loss 0.020863\n",
      "batch 5341: loss 0.115827\n",
      "batch 5342: loss 0.009636\n",
      "batch 5343: loss 0.026373\n",
      "batch 5344: loss 0.089559\n",
      "batch 5345: loss 0.108716\n",
      "batch 5346: loss 0.054966\n",
      "batch 5347: loss 0.006368\n",
      "batch 5348: loss 0.040059\n",
      "batch 5349: loss 0.053094\n",
      "batch 5350: loss 0.019343\n",
      "batch 5351: loss 0.039597\n",
      "batch 5352: loss 0.094318\n",
      "batch 5353: loss 0.094150\n",
      "batch 5354: loss 0.014704\n",
      "batch 5355: loss 0.082926\n",
      "batch 5356: loss 0.066106\n",
      "batch 5357: loss 0.077163\n",
      "batch 5358: loss 0.039702\n",
      "batch 5359: loss 0.040506\n",
      "batch 5360: loss 0.061418\n",
      "batch 5361: loss 0.074264\n",
      "batch 5362: loss 0.050997\n",
      "batch 5363: loss 0.054777\n",
      "batch 5364: loss 0.041090\n",
      "batch 5365: loss 0.104476\n",
      "batch 5366: loss 0.011427\n",
      "batch 5367: loss 0.009616\n",
      "batch 5368: loss 0.127443\n",
      "batch 5369: loss 0.008522\n",
      "batch 5370: loss 0.096421\n",
      "batch 5371: loss 0.020856\n",
      "batch 5372: loss 0.032405\n",
      "batch 5373: loss 0.059090\n",
      "batch 5374: loss 0.017910\n",
      "batch 5375: loss 0.148247\n",
      "batch 5376: loss 0.042226\n",
      "batch 5377: loss 0.022797\n",
      "batch 5378: loss 0.082359\n",
      "batch 5379: loss 0.034672\n",
      "batch 5380: loss 0.096979\n",
      "batch 5381: loss 0.062351\n",
      "batch 5382: loss 0.043271\n",
      "batch 5383: loss 0.095908\n",
      "batch 5384: loss 0.020939\n",
      "batch 5385: loss 0.082950\n",
      "batch 5386: loss 0.007601\n",
      "batch 5387: loss 0.047731\n",
      "batch 5388: loss 0.026663\n",
      "batch 5389: loss 0.069119\n",
      "batch 5390: loss 0.056536\n",
      "batch 5391: loss 0.042111\n",
      "batch 5392: loss 0.044243\n",
      "batch 5393: loss 0.026754\n",
      "batch 5394: loss 0.042722\n",
      "batch 5395: loss 0.137142\n",
      "batch 5396: loss 0.023856\n",
      "batch 5397: loss 0.051709\n",
      "batch 5398: loss 0.066115\n",
      "batch 5399: loss 0.093277\n",
      "batch 5400: loss 0.023507\n",
      "batch 5401: loss 0.014495\n",
      "batch 5402: loss 0.019186\n",
      "batch 5403: loss 0.016317\n",
      "batch 5404: loss 0.126104\n",
      "batch 5405: loss 0.078412\n",
      "batch 5406: loss 0.007047\n",
      "batch 5407: loss 0.184312\n",
      "batch 5408: loss 0.027016\n",
      "batch 5409: loss 0.063471\n",
      "batch 5410: loss 0.059839\n",
      "batch 5411: loss 0.040082\n",
      "batch 5412: loss 0.017812\n",
      "batch 5413: loss 0.088187\n",
      "batch 5414: loss 0.059865\n",
      "batch 5415: loss 0.166102\n",
      "batch 5416: loss 0.019028\n",
      "batch 5417: loss 0.187029\n",
      "batch 5418: loss 0.058107\n",
      "batch 5419: loss 0.014780\n",
      "batch 5420: loss 0.030034\n",
      "batch 5421: loss 0.030575\n",
      "batch 5422: loss 0.013617\n",
      "batch 5423: loss 0.094176\n",
      "batch 5424: loss 0.028318\n",
      "batch 5425: loss 0.062485\n",
      "batch 5426: loss 0.009553\n",
      "batch 5427: loss 0.024190\n",
      "batch 5428: loss 0.010216\n",
      "batch 5429: loss 0.108514\n",
      "batch 5430: loss 0.126292\n",
      "batch 5431: loss 0.024041\n",
      "batch 5432: loss 0.076691\n",
      "batch 5433: loss 0.051832\n",
      "batch 5434: loss 0.039992\n",
      "batch 5435: loss 0.057137\n",
      "batch 5436: loss 0.116874\n",
      "batch 5437: loss 0.143685\n",
      "batch 5438: loss 0.022605\n",
      "batch 5439: loss 0.006588\n",
      "batch 5440: loss 0.026075\n",
      "batch 5441: loss 0.058046\n",
      "batch 5442: loss 0.021305\n",
      "batch 5443: loss 0.066161\n",
      "batch 5444: loss 0.120165\n",
      "batch 5445: loss 0.019694\n",
      "batch 5446: loss 0.049405\n",
      "batch 5447: loss 0.016600\n",
      "batch 5448: loss 0.015418\n",
      "batch 5449: loss 0.054718\n",
      "batch 5450: loss 0.022720\n",
      "batch 5451: loss 0.082979\n",
      "batch 5452: loss 0.019897\n",
      "batch 5453: loss 0.019746\n",
      "batch 5454: loss 0.018758\n",
      "batch 5455: loss 0.044228\n",
      "batch 5456: loss 0.038543\n",
      "batch 5457: loss 0.019167\n",
      "batch 5458: loss 0.045542\n",
      "batch 5459: loss 0.061151\n",
      "batch 5460: loss 0.012953\n",
      "batch 5461: loss 0.074437\n",
      "batch 5462: loss 0.270924\n",
      "batch 5463: loss 0.012891\n",
      "batch 5464: loss 0.055611\n",
      "batch 5465: loss 0.019445\n",
      "batch 5466: loss 0.101355\n",
      "batch 5467: loss 0.105361\n",
      "batch 5468: loss 0.058777\n",
      "batch 5469: loss 0.408257\n",
      "batch 5470: loss 0.130074\n",
      "batch 5471: loss 0.060201\n",
      "batch 5472: loss 0.044133\n",
      "batch 5473: loss 0.019365\n",
      "batch 5474: loss 0.031233\n",
      "batch 5475: loss 0.054043\n",
      "batch 5476: loss 0.010781\n",
      "batch 5477: loss 0.017262\n",
      "batch 5478: loss 0.013938\n",
      "batch 5479: loss 0.025302\n",
      "batch 5480: loss 0.176479\n",
      "batch 5481: loss 0.059211\n",
      "batch 5482: loss 0.105691\n",
      "batch 5483: loss 0.040407\n",
      "batch 5484: loss 0.019553\n",
      "batch 5485: loss 0.015878\n",
      "batch 5486: loss 0.056033\n",
      "batch 5487: loss 0.038091\n",
      "batch 5488: loss 0.020168\n",
      "batch 5489: loss 0.222461\n",
      "batch 5490: loss 0.133573\n",
      "batch 5491: loss 0.036030\n",
      "batch 5492: loss 0.045004\n",
      "batch 5493: loss 0.026866\n",
      "batch 5494: loss 0.021275\n",
      "batch 5495: loss 0.035594\n",
      "batch 5496: loss 0.049542\n",
      "batch 5497: loss 0.100071\n",
      "batch 5498: loss 0.043034\n",
      "batch 5499: loss 0.076305\n",
      "batch 5500: loss 0.192568\n",
      "batch 5501: loss 0.052089\n",
      "batch 5502: loss 0.062118\n",
      "batch 5503: loss 0.023972\n",
      "batch 5504: loss 0.065501\n",
      "batch 5505: loss 0.011448\n",
      "batch 5506: loss 0.020097\n",
      "batch 5507: loss 0.026966\n",
      "batch 5508: loss 0.042447\n",
      "batch 5509: loss 0.016445\n",
      "batch 5510: loss 0.087226\n",
      "batch 5511: loss 0.180575\n",
      "batch 5512: loss 0.046863\n",
      "batch 5513: loss 0.039549\n",
      "batch 5514: loss 0.032700\n",
      "batch 5515: loss 0.084541\n",
      "batch 5516: loss 0.024600\n",
      "batch 5517: loss 0.026505\n",
      "batch 5518: loss 0.055800\n",
      "batch 5519: loss 0.038825\n",
      "batch 5520: loss 0.089840\n",
      "batch 5521: loss 0.057742\n",
      "batch 5522: loss 0.104141\n",
      "batch 5523: loss 0.014909\n",
      "batch 5524: loss 0.031217\n",
      "batch 5525: loss 0.027389\n",
      "batch 5526: loss 0.082251\n",
      "batch 5527: loss 0.031451\n",
      "batch 5528: loss 0.024410\n",
      "batch 5529: loss 0.061921\n",
      "batch 5530: loss 0.053125\n",
      "batch 5531: loss 0.109089\n",
      "batch 5532: loss 0.039309\n",
      "batch 5533: loss 0.117712\n",
      "batch 5534: loss 0.038507\n",
      "batch 5535: loss 0.021961\n",
      "batch 5536: loss 0.113237\n",
      "batch 5537: loss 0.053509\n",
      "batch 5538: loss 0.023577\n",
      "batch 5539: loss 0.017040\n",
      "batch 5540: loss 0.094243\n",
      "batch 5541: loss 0.053464\n",
      "batch 5542: loss 0.040907\n",
      "batch 5543: loss 0.008609\n",
      "batch 5544: loss 0.060760\n",
      "batch 5545: loss 0.010826\n",
      "batch 5546: loss 0.011412\n",
      "batch 5547: loss 0.071073\n",
      "batch 5548: loss 0.103321\n",
      "batch 5549: loss 0.010687\n",
      "batch 5550: loss 0.037514\n",
      "batch 5551: loss 0.045327\n",
      "batch 5552: loss 0.056961\n",
      "batch 5553: loss 0.216161\n",
      "batch 5554: loss 0.007437\n",
      "batch 5555: loss 0.029217\n",
      "batch 5556: loss 0.024431\n",
      "batch 5557: loss 0.011699\n",
      "batch 5558: loss 0.105817\n",
      "batch 5559: loss 0.016491\n",
      "batch 5560: loss 0.036860\n",
      "batch 5561: loss 0.053397\n",
      "batch 5562: loss 0.023978\n",
      "batch 5563: loss 0.021758\n",
      "batch 5564: loss 0.139893\n",
      "batch 5565: loss 0.083298\n",
      "batch 5566: loss 0.050895\n",
      "batch 5567: loss 0.104784\n",
      "batch 5568: loss 0.012062\n",
      "batch 5569: loss 0.091377\n",
      "batch 5570: loss 0.025796\n",
      "batch 5571: loss 0.020954\n",
      "batch 5572: loss 0.054267\n",
      "batch 5573: loss 0.002471\n",
      "batch 5574: loss 0.006608\n",
      "batch 5575: loss 0.028422\n",
      "batch 5576: loss 0.036222\n",
      "batch 5577: loss 0.069514\n",
      "batch 5578: loss 0.121420\n",
      "batch 5579: loss 0.035406\n",
      "batch 5580: loss 0.063002\n",
      "batch 5581: loss 0.020243\n",
      "batch 5582: loss 0.034618\n",
      "batch 5583: loss 0.010931\n",
      "batch 5584: loss 0.066341\n",
      "batch 5585: loss 0.056846\n",
      "batch 5586: loss 0.022510\n",
      "batch 5587: loss 0.026829\n",
      "batch 5588: loss 0.047953\n",
      "batch 5589: loss 0.097165\n",
      "batch 5590: loss 0.030727\n",
      "batch 5591: loss 0.092127\n",
      "batch 5592: loss 0.006134\n",
      "batch 5593: loss 0.010772\n",
      "batch 5594: loss 0.019130\n",
      "batch 5595: loss 0.018196\n",
      "batch 5596: loss 0.046954\n",
      "batch 5597: loss 0.016789\n",
      "batch 5598: loss 0.132754\n",
      "batch 5599: loss 0.040498\n",
      "batch 5600: loss 0.207485\n",
      "batch 5601: loss 0.013463\n",
      "batch 5602: loss 0.050801\n",
      "batch 5603: loss 0.029025\n",
      "batch 5604: loss 0.084564\n",
      "batch 5605: loss 0.066301\n",
      "batch 5606: loss 0.107688\n",
      "batch 5607: loss 0.039239\n",
      "batch 5608: loss 0.013713\n",
      "batch 5609: loss 0.034121\n",
      "batch 5610: loss 0.043736\n",
      "batch 5611: loss 0.050070\n",
      "batch 5612: loss 0.022645\n",
      "batch 5613: loss 0.010582\n",
      "batch 5614: loss 0.050809\n",
      "batch 5615: loss 0.121183\n",
      "batch 5616: loss 0.035253\n",
      "batch 5617: loss 0.056665\n",
      "batch 5618: loss 0.024608\n",
      "batch 5619: loss 0.015947\n",
      "batch 5620: loss 0.028690\n",
      "batch 5621: loss 0.035967\n",
      "batch 5622: loss 0.055711\n",
      "batch 5623: loss 0.032204\n",
      "batch 5624: loss 0.017190\n",
      "batch 5625: loss 0.015302\n",
      "batch 5626: loss 0.043603\n",
      "batch 5627: loss 0.027651\n",
      "batch 5628: loss 0.068654\n",
      "batch 5629: loss 0.067362\n",
      "batch 5630: loss 0.076518\n",
      "batch 5631: loss 0.037148\n",
      "batch 5632: loss 0.095922\n",
      "batch 5633: loss 0.138676\n",
      "batch 5634: loss 0.042452\n",
      "batch 5635: loss 0.020102\n",
      "batch 5636: loss 0.009432\n",
      "batch 5637: loss 0.033305\n",
      "batch 5638: loss 0.067777\n",
      "batch 5639: loss 0.027750\n",
      "batch 5640: loss 0.107503\n",
      "batch 5641: loss 0.022246\n",
      "batch 5642: loss 0.018536\n",
      "batch 5643: loss 0.103726\n",
      "batch 5644: loss 0.024958\n",
      "batch 5645: loss 0.152259\n",
      "batch 5646: loss 0.085579\n",
      "batch 5647: loss 0.036364\n",
      "batch 5648: loss 0.040107\n",
      "batch 5649: loss 0.015122\n",
      "batch 5650: loss 0.016181\n",
      "batch 5651: loss 0.017052\n",
      "batch 5652: loss 0.059393\n",
      "batch 5653: loss 0.168184\n",
      "batch 5654: loss 0.047110\n",
      "batch 5655: loss 0.027616\n",
      "batch 5656: loss 0.165291\n",
      "batch 5657: loss 0.061770\n",
      "batch 5658: loss 0.029138\n",
      "batch 5659: loss 0.019720\n",
      "batch 5660: loss 0.012344\n",
      "batch 5661: loss 0.121148\n",
      "batch 5662: loss 0.037436\n",
      "batch 5663: loss 0.026236\n",
      "batch 5664: loss 0.027738\n",
      "batch 5665: loss 0.020425\n",
      "batch 5666: loss 0.090847\n",
      "batch 5667: loss 0.044916\n",
      "batch 5668: loss 0.124801\n",
      "batch 5669: loss 0.081345\n",
      "batch 5670: loss 0.046475\n",
      "batch 5671: loss 0.026866\n",
      "batch 5672: loss 0.055663\n",
      "batch 5673: loss 0.026593\n",
      "batch 5674: loss 0.035603\n",
      "batch 5675: loss 0.187662\n",
      "batch 5676: loss 0.015956\n",
      "batch 5677: loss 0.014864\n",
      "batch 5678: loss 0.047585\n",
      "batch 5679: loss 0.029514\n",
      "batch 5680: loss 0.105967\n",
      "batch 5681: loss 0.282287\n",
      "batch 5682: loss 0.067027\n",
      "batch 5683: loss 0.058031\n",
      "batch 5684: loss 0.031327\n",
      "batch 5685: loss 0.029561\n",
      "batch 5686: loss 0.024518\n",
      "batch 5687: loss 0.023324\n",
      "batch 5688: loss 0.017458\n",
      "batch 5689: loss 0.030122\n",
      "batch 5690: loss 0.076795\n",
      "batch 5691: loss 0.123477\n",
      "batch 5692: loss 0.143625\n",
      "batch 5693: loss 0.006272\n",
      "batch 5694: loss 0.012310\n",
      "batch 5695: loss 0.037799\n",
      "batch 5696: loss 0.029497\n",
      "batch 5697: loss 0.026040\n",
      "batch 5698: loss 0.033810\n",
      "batch 5699: loss 0.036647\n",
      "batch 5700: loss 0.008539\n",
      "batch 5701: loss 0.056150\n",
      "batch 5702: loss 0.026818\n",
      "batch 5703: loss 0.011199\n",
      "batch 5704: loss 0.067522\n",
      "batch 5705: loss 0.021840\n",
      "batch 5706: loss 0.028077\n",
      "batch 5707: loss 0.020514\n",
      "batch 5708: loss 0.018016\n",
      "batch 5709: loss 0.058730\n",
      "batch 5710: loss 0.175480\n",
      "batch 5711: loss 0.095310\n",
      "batch 5712: loss 0.037861\n",
      "batch 5713: loss 0.039436\n",
      "batch 5714: loss 0.022711\n",
      "batch 5715: loss 0.036099\n",
      "batch 5716: loss 0.064589\n",
      "batch 5717: loss 0.013243\n",
      "batch 5718: loss 0.053995\n",
      "batch 5719: loss 0.012784\n",
      "batch 5720: loss 0.030905\n",
      "batch 5721: loss 0.090553\n",
      "batch 5722: loss 0.034874\n",
      "batch 5723: loss 0.004369\n",
      "batch 5724: loss 0.118041\n",
      "batch 5725: loss 0.139922\n",
      "batch 5726: loss 0.074188\n",
      "batch 5727: loss 0.066746\n",
      "batch 5728: loss 0.007902\n",
      "batch 5729: loss 0.034174\n",
      "batch 5730: loss 0.100711\n",
      "batch 5731: loss 0.060116\n",
      "batch 5732: loss 0.056762\n",
      "batch 5733: loss 0.005253\n",
      "batch 5734: loss 0.081682\n",
      "batch 5735: loss 0.234761\n",
      "batch 5736: loss 0.029580\n",
      "batch 5737: loss 0.075473\n",
      "batch 5738: loss 0.279726\n",
      "batch 5739: loss 0.016167\n",
      "batch 5740: loss 0.053594\n",
      "batch 5741: loss 0.063738\n",
      "batch 5742: loss 0.010293\n",
      "batch 5743: loss 0.013400\n",
      "batch 5744: loss 0.080233\n",
      "batch 5745: loss 0.017389\n",
      "batch 5746: loss 0.060985\n",
      "batch 5747: loss 0.010313\n",
      "batch 5748: loss 0.131273\n",
      "batch 5749: loss 0.025373\n",
      "batch 5750: loss 0.021741\n",
      "batch 5751: loss 0.185253\n",
      "batch 5752: loss 0.161519\n",
      "batch 5753: loss 0.025386\n",
      "batch 5754: loss 0.104710\n",
      "batch 5755: loss 0.051333\n",
      "batch 5756: loss 0.030452\n",
      "batch 5757: loss 0.042325\n",
      "batch 5758: loss 0.046596\n",
      "batch 5759: loss 0.066099\n",
      "batch 5760: loss 0.038166\n",
      "batch 5761: loss 0.142349\n",
      "batch 5762: loss 0.026974\n",
      "batch 5763: loss 0.049215\n",
      "batch 5764: loss 0.183218\n",
      "batch 5765: loss 0.050738\n",
      "batch 5766: loss 0.028180\n",
      "batch 5767: loss 0.026477\n",
      "batch 5768: loss 0.084359\n",
      "batch 5769: loss 0.018189\n",
      "batch 5770: loss 0.130011\n",
      "batch 5771: loss 0.079638\n",
      "batch 5772: loss 0.153765\n",
      "batch 5773: loss 0.021565\n",
      "batch 5774: loss 0.035029\n",
      "batch 5775: loss 0.016857\n",
      "batch 5776: loss 0.022969\n",
      "batch 5777: loss 0.061407\n",
      "batch 5778: loss 0.044445\n",
      "batch 5779: loss 0.057037\n",
      "batch 5780: loss 0.068413\n",
      "batch 5781: loss 0.036937\n",
      "batch 5782: loss 0.017171\n",
      "batch 5783: loss 0.042496\n",
      "batch 5784: loss 0.055430\n",
      "batch 5785: loss 0.023181\n",
      "batch 5786: loss 0.016775\n",
      "batch 5787: loss 0.029471\n",
      "batch 5788: loss 0.040284\n",
      "batch 5789: loss 0.006545\n",
      "batch 5790: loss 0.045770\n",
      "batch 5791: loss 0.026406\n",
      "batch 5792: loss 0.062670\n",
      "batch 5793: loss 0.025935\n",
      "batch 5794: loss 0.018593\n",
      "batch 5795: loss 0.028225\n",
      "batch 5796: loss 0.049029\n",
      "batch 5797: loss 0.020221\n",
      "batch 5798: loss 0.010876\n",
      "batch 5799: loss 0.068132\n",
      "batch 5800: loss 0.040115\n",
      "batch 5801: loss 0.015809\n",
      "batch 5802: loss 0.065363\n",
      "batch 5803: loss 0.022938\n",
      "batch 5804: loss 0.019553\n",
      "batch 5805: loss 0.090159\n",
      "batch 5806: loss 0.109847\n",
      "batch 5807: loss 0.109204\n",
      "batch 5808: loss 0.018761\n",
      "batch 5809: loss 0.004911\n",
      "batch 5810: loss 0.033942\n",
      "batch 5811: loss 0.084818\n",
      "batch 5812: loss 0.053660\n",
      "batch 5813: loss 0.030412\n",
      "batch 5814: loss 0.050259\n",
      "batch 5815: loss 0.110642\n",
      "batch 5816: loss 0.039727\n",
      "batch 5817: loss 0.096892\n",
      "batch 5818: loss 0.035834\n",
      "batch 5819: loss 0.060431\n",
      "batch 5820: loss 0.051864\n",
      "batch 5821: loss 0.103123\n",
      "batch 5822: loss 0.199881\n",
      "batch 5823: loss 0.070889\n",
      "batch 5824: loss 0.023943\n",
      "batch 5825: loss 0.051040\n",
      "batch 5826: loss 0.073209\n",
      "batch 5827: loss 0.131125\n",
      "batch 5828: loss 0.008739\n",
      "batch 5829: loss 0.025088\n",
      "batch 5830: loss 0.059367\n",
      "batch 5831: loss 0.031014\n",
      "batch 5832: loss 0.058761\n",
      "batch 5833: loss 0.007498\n",
      "batch 5834: loss 0.021786\n",
      "batch 5835: loss 0.019576\n",
      "batch 5836: loss 0.059250\n",
      "batch 5837: loss 0.023754\n",
      "batch 5838: loss 0.209796\n",
      "batch 5839: loss 0.092082\n",
      "batch 5840: loss 0.063672\n",
      "batch 5841: loss 0.009467\n",
      "batch 5842: loss 0.009543\n",
      "batch 5843: loss 0.004924\n",
      "batch 5844: loss 0.032872\n",
      "batch 5845: loss 0.073152\n",
      "batch 5846: loss 0.204908\n",
      "batch 5847: loss 0.023540\n",
      "batch 5848: loss 0.038541\n",
      "batch 5849: loss 0.017093\n",
      "batch 5850: loss 0.066767\n",
      "batch 5851: loss 0.017360\n",
      "batch 5852: loss 0.097260\n",
      "batch 5853: loss 0.015613\n",
      "batch 5854: loss 0.032349\n",
      "batch 5855: loss 0.014843\n",
      "batch 5856: loss 0.035664\n",
      "batch 5857: loss 0.006289\n",
      "batch 5858: loss 0.031296\n",
      "batch 5859: loss 0.067650\n",
      "batch 5860: loss 0.026409\n",
      "batch 5861: loss 0.093956\n",
      "batch 5862: loss 0.012510\n",
      "batch 5863: loss 0.037815\n",
      "batch 5864: loss 0.024025\n",
      "batch 5865: loss 0.019789\n",
      "batch 5866: loss 0.098302\n",
      "batch 5867: loss 0.082057\n",
      "batch 5868: loss 0.021782\n",
      "batch 5869: loss 0.039833\n",
      "batch 5870: loss 0.071232\n",
      "batch 5871: loss 0.005238\n",
      "batch 5872: loss 0.043936\n",
      "batch 5873: loss 0.071374\n",
      "batch 5874: loss 0.025251\n",
      "batch 5875: loss 0.028998\n",
      "batch 5876: loss 0.245638\n",
      "batch 5877: loss 0.045632\n",
      "batch 5878: loss 0.086644\n",
      "batch 5879: loss 0.035170\n",
      "batch 5880: loss 0.018401\n",
      "batch 5881: loss 0.019126\n",
      "batch 5882: loss 0.064922\n",
      "batch 5883: loss 0.008720\n",
      "batch 5884: loss 0.027353\n",
      "batch 5885: loss 0.030029\n",
      "batch 5886: loss 0.112491\n",
      "batch 5887: loss 0.031413\n",
      "batch 5888: loss 0.038869\n",
      "batch 5889: loss 0.354119\n",
      "batch 5890: loss 0.091633\n",
      "batch 5891: loss 0.023540\n",
      "batch 5892: loss 0.049111\n",
      "batch 5893: loss 0.052988\n",
      "batch 5894: loss 0.002935\n",
      "batch 5895: loss 0.044408\n",
      "batch 5896: loss 0.030068\n",
      "batch 5897: loss 0.020127\n",
      "batch 5898: loss 0.006103\n",
      "batch 5899: loss 0.058250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5900: loss 0.074754\n",
      "batch 5901: loss 0.068444\n",
      "batch 5902: loss 0.047146\n",
      "batch 5903: loss 0.043980\n",
      "batch 5904: loss 0.008381\n",
      "batch 5905: loss 0.037290\n",
      "batch 5906: loss 0.133585\n",
      "batch 5907: loss 0.111437\n",
      "batch 5908: loss 0.022635\n",
      "batch 5909: loss 0.019949\n",
      "batch 5910: loss 0.066932\n",
      "batch 5911: loss 0.112582\n",
      "batch 5912: loss 0.064828\n",
      "batch 5913: loss 0.072226\n",
      "batch 5914: loss 0.042208\n",
      "batch 5915: loss 0.022034\n",
      "batch 5916: loss 0.152647\n",
      "batch 5917: loss 0.078085\n",
      "batch 5918: loss 0.043009\n",
      "batch 5919: loss 0.195933\n",
      "batch 5920: loss 0.033591\n",
      "batch 5921: loss 0.058864\n",
      "batch 5922: loss 0.018494\n",
      "batch 5923: loss 0.047380\n",
      "batch 5924: loss 0.048584\n",
      "batch 5925: loss 0.023659\n",
      "batch 5926: loss 0.257166\n",
      "batch 5927: loss 0.016452\n",
      "batch 5928: loss 0.243148\n",
      "batch 5929: loss 0.007725\n",
      "batch 5930: loss 0.011083\n",
      "batch 5931: loss 0.010667\n",
      "batch 5932: loss 0.035299\n",
      "batch 5933: loss 0.026184\n",
      "batch 5934: loss 0.090633\n",
      "batch 5935: loss 0.020782\n",
      "batch 5936: loss 0.017605\n",
      "batch 5937: loss 0.098259\n",
      "batch 5938: loss 0.046028\n",
      "batch 5939: loss 0.030996\n",
      "batch 5940: loss 0.007601\n",
      "batch 5941: loss 0.032405\n",
      "batch 5942: loss 0.013410\n",
      "batch 5943: loss 0.021021\n",
      "batch 5944: loss 0.060417\n",
      "batch 5945: loss 0.040812\n",
      "batch 5946: loss 0.054139\n",
      "batch 5947: loss 0.002807\n",
      "batch 5948: loss 0.017459\n",
      "batch 5949: loss 0.028791\n",
      "batch 5950: loss 0.034052\n",
      "batch 5951: loss 0.020396\n",
      "batch 5952: loss 0.009376\n",
      "batch 5953: loss 0.004223\n",
      "batch 5954: loss 0.023717\n",
      "batch 5955: loss 0.020339\n",
      "batch 5956: loss 0.169354\n",
      "batch 5957: loss 0.013366\n",
      "batch 5958: loss 0.045741\n",
      "batch 5959: loss 0.117612\n",
      "batch 5960: loss 0.035389\n",
      "batch 5961: loss 0.020306\n",
      "batch 5962: loss 0.038788\n",
      "batch 5963: loss 0.054191\n",
      "batch 5964: loss 0.021395\n",
      "batch 5965: loss 0.014928\n",
      "batch 5966: loss 0.020080\n",
      "batch 5967: loss 0.011374\n",
      "batch 5968: loss 0.082887\n",
      "batch 5969: loss 0.025247\n",
      "batch 5970: loss 0.008919\n",
      "batch 5971: loss 0.152699\n",
      "batch 5972: loss 0.015809\n",
      "batch 5973: loss 0.008713\n",
      "batch 5974: loss 0.037524\n",
      "batch 5975: loss 0.075794\n",
      "batch 5976: loss 0.063869\n",
      "batch 5977: loss 0.090518\n",
      "batch 5978: loss 0.049253\n",
      "batch 5979: loss 0.023211\n",
      "batch 5980: loss 0.012407\n",
      "batch 5981: loss 0.006668\n",
      "batch 5982: loss 0.023910\n",
      "batch 5983: loss 0.021404\n",
      "batch 5984: loss 0.064283\n",
      "batch 5985: loss 0.078662\n",
      "batch 5986: loss 0.149315\n",
      "batch 5987: loss 0.035831\n",
      "batch 5988: loss 0.066177\n",
      "batch 5989: loss 0.021467\n",
      "batch 5990: loss 0.027072\n",
      "batch 5991: loss 0.092760\n",
      "batch 5992: loss 0.084011\n",
      "batch 5993: loss 0.085570\n",
      "batch 5994: loss 0.009414\n",
      "batch 5995: loss 0.058030\n",
      "batch 5996: loss 0.107290\n",
      "batch 5997: loss 0.051770\n",
      "batch 5998: loss 0.015287\n",
      "batch 5999: loss 0.048848\n"
     ]
    }
   ],
   "source": [
    "#模型超参数设置\n",
    "num_epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "#开始操作\n",
    "model = MLP()\n",
    "#调用tensorflow内置优化器\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "#设置批次数量\n",
    "num_batch = int(num_x_train//batch_size*num_epochs)\n",
    "for tr_index in range(num_batch):\n",
    "    X,Y = get_batch(batch_size,x_train)\n",
    "    with tf.GradientTape() as tape:\n",
    "        #得到模型预测值\n",
    "        y_pred = model(X)\n",
    "        #计算损失函数\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "                y_true=Y, y_pred=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        print(\"batch %d: loss %f\" % (tr_index, loss.numpy()))\n",
    "        # 计算模型变量的导数\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "        # 优化器的使用\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T07:25:45.158498Z",
     "start_time": "2021-07-18T07:25:35.225995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.971200\n"
     ]
    }
   ],
   "source": [
    "#调用tensorflow内置准确度测量函数进行模型评估\n",
    "#逐批次地计算准确值并累加\n",
    "acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "num_batch = int(num_x_test//batch_size)\n",
    "for tr_index in range(num_batch):\n",
    "    start_index,end_index = tr_index*batch_size,(1+tr_index)*batch_size\n",
    "    y_pred = model.predict(x_test[start_index:end_index])\n",
    "    acc.update_state(y_true=y_test[start_index:end_index],y_pred=y_pred)\n",
    "print(\"accuracy:%f\"%acc.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果需要进一步提高精度，可以尝试最优化超参数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "364.667px",
    "left": "564px",
    "right": "20px",
    "top": "-16px",
    "width": "397px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
